{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to OBOparser's documentation! \n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "<pre>\n",
    "<a href=\"#overview\">Overview</a>\n",
    "<a href=\"#install-load-and-run-oboparser\">Install Load and Run OBOparser</a>\n",
    "<a href=\"#oboparsers-subroutines\">OBOparser's subroutines</a>\n",
    "<a href=\"#tutorial\">Tutorial</a>\n",
    "    <a href=\"#application-to-the-gene-ontology-go\">Application to the Gene Ontology (GO)</a>\n",
    "        <a href=\"#parse-the-go-obo-file\">Parse the GO obo file</a>\n",
    "        <a href=\"#parse-the-goa-annotation-file\">Parse the GOA annotation file</a>\n",
    "        <a href=\"#map-go-terms-between-releases\">Map GO terms between releases</a>\n",
    "    <a href=\"#application-to-human-phenotype-ontology-hpo\">Application to the Human Phenotype Ontology (HPO)</a>\n",
    "        <a href=\"#parse-the-hpo-obo-file\">Parse the HPO obo file</a>\n",
    "        <a href=\"#parse-the-hpo-annotation-file\">Parse the HPO annotation file</a>\n",
    "        <a href=\"#map-hpo-terms-between-releases\">Map HPO terms between releases</a>\n",
    "</pre>\n",
    "\n",
    "---\n",
    "\n",
    "# Overview\n",
    "\n",
    "``OBOparser`` is a Perl module specifically designed to handle **GO** and **HPO** obo file and their annotation file. However, subroutines gathered under the alias ``ontology`` can be safely used to parse any *obo* file listed in [OBO foundry](http://www.obofoundry.org/). For further details on ``OBOparser`` subroutines, see <a href=\"#oboparsers-subroutines\">OBOparser's subroutines</a>, whereas subroutines gathered under the alias ``annotation`` can be safely used to parse any *annotation* file listed in [GOA website](https://www.ebi.ac.uk/GOA/downloads) and [HPO website](https://hpo.jax.org/app/download/annotation) and more in general any file structured as those shown in GOA and HPO website (basically a csv file using ``tab`` as separator). \n",
    "\n",
    "# Install Load and Run OBOparser\n",
    "\n",
    "You can install ``OBOparser`` by ``cpan`` (``cpan install OBOparser``) or by ``cpanm`` (``cpanm OBOparser``). To load the ``OBOparser`` module, just type inside a Perl script ``use OBOparser``. More precisely, the 'header' of your Perl script should be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "perl"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/perl \n",
    "\n",
    "use strict;\n",
    "use warnings;\n",
    "use OBOparser; \n",
    "\n",
    "... beginning of your perl code ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively you can clone (or download) this repository and initialize your Perl script as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "perl"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/perl \n",
    "\n",
    "use strict;\n",
    "use warnings;\n",
    "use lib 'path/to/folder/containing/OBOparser.pm'; ## nb: folder != full filename\n",
    "use 'OBOparser';\n",
    "\n",
    "... beginning of your Perl code ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run your Perl script by making it executable (``chmod +x perl-script.pl``) or by placing the Perl interpreter before your script (``perl perl-script.pl``).\n",
    "\n",
    "# OBOparser's subroutines\n",
    "\n",
    "``OBOparser`` contains the following subroutines:\n",
    "\n",
    "* __build_edges__: extract edges from an ``obo`` file;\n",
    "* __build_subonto__: extract edges for a specified subontology domain;\n",
    "* __make_stat__: make basic statistic on a graph;\n",
    "* __gene2biofun__: build an annotations adjacency list;\n",
    "* __map_OBOterm_between_release__: map ontology terms between releases;\n",
    "\n",
    "``OBOparser`` subroutines are gathered under different alias. For instance, if you want just call the subroutines specific to handle an ``obo`` file you should type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "perl"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "use OBOparser qw(:ontology):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, if you want to load the subroutines specific to handle the annotations file you should type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "perl "
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "use OBOparser qw(:annotation):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, if you want to load all the ``OBOparser``subroutines at one fell swoop you should type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "perl "
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "use OBOparser qw(:all):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial\n",
    "\n",
    "Here we show a step-by-step application of ``OBOparser`` on Gene Ontology (``GO``) and Human Phenotype Ontology (``HPO``) and their respective annotation file.\n",
    "The Perl code snippets reported below using the ``GO`` and ``HPO`` are *glued* respectively in the script ``GOscript.pl`` and ``HPOscript.pl`` stored in ``t`` folder of this repository.\n",
    "\n",
    "## Application to the Gene Ontology (GO) \n",
    "\n",
    "Note: for all the examples shown below, we assume that the I/O files are saved in the ``t/data`` directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p t/data  ## create a directory if it does not already exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the GO obo file\n",
    "\n",
    "First of all we must download the *obo* file from [Gene Ontoloy website](http://geneontology.org/docs/download-ontology/). In the experiments shown below we use the *basic* version of the **GO**, because this version excludes relationships that cross the 3 **GO** hierarchies (``BP``, ``MF``, ``CC``). To do that in a Linux environment, just type on the bash:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd t/data && wget http://purl.obolibrary.org/obo/go/go-basic.obo -O gobasic.obo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a look to the ``gobasic.obo`` file to see how it is structured. For instance, to display the first ``60`` lines we can type ``head -n60 t/data/gobasic.obo ``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format-version: 1.2\n",
    "data-version: releases/2019-07-01\n",
    "subsetdef: gocheck_do_not_annotate \"Term not to be used for direct annotation\"\n",
    "subsetdef: gocheck_do_not_manually_annotate \"Term not to be used for direct manual annotation\"\n",
    "subsetdef: goslim_agr \"AGR slim\"\n",
    "subsetdef: goslim_aspergillus \"Aspergillus GO slim\"\n",
    "subsetdef: goslim_candida \"Candida GO slim\"\n",
    "subsetdef: goslim_chembl \"ChEMBL protein targets summary\"\n",
    "subsetdef: goslim_flybase_ribbon \"FlyBase Drosophila GO ribbon slim\"\n",
    "subsetdef: goslim_generic \"Generic GO slim\"\n",
    "subsetdef: goslim_metagenomics \"Metagenomics GO slim\"\n",
    "subsetdef: goslim_mouse \"Mouse GO slim\"\n",
    "subsetdef: goslim_pir \"PIR GO slim\"\n",
    "subsetdef: goslim_plant \"Plant GO slim\"\n",
    "subsetdef: goslim_pombe \"Fission yeast GO slim\"\n",
    "subsetdef: goslim_synapse \"synapse GO slim\"\n",
    "subsetdef: goslim_yeast \"Yeast GO slim\"\n",
    "synonymtypedef: syngo_official_label \"label approved by the SynGO project\"\n",
    "synonymtypedef: systematic_synonym \"Systematic synonym\" EXACT\n",
    "default-namespace: gene_ontology\n",
    "remark: cvs version: use data-version\n",
    "remark: Includes Ontology(OntologyID(OntologyIRI(<http://purl.obolibrary.org/obo/go/never_in_taxon.owl>))) [Axioms: 18 Logical Axioms: 0]\n",
    "ontology: go\n",
    "\n",
    "[Term]\n",
    "id: GO:0000001\n",
    "name: mitochondrion inheritance\n",
    "namespace: biological_process\n",
    "def: \"The distribution of mitochondria, including the mitochondrial genome, into daughter cells after mitosis or meiosis, mediated by interactions between mitochondria and the cytoskeleton.\" [GOC:mcc, PMID:10873824, PMID:11389764]\n",
    "synonym: \"mitochondrial inheritance\" EXACT []\n",
    "is_a: GO:0048308 ! organelle inheritance\n",
    "is_a: GO:0048311 ! mitochondrion distribution\n",
    "\n",
    "[Term]\n",
    "id: GO:0000002\n",
    "name: mitochondrial genome maintenance\n",
    "namespace: biological_process\n",
    "def: \"The maintenance of the structure and integrity of the mitochondrial genome; includes replication and segregation of the mitochondrial chromosome.\" [GOC:ai, GOC:vw]\n",
    "is_a: GO:0007005 ! mitochondrion organization\n",
    "\n",
    "[Term]\n",
    "id: GO:0000003\n",
    "name: reproduction\n",
    "namespace: biological_process\n",
    "alt_id: GO:0019952\n",
    "alt_id: GO:0050876\n",
    "def: \"The production of new individuals that contain some portion of genetic material inherited from one or more parent organisms.\" [GOC:go_curators, GOC:isa_complete, GOC:jl, ISBN:0198506732]\n",
    "subset: goslim_agr\n",
    "subset: goslim_chembl\n",
    "subset: goslim_flybase_ribbon\n",
    "subset: goslim_generic\n",
    "subset: goslim_pir\n",
    "subset: goslim_plant\n",
    "synonym: \"reproductive physiological process\" EXACT []\n",
    "xref: Wikipedia:Reproduction\n",
    "is_a: GO:0008150 ! biological_process\n",
    "\n",
    "\n",
    "[Term]\n",
    "id: GO:0000005\n",
    "name: obsolete ribosomal chaperone activity\n",
    "\n",
    "... to be continued ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are interested to extrapolate the **GO** edges from the ``gobasic.obo`` file, we can use the subroutine ``build_edges``. This subroutine receives in input just the ``obo`` file to parse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "perl"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "## loading and calling\n",
    "my $obofile= \"t/data/gobasic.obo\";\n",
    "my $gores= OBOparser::build_edges($obofile);\n",
    "\n",
    "## storing\n",
    "my $goedges= \"t/data/gobasic-edges.txt\";\n",
    "open OUT, \"> $goedges\"; \n",
    "print OUT \"${$gores}\"; ## dereferencing\n",
    "close OUT;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of the space, below we just show the first ``25`` lines of the output file ``gobasic-edges.txt`` (``head -n25 t/data/gobasic-edges.txt``):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biological_process  GO:0048308  GO:0000001  is-a\n",
    "biological_process  GO:0048311  GO:0000001  is-a\n",
    "biological_process  GO:0007005  GO:0000002  is-a\n",
    "biological_process  GO:0008150  GO:0000003  is-a\n",
    "molecular_function  GO:0005385  GO:0000006  is-a\n",
    "molecular_function  GO:0005385  GO:0000007  is-a\n",
    "molecular_function  GO:0000030  GO:0000009  is-a\n",
    "molecular_function  GO:0016765  GO:0000010  is-a\n",
    "biological_process  GO:0007033  GO:0000011  is-a\n",
    "biological_process  GO:0048308  GO:0000011  is-a\n",
    "biological_process  GO:0006281  GO:0000012  is-a\n",
    "molecular_function  GO:0004520  GO:0000014  is-a\n",
    "cellular_component  GO:0044445  GO:0000015  is-a\n",
    "cellular_component  GO:1902494  GO:0000015  is-a\n",
    "molecular_function  GO:0004553  GO:0000016  is-a\n",
    "biological_process  GO:0042946  GO:0000017  is-a\n",
    "biological_process  GO:0051052  GO:0000018  is-a\n",
    "biological_process  GO:0000018  GO:0000019  is-a\n",
    "biological_process  GO:0051231  GO:0000022  is-a\n",
    "biological_process  GO:1903047  GO:0000022  is-a\n",
    "biological_process  GO:0000070  GO:0000022  part-of\n",
    "biological_process  GO:0007052  GO:0000022  part-of\n",
    "biological_process  GO:0005984  GO:0000023  is-a\n",
    "biological_process  GO:0000023  GO:0000024  is-a\n",
    "biological_process  GO:0046351  GO:0000024  is-a\n",
    "\n",
    "... to be continued ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column of the output file refers to the domain whose a **GO** term belong to, the second and the third column represent the edge as pair of nodes in the form ``source (parent) - destination (child)`` and the fourth column refers to the kind of relationships. The last column can assume only two values, ``is-a`` and ``part-of``, since it is safe grouping annotations by using both these relationships. For more details about **GO** relationships have a look at this [link](http://geneontology.org/docs/ontology-relations/).\n",
    "\n",
    "If we want to isolate nodes and relationships, belonging only to one of the **GO** sub-ontology (e.g. ``biological_process (BP)``), we can use the subroutine ``build_subonto``. This subroutine receives in input the edges file obtained above and the specific sub-domain for which we want to extrapolate edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "perl"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "## loading and calling\n",
    "my $goedges= \"t/data/gobasic-edges.txt\"; ## obtained previously by calling OBOparser::build_edges\n",
    "my $BPres= OBOparser::build_subonto($goedges, \"biological_process\");\n",
    "\n",
    "## storing\n",
    "my $BPedges= \"t/data/gobasic-edgesBP.txt\";\n",
    "open OUT, \"> $BPedges\";\n",
    "print OUT \"${$BPres}\";\n",
    "close OUT;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we report the first ``10`` lines of ``gobasic-edgesBP.txt`` (``head -n10 t/data/gobasic-edgesBP.txt``):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GO:0048308  GO:0000001  is-a\n",
    "GO:0048311  GO:0000001  is-a\n",
    "GO:0007005  GO:0000002  is-a\n",
    "GO:0008150  GO:0000003  is-a\n",
    "GO:0007033  GO:0000011  is-a\n",
    "GO:0048308  GO:0000011  is-a\n",
    "GO:0006281  GO:0000012  is-a\n",
    "GO:0042946  GO:0000017  is-a\n",
    "GO:0051052  GO:0000018  is-a\n",
    "GO:0000018  GO:0000019  is-a\n",
    "\n",
    "... to be continued ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth noting that the same output can be also achieved by using the ``grep`` command (in a Linux environment):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "grep \"biological_process\" data/gobasic-edges.txt | cut -f2- > data/gobasic-edgesBP.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to isolate nodes and relationships separately for each **GO** subontology at one fell swoop, by Perl:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "perl"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "my $goedges= \"t/data/gobasic-edges.txt\"; ## obtained previously by calling OBOparser::build_edges\n",
    "my @domains= qw(biological_process molecular_function cellular_component);\n",
    "my %aspects=(biological_process => \"BP\", molecular_function => \"MF\", cellular_component => \"CC\");\n",
    "\n",
    "foreach my $domain (@domains){\n",
    "    my $outfile= \"data/gobasic-edges\".\"$aspects{$domain}\".\".txt\";\n",
    "    open OUT, \"> $outfile\";\n",
    "    my $domainres= OBOparser::build_subonto($goedges, $domain);\n",
    "    print OUT \"${$domainres}\";\n",
    "    close OUT;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and by bash:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "goedges=\"t/data/gobasic-edges.txt\"; ## obtained previously by calling OBOparser::build_edges\n",
    "domains=(\"biological_process\" \"molecular_function\" \"cellular_component\");\n",
    "aspects=(\"BP\" \"MF\" \"CC\");\n",
    "\n",
    "len=\"${#domains[@]}\"\n",
    "for ((i = 0 ; i < len ; i++)); do\n",
    "    grep ${domains[$i]} data/gobasic-edges.txt | cut -f2- > data/gobasic-edges${aspects[$i]}.txt\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To print some statistics on the ``GO`` graph, we can use the subroutine ``make_stat``. The input arguments required by this subroutine are:\n",
    "\n",
    "1. ``$goedges``: the file containing the ``GO`` graph represented as a list of edges where each edge is turn represented as a pair of vertices ``tab`` separated (``$goedges`` file can be obtained by calling the ``OBOparser::build_edges`` subroutine)\n",
    "2. ``$parentIndex`` and ``$childIndex``: the index that refer restrictively to the column containing the ``source`` and ``destination`` nodes in the ``$goedges`` file (reminder; Perl starts counting from zero)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "perl"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "my ($goedges, $parentIndex, $childIndex)= (\"$data/gobasic-edges.txt\", 1,2);\n",
    "my $res= OBOparser::make_stat($goedges, $parentIndex, $childIndex);\n",
    "print \"$res\";\n",
    "\n",
    "## results printed on the shell\n",
    "oboterm <tab> degree <tab> indegree <tab> outdegree\n",
    "GO:0032991  470 1   469\n",
    "GO:0016616  351 1   350\n",
    "GO:0016709  303 2   301\n",
    "GO:0044444  211 2   209\n",
    "GO:0016758  204 1   203\n",
    "GO:0048856  199 1   198\n",
    "GO:0098797  180 2   178\n",
    "GO:0003006  171 2   169\n",
    "GO:0016747  159 1   158\n",
    ".\n",
    ".\n",
    ".\n",
    "~summary stats~\n",
    "nodes: 44945\n",
    "edges: 83839\n",
    "max degree: 470\n",
    "min degree: 1\n",
    "median degree: 2.0000\n",
    "average degree: 1.8654\n",
    "density: 4.1504e-05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can observe from the snippet above for each node of the graph is printed its ``degree``, ``in-degree`` and ``out-degree``, with the nodes sorted in a decreasing order on the basis of degree, from the higher to the smaller one. In addition are also printed the following statistics: 1) number of nodes and edges of the graph; 2) maximum and minimum degree; 3) average and median degree; 4) density of the graph. \n",
    "\n",
    "To compute the stats just for a specific ``GO`` subontology (e.g. ``GO BP``) we can always use ``OBOparser::make_stat``, paying attention to properly set its input arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "perl"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "my ($goedges, $parentIndex, $childIndex)= (\"data/gobasic-edgesBP.txt\", 0,1);\n",
    "my $res= OBOparser::make_stat($goedges, $parentIndex, $childIndex);\n",
    "print \"$res\";\n",
    "\n",
    "## results returned on the shell\n",
    "oboterm <tab> degree <tab> indegree <tab> outdegree\n",
    "GO:0048856  199 1   198\n",
    "GO:0003006  171 2   169\n",
    "GO:0051241  136 2   134\n",
    "GO:0051240  129 2   127\n",
    "GO:0014070  128 1   127\n",
    "GO:1901700  112 1   111\n",
    "GO:0022414  110 2   108\n",
    "GO:0048646  108 2   106\n",
    "GO:0031328  105 3   102\n",
    "GO:1901361  105 2   103\n",
    ".\n",
    ".\n",
    ".\n",
    "~summary stats~\n",
    "nodes: 29652\n",
    "edges: 62739\n",
    "max degree: 199\n",
    "min degree: 1\n",
    "median degree: 3.0000\n",
    "average degree: 2.1158\n",
    "density: 7.1358e-05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the GOA annotation file\n",
    "\n",
    "``OBOparser`` can be also used to parse the annotation file taken from the Gene Ontology Annotation (``GOA``) Database ([link](https://www.ebi.ac.uk/GOA)). \n",
    "\n",
    "For the examples shown below we use the annotation of the ``CHICKEN`` organism (release ``7/29/19``), but of course the ``OBOparser`` subroutines gather under the alias ``annotation`` can be applied to the annotation file of any other organisms listed in the ``GOA`` database and more in general to any file structured as those listed in the ``GOA`` database. \n",
    "\n",
    "---\n",
    "\n",
    "NOTE: the annotation file on ``GOA`` website are monthly updated. The release used at the time of writing this tutorial is July release (7/29/19).\n",
    "\n",
    "---\n",
    "First we must download the annotation file in the ``data`` folder (note that the link refers to the most updated release):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd data && wget ftp://ftp.ebi.ac.uk/pub/databases/GO/goa/CHICKEN/goa_chicken.gaf.gz -O goa_chicken.gaf.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By having a look to the ``goa_chicken.gaf.gz`` file we see that it is structured as follow (for the sake of space we display just the first ``20`` lines):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gaf-version: 2.1\n",
    "!\n",
    "!The set of protein accessions included in this file is based on UniProt reference proteomes, which provide one protein per gene.\n",
    "!They include the protein sequences annotated in Swiss-Prot or the longest TrEMBL transcript if there is no Swiss-Prot record.\n",
    "!If a particular protein accession is not annotated with GO, then it will not appear in this file.\n",
    "!\n",
    "!Note that the annotation set in this file is filtered in order to reduce redundancy; the full, unfiltered set can be found in\n",
    "!ftp://ftp.ebi.ac.uk/pub/databases/GO/goa/UNIPROT/goa_uniprot_all.gz\n",
    "!\n",
    "!Generated: 2019-07-29 13:51\n",
    "!GO-version: http://purl.obolibrary.org/obo/go/releases/2019-07-17/extensions/go-plus.owl\n",
    "!\n",
    "UniProtKB   A0A088BIK7  EDbeta      GO:0005200  GO_REF:0000002  IEA InterPro:IPR003461  F   Keratin EDbeta|EDBETA   protein taxon:9031  20190727    InterPro        \n",
    "UniProtKB   A0A088BIK7  EDbeta      GO:0005882  GO_REF:0000038  IEA UniProtKB-KW:KW-0416    C   Keratin EDbeta|EDBETA   protein taxon:9031  20190727    UniProt     \n",
    "UniProtKB   A0A088BIK7  EDbeta      GO:0007010  GO_REF:0000108  IEA GO:0005200  P   Keratin EDbeta|EDBETA   protein taxon:9031  20190727    GOC     \n",
    "UniProtKB   A0A0A0MQ32  LOXL2       GO:0000122  GO_REF:0000107  IEA UniProtKB:Q9Y4K0|ensembl:ENSP00000373783    P   Lysyl oxidase homolog 2 LOXL2   protein taxon:9031  20190727    Ensembl     \n",
    "UniProtKB   A0A0A0MQ32  LOXL2       GO:0000785  GO_REF:0000107  IEA UniProtKB:Q9Y4K0|ensembl:ENSP00000373783    C   Lysyl oxidase homolog 2 LOXL2   protein taxon:9031  20190727    Ensembl     \n",
    "UniProtKB   A0A0A0MQ32  LOXL2       GO:0001666  GO_REF:0000107  IEA UniProtKB:P58022|ensembl:ENSMUSP00000022660 P   Lysyl oxidase homolog 2 LOXL2   protein taxon:9031  20190727    Ensembl     \n",
    "UniProtKB   A0A0A0MQ32  LOXL2       GO:0001837  GO_REF:0000107  IEA UniProtKB:Q9Y4K0|ensembl:ENSP00000373783    P   Lysyl oxidase homolog 2 LOXL2   protein taxon:9031  20190727    Ensembl     \n",
    "UniProtKB   A0A0A0MQ32  LOXL2       GO:0001935  GO_REF:0000107  IEA UniProtKB:Q9Y4K0|ensembl:ENSP00000373783    P   Lysyl oxidase homolog 2 LOXL2   protein taxon:9031  20190727    Ensembl \n",
    "\n",
    "... to be continued ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can build the adjacency list of annotations by using the subroutine ``OBOparser::gene2biofun``. The input arguments required are:\n",
    "\n",
    "1. ``$inputfile``: ``GOA`` annotation file for the ``CHICKEN`` organism;\n",
    "2. ``$geneindex`` and ``$geneindex``: index referring respectively to the column containing the proteins and the ``GO`` term in the ``$inputfile`` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "perl"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "my ($inputfile, $geneindex, $classindex)= (\"t/data/goa_chicken.gaf.gz\", 1, 4);\n",
    "my ($res, $stat)= OBOparser::gene2biofun($inputfile, $geneindex, $classindex);\n",
    "\n",
    "my $goaout= \"t/data/chicken.uniprot2go.txt\";\n",
    "open OUT, \"> $goaout\";\n",
    "foreach my $k (sort{$a cmp $b} keys %$res) { print OUT \"$k $$res{$k}\\n\";} \n",
    "close OUT;\n",
    "print \"${$stat}\\n\";\n",
    "\n",
    "## results printed on the shell\n",
    "genes: 15695\n",
    "ontology terms: 13953"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``OBOparser::gene2biofun`` returns a list of two anonymous references. The first is an anonymous hash storing for each UniProtKB protein all its associated ``GO`` terms (pipe separated). The second is an anonymous scalar containing basic statistics such as the total unique number of proteins and ontology terms. In the example above the anonymous hash is addressed in the output file ``data/chicken.uniprot2go.txt`` and the stats are printed on the shell. Finally, it is worth noting that ``OBOparser::gene2biofun`` can handle both compress ``.gz`` file and plain ``.txt`` file. Below as an example is reported a snapshot of the associations between UniProtKB entry and ``GO`` terms stored ``data/chicken.uniprot2go.txt``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head -n10 data/chicken.uniprot2go.txt\n",
    "\n",
    "A0A088BIK7 GO:0005200|GO:0005882|GO:0007010\n",
    "A0A0A0MQ32 GO:0000122|GO:0000785|GO:0001666|GO:0001837|GO:0001935|GO:0002040|GO:0004720|GO:0005044|GO:0005507|GO:0005509|GO:0005615|GO:0005654|GO:0005783|GO:0006897|GO:0010718|GO:0016020|GO:0018057|GO:0030199|GO:0032332|GO:0043542|GO:0046688|GO:0070492|GO:0070828|GO:1902455\n",
    "A0A0A0MQ34 GO:0009374\n",
    "A0A0A0MQ35 GO:0000421|GO:0005654|GO:0005765|GO:0016021|GO:0032266|GO:0097352\n",
    "A0A0A0MQ36 GO:0005246|GO:0005509|GO:0007165\n",
    "A0A0A0MQ42 GO:0005654|GO:0005794|GO:0019221|GO:0030368\n",
    "A0A0A0MQ45 GO:0000086|GO:0004674|GO:0005524|GO:0005634|GO:0005654|GO:0005813|GO:0007147|GO:0018105|GO:0032154|GO:0032515|GO:0035556|GO:0051726|GO:1904668\n",
    "A0A0A0MQ47 GO:0000122|GO:0000993|GO:0002039|GO:0005634|GO:0005829|GO:0008285|GO:0010452|GO:0018026|GO:0018027|GO:0043516|GO:0046975\n",
    "A0A0A0MQ52 GO:0000724|GO:0003678|GO:0003682|GO:0003682|GO:0003688|GO:0003697|GO:0005524|GO:0005634|GO:0006270|GO:0007292|GO:0019899|GO:0032406|GO:0032407|GO:0032408|GO:0032508|GO:0036298|GO:0036298|GO:0042555|GO:0070716|GO:0070716|GO:0071168|GO:0097362|GO:0097362\n",
    "A0A0A0MQ56 GO:0005615|GO:0005623|GO:0010975|GO:1990830|GO:0005874\n",
    "\n",
    "... to be continued..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map GO terms between releases\n",
    "In time-lapse hold-out experiments we use annotations of an old ``GO`` release to predict the protein function of a more recent ``GO`` release. However, between different ``GO`` releases some ontology terms could be removed, others changed or become obsolete. Then we must map the old ``GO`` terms to the new ones by parsing the annotation file of an *old* ``GO`` release by using as key the alt-ID taken from the obo file of a *new* ``GO`` release. The ``OBOparser`` subroutine ``map_OBOterm_between_release`` does the work for us.\n",
    "\n",
    "First we download the old annotation file of the ``CHICKEN`` organism in the ``data`` directory (in the example below we use the ``07/06/16`` release):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd data && wget ftp://ftp.ebi.ac.uk/pub/databases/GO/goa/old/CHICKEN/goa_chicken.gaf.128.gz -O goa_chicken.gaf.128.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input arguments required by ``map_OBOterm_between_release`` are:\n",
    "\n",
    "1. ``$obofile``: the new release of a ``GO`` obo file. This file is used to make the ``alt_id - id`` pairing by using ``alt_id`` as key;\n",
    "2. ``$goafileOld``: the old release of an annotation file. In this example we use the ``07/06/16`` release;\n",
    "3. ``$classindex``: the index referring to the column of the ``$goafileOld`` containing the ontology terms to be mapped (in the ``GOA`` file the ``GO`` terms are in the 4 columns -- NB: we must start to count from zero)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "perl"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "my ($obofile, $goafileOld, $classindex)= (\"data/gobasic.obo\", \"data/goa_chicken.gaf.128.gz\", 4);\n",
    "my ($res, $stat)= OBOparser::map_OBOterm_between_release($obofile, $goafileOld, $classindex);\n",
    "\n",
    "my $mapfile= \"t/data/chicken.goa.mapped.txt\";\n",
    "open OUT, \"> $mapfile\"; \n",
    "print OUT \"${$res}\";\n",
    "close OUT;\n",
    "print \"${$stat}\";\n",
    "\n",
    "# results printed on the shell\n",
    "#alt-id <tab> id\n",
    "GO:0000042  GO:0034067\n",
    "GO:0000975  GO:0044212\n",
    "GO:0000982  GO:0000981\n",
    "GO:0000983  GO:0016251\n",
    "GO:0001075  GO:0016251\n",
    "GO:0001077  GO:0001228\n",
    "GO:0001078  GO:0001227\n",
    "GO:0001104  GO:0003712\n",
    "GO:0001105  GO:0003713\n",
    "GO:0001106  GO:0003714\n",
    ".\n",
    ".\n",
    ".\n",
    "Tot. ontology terms:    12546\n",
    "Tot. altID: 2532\n",
    "Tot. altID seen:    201\n",
    "Tot. altID unseen:  2331"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``OBOparser::map_OBOterm_between_release`` subroutine returns a list of two anonymous references. The first is an anonymous scalar storing the annotations file in the same format of the input file but with the *obsolete* ontology terms substituted with the *updated* ones. The second reference is an anonymous scalar containing some basic statistics, such as the total unique number of ontology terms (of the old release) and the total number of mapped and not mapped *altID* ontology terms. In addition, all the found pairs ``alt_id - id`` are also returned. In the example above the anonymous hash is addressed in the output file ``data/chicken.goa.mapped.txt`` whereas the stats are printed on the shell. \n",
    "\n",
    "The difference between the *old* and the *mapped* file can be easily displayed by using the ``diff`` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd data && gunzip -k goa_chicken.gaf.128.gz\n",
    "diff goa_chicken.gaf.128 chicken.goa.mapped.txt > ann.diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, below we show the first 21 lines of the file ``ann.diff``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "diff"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "75c75\n",
    "< UniProtKB A0AVX7  TESC        GO:0072661  GO_REF:0000024  ISS UniProtKB:Q96BS2    P   Calcineurin B homologous protein 3  CHP3_CHICK|TESC|CHP3    protein taxon:9031  20120627    UniProt     \n",
    "---\n",
    "> UniProtKB A0AVX7  TESC        GO:0072659  GO_REF:0000024  ISS UniProtKB:Q96BS2    P   Calcineurin B homologous protein 3  CHP3_CHICK|TESC|CHP3    protein taxon:9031  20120627    UniProt     \n",
    "159c159\n",
    "< UniProtKB A1DYI3  Wnt3        GO:0005578  GO_REF:0000040  IEA UniProtKB-SubCell:SL-0111   C   Protein Wnt A1DYI3_CHICK|Wnt3|WNT3  protein taxon:9031  20160507    UniProt     \n",
    "---\n",
    "> UniProtKB A1DYI3  Wnt3        GO:0031012  GO_REF:0000040  IEA UniProtKB-SubCell:SL-0111   C   Protein Wnt A1DYI3_CHICK|Wnt3|WNT3  protein taxon:9031  20160507    UniProt     \n",
    "234,235c234,235\n",
    "< UniProtKB A1KXM5  SPERT       GO:0016023  GO_REF:0000019  IEA Ensembl:ENSMUSP00000127439  C   Spermatid-associated protein    SPERT_CHICK|SPERT   protein taxon:9031  20160507    Ensembl     \n",
    "< UniProtKB A1XGV6  TNFRSF19        GO:0004872  GO_REF:0000033  IBA PANTHER:PTN000950406    F   Troy-long   A1XGV6_CHICK|TNFRSF19   protein taxon:9031  20160114    GO_Central      \n",
    "---\n",
    "> UniProtKB A1KXM5  SPERT       GO:0031410  GO_REF:0000019  IEA Ensembl:ENSMUSP00000127439  C   Spermatid-associated protein    SPERT_CHICK|SPERT   protein taxon:9031  20160507    Ensembl     \n",
    "> UniProtKB A1XGV6  TNFRSF19        GO:0038023  GO_REF:0000033  IBA PANTHER:PTN000950406    F   Troy-long   A1XGV6_CHICK|TNFRSF19   protein taxon:9031  20160114    GO_Central      \n",
    "268c268\n",
    "< UniProtKB A3F962  MBNL2       GO:0044822  GO_REF:0000019  IEA Ensembl:ENSP00000365861 F   Muscleblind-like 2 isoform 1    A3F962_CHICK|MBNL2  protein taxon:9031  20160507    Ensembl     \n",
    "---\n",
    "> UniProtKB A3F962  MBNL2       GO:0003723  GO_REF:0000019  IEA Ensembl:ENSP00000365861 F   Muscleblind-like 2 isoform 1    A3F962_CHICK|MBNL2  protein taxon:9031  20160507    Ensembl     \n",
    "286c286\n",
    "< UniProtKB A4GTP0  A4GTP0      GO:0044822  GO_REF:0000019  IEA Ensembl:ENSP00000254301 F   Galectin    A4GTP0_CHICK    protein taxon:9031  20160507    Ensembl     \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application to Human Phenotype Ontology (HPO)\n",
    "\n",
    "Here we show how to apply ``OBOparser`` on the ``HPO`` obo file and its annotation file. Here we go fast, because the experiments are carried-out in the same way of those shown above with ``GO``. \n",
    "\n",
    "### Parse the HPO obo file\n",
    "\n",
    "Here we use ``OBOparser`` to handle the ``HPO`` obo file and return some basic statistics. ``HPO`` obo release used in this tutorial: ``03/06/19``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "perl"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "use strict;\n",
    "use warnings;\n",
    "use OBOparser; \n",
    "\n",
    "## create folder where storing example I/O files\n",
    "my $basedir= \"t/data/\";\n",
    "mkdir $basedir unless(-e $basedir);\n",
    "\n",
    "## download HPO obo file\n",
    "my $obofile= $basedir.\"hpo.obo\";\n",
    "my $hpobo= qx{wget --quiet --output-document=$obofile http://purl.obolibrary.org/obo/hp.obo};\n",
    "print \"HPO obo file downloaded: done\\n\\n\";\n",
    "\n",
    "## extract edges from HPO obo file\n",
    "my $hpores= OBOparser::build_edges($obofile);\n",
    "my $hpoedges= $basedir.\"hpo-edges.txt\"; ## hpo edges file declared here \n",
    "open OUT, \"> $hpoedges\"; ## redirect hpo edges on file\n",
    "print OUT \"${$hpores}\"; ## scalar dereferencing\n",
    "close OUT;\n",
    "print \"build HPO edges: done\\n\\n\";\n",
    "\n",
    "## make stats on HPO \n",
    "my ($res, $stat, $parentIndex, $childIndex);\n",
    "($parentIndex, $childIndex)= (0,1);\n",
    "$res= OBOparser::make_stat($hpoedges, $parentIndex, $childIndex);\n",
    "print \"$res\"; ## print stats on shell\n",
    "\n",
    "## results printed on the shell\n",
    "#oboterm <tab> degree <tab> indegree <tab> outdegree\n",
    "HP:0003110  59  2   57\n",
    "HP:0012379  44  1   43\n",
    "HP:0010876  40  1   39\n",
    "HP:0000708  39  1   38\n",
    "HP:0003355  36  1   35\n",
    "HP:0012531  36  1   35\n",
    "HP:0030057  33  1   32\n",
    "HP:0001760  31  1   30\n",
    "HP:0008069  31  2   29\n",
    "HP:0011355  30  1   29\n",
    ".\n",
    ".\n",
    ".\n",
    "~summary stat~\n",
    "nodes: 14468\n",
    "edges: 18312\n",
    "max degree: 59\n",
    "min degree: 1\n",
    "median degree: 1.0000\n",
    "average degree: 1.2657\n",
    "density: 8.7488e-05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the HPO annotation file\n",
    "\n",
    "Here we use ``OBOparser`` to parse the ``HPO`` annotation file (release ``03/06/19``)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "perl"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "## loading OBOparser and useful Perl module\n",
    "use strict;\n",
    "use warnings;\n",
    "use OBOparser; \n",
    "\n",
    "## create folder where storing example I/O files\n",
    "my $basedir= \"t/data/\";\n",
    "mkdir $basedir unless(-e $basedir);\n",
    "\n",
    "## download HPO annotations \n",
    "my $hpofile= $basedir.\"hpo.ann.txt\"; ## hpo annotation file declared here\n",
    "my $hpoann= qx{wget --quiet --output-document=$hpofile http://compbio.charite.de/jenkins/job/hpo.annotations.monthly/lastStableBuild/artifact/annotation/ALL_SOURCES_ALL_FREQUENCIES_genes_to_phenotype.txt};\n",
    "\n",
    "## extract HPO annotations \n",
    "my ($geneindex, $classindex)= (1,3);\n",
    "($res, $stat)= OBOparser::gene2biofun($hpofile, $geneindex, $classindex);\n",
    "my $hpout= $basedir.\"hpo.gene2pheno.txt\"; ## annotation adj list stored in a file\n",
    "open OUT, \"> $hpout\";\n",
    "foreach my $k (sort{$a <=> $b} keys %$res) { print OUT \"$k $$res{$k}\\n\";} ## dereferencing\n",
    "close OUT;\n",
    "print \"${$stat}\\n\";\n",
    "\n",
    "## results printed on the shell\n",
    "genes: 4073\n",
    "ontology terms: 7464"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we show the first ``10`` lines of the ``hpo.gene2pheno.txt`` file, just to give an example of how the returned adjacency list stored in the file ``hpo.gene2pheno.txt``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2M HP:0000006\n",
    "A2ML1 HP:0000768|HP:0001156|HP:0000391|HP:0000520|HP:0001928|HP:0100625|HP:0000407|HP:0011800|HP:0011675|HP:0000028|HP:0002974|HP:0002208|HP:0008872|HP:0000044|HP:0001324|HP:0000179|HP:0007477|HP:0000316|HP:0005692|HP:0002750|HP:0004415|HP:0002240|HP:0000325|HP:0010318|HP:0001743|HP:0000465|HP:0006610|HP:0000218|HP:0002650|HP:0000474|HP:0000347|HP:0000348|HP:0000476|HP:0011869|HP:0011362|HP:0004322|HP:0000995|HP:0001252|HP:0001892|HP:0000486|HP:0001641|HP:0001004|HP:0001260|HP:0000494|HP:0000368|HP:0004209|HP:0002162|HP:0011381|HP:0000508|HP:0000639|HP:0000767\n",
    "A4GALT HP:0000006|HP:0010970\n",
    "AAAS HP:0001347|HP:0008259|HP:0007556|HP:0000007|HP:0011463|HP:0000648|HP:0002376|HP:0000649|HP:0000522|HP:0002571|HP:0000972|HP:0000846|HP:0007440|HP:0001430|HP:0000982|HP:0000407|HP:0007002|HP:0003676|HP:0003487|HP:0004319|HP:0001761|HP:0001249|HP:0004322|HP:0001250|HP:0001251|HP:0008163|HP:0000612|HP:0001252|HP:0001324|HP:0001260|HP:0012332|HP:0002093|HP:0001263|HP:0010486|HP:0000505|HP:0000953|HP:0000252|HP:0009916|HP:0000830|HP:0001278\n",
    "AAGAB HP:0003584|HP:0040162|HP:0025092|HP:0000006|HP:0007530|HP:0002894|HP:0005584|HP:0001425|HP:0006740|HP:0000982|HP:0003002|HP:0025114|HP:0003003|HP:0001597|HP:0012189\n",
    "AARS HP:0003202|HP:0000643|HP:0001284|HP:0000006|HP:0000007|HP:0000648|HP:0001290|HP:0002059|HP:0002827|HP:0002317|HP:0002063|HP:0001298|HP:0003477|HP:0001558|HP:0000407|HP:0002072|HP:0002460|HP:0000668|HP:0012447|HP:0000546|HP:0002355|HP:0100660|HP:0001336|HP:0001337|HP:0011968|HP:0009027|HP:0200134|HP:0002376|HP:0000717|HP:0002509|HP:0002133|HP:0002521|HP:0000348|HP:0010844|HP:0001761|HP:0001249|HP:0004322|HP:0001250|HP:0001251|HP:0002020|HP:0001508|HP:0001765|HP:0003429|HP:0009830|HP:0003431|HP:0100710|HP:0001511|HP:0001257|HP:0007018|HP:0000750|HP:0000494|HP:0001263|HP:0001265|HP:0003828|HP:0001268|HP:0002421|HP:0002936|HP:0000504|HP:0001273|HP:0003577|HP:0000508|HP:0000252|HP:0000639\n",
    "AARS2 HP:0002371|HP:0006980|HP:0002180|HP:0000007|HP:0002186|HP:0000716|HP:0008209|HP:0000726|HP:0003676|HP:0001251|HP:0001508|HP:0001639|HP:0002151|HP:0001257|HP:0002089|HP:0001260|HP:0002353|HP:0001522|HP:0001332|HP:0001272|HP:0003128|HP:0001337|HP:0006970|HP:0003324|HP:0000639\n",
    "AASS HP:0000736|HP:0001249|HP:0003297|HP:0001250|HP:0004322|HP:0001252|HP:0000007|HP:0001256|HP:0003593|HP:0000750|HP:0001903|HP:0002927|HP:0000752|HP:0001264|HP:0002161|HP:0002353|HP:0000119|HP:0001083|HP:0100543\n",
    "ABAT HP:0001250|HP:0000098|HP:0001347|HP:0001254|HP:0000007|HP:0001321|HP:0003819|HP:0025356|HP:0006829|HP:0000494|HP:0002415|HP:0001263|HP:0000278|HP:0025430|HP:0001274|HP:0007291\n",
    "ABCA1 HP:0002240|HP:0003457|HP:0100546|HP:0003396|HP:0001349|HP:0000006|HP:0000007|HP:0025608|HP:0003146|HP:0010829|HP:0001677|HP:0004943|HP:0007759|HP:0000656|HP:0001744|HP:0001873|HP:0008404|HP:0003477|HP:0007957|HP:0004374|HP:0011096|HP:0001433|HP:0005145|HP:0002460|HP:0002716|HP:0007133|HP:0030814|HP:0000991|HP:0007328|HP:0003233|HP:0002730|HP:0002155|HP:0002027|HP:0003693|HP:0000622|HP:0001903|HP:0001712|HP:0001392|HP:0001265|HP:0002164|HP:0006901|HP:0000505|HP:0001658|HP:0005181|HP:0000958\n",
    "\n",
    "... to be continued ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map HPO terms between releases\n",
    "\n",
    "Here we use ``OBOparser`` to map ``HPO`` terms between release. ``HPO`` old release used in this tutorial: ``09/03/18``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "perl"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "use strict;\n",
    "use warnings;\n",
    "use OBOparser; \n",
    "\n",
    "## create folder where storing example I/O files\n",
    "my $basedir= \"t/data/\";\n",
    "mkdir $basedir unless(-e $basedir);\n",
    "\n",
    "## download HPO obo file\n",
    "my $obofile= $basedir.\"hpo.obo\";\n",
    "my $hpobo= qx{wget --quiet --output-document=$obofile http://purl.obolibrary.org/obo/hp.obo};\n",
    "print \"HPO obo file downloaded: done\\n\\n\";\n",
    "\n",
    "## download HPO annotation file\n",
    "my $hpofileOld= $basedir.\"hpo.ann.old.txt\"; ## goa annotation file declared here\n",
    "my $hpold= qx{wget --quiet --output-document=$hpofileOld http://compbio.charite.de/jenkins/job/hpo.annotations.monthly/139/artifact/annotation/ALL_SOURCES_ALL_FREQUENCIES_genes_to_phenotype.txt};\n",
    "\n",
    "## map HPO terms between release\n",
    "my $classindex= 3;\n",
    "my ($res, $stat)= OBOparser::map_OBOterm_between_release($obofile, $hpofileOld, $classindex);\n",
    "my $mapfile= $basedir.\"hpo.ann.mapped.txt\";\n",
    "open OUT, \"> $mapfile\"; ## mapped annotation stored in a file\n",
    "print OUT \"${$res}\";\n",
    "close OUT;\n",
    "print \"${$stat}\";\n",
    "\n",
    "## results printed on shell\n",
    "#alt-id <tab> id\n",
    "HP:0000487  HP:0000486\n",
    "HP:0000547  HP:0000510\n",
    "HP:0000655  HP:0007773\n",
    "HP:0000833  HP:0001952\n",
    "HP:0001226  HP:0006121\n",
    "HP:0001322  HP:0006872\n",
    "HP:0001472  HP:0001426\n",
    "HP:0001862  HP:0006121\n",
    "HP:0002271  HP:0012332\n",
    "HP:0002281  HP:0002282\n",
    "HP:0002459  HP:0012332\n",
    "HP:0003464  HP:0003107\n",
    "HP:0003490  HP:0003150\n",
    "HP:0005130  HP:0001723\n",
    "HP:0005364  HP:0004429\n",
    "HP:0005901  HP:0002754\n",
    "HP:0006830  HP:0001319\n",
    "HP:0007314  HP:0002282\n",
    "HP:0007713  HP:0010920\n",
    "HP:0007758  HP:0000505\n",
    "HP:0007868  HP:0000608\n",
    "HP:0007893  HP:0000546\n",
    "HP:0008012  HP:0000545\n",
    "HP:0008024  HP:0100018\n",
    "HP:0008230  HP:0040171\n",
    "HP:0010700  HP:0000518\n",
    "HP:0011146  HP:0002384\n",
    "HP:0012201  HP:0008151\n",
    "HP:0045016  HP:0003455\n",
    "\n",
    "Tot. ontology terms:    6789\n",
    "Tot. altID: 3631\n",
    "Tot. altID seen:    29\n",
    "Tot. altID unseen:  3602"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running the ``diff`` command between ``hpo.ann.old.txt`` and ``hpo.ann.mapped.txt`` file and saving the output on a file (e.g.: ``diff hpo.ann.old.txt hpo.ann.mapped.txt > hpo.ann.diff``) we can easily see the ``HPO`` terms changed between the two release. Below we show just some few lines of ``hpo.ann.diff``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "diff"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "1148c1148\n",
    "< 51    ACOX1   Tapetoretinal degeneration  HP:0000547\n",
    "---\n",
    "> 51    ACOX1   Tapetoretinal degeneration  HP:0000510\n",
    "3423c3423\n",
    "< 190   NR0B1   Decreased testosterone in males HP:0008230\n",
    "---\n",
    "> 190   NR0B1   Decreased testosterone in males HP:0040171\n",
    "4041c4041\n",
    "< 212   ALAS2   Glucose intolerance HP:0000833\n",
    "---\n",
    "> 212   ALAS2   Glucose intolerance HP:0001952\n",
    "5049c5049\n",
    "< 8481  OFD1    Gray matter heterotopias    HP:0002281\n",
    "---\n",
    "> 8481  OFD1    Gray matter heterotopias    HP:0002282\n",
    "6597c6597\n",
    "< 57724 EPG5    White matter neuronal heterotopia   HP:0007314\n",
    "---\n",
    "> 57724 EPG5    White matter neuronal heterotopia   HP:0002282\n",
    "7244c7244"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
