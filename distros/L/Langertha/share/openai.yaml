components:
  schemas:
    AssistantObject:
      description: Represents an `assistant` that can call the model and use tools.
      properties:
        created_at:
          description: The Unix timestamp (in seconds) for when the assistant was
            created.
          type: integer
        description:
          description: 'The description of the assistant. The maximum length is 512
            characters.

            '
          maxLength: 512
          type:
          - string
          - 'null'
        id:
          description: The identifier, which can be referenced in API endpoints.
          type: string
        instructions:
          description: 'The system instructions that the assistant uses. The maximum
            length is 256,000 characters.

            '
          maxLength: 256000
          type:
          - string
          - 'null'
        metadata:
          description: 'Set of 16 key-value pairs that can be attached to an object.
            This can be useful for storing additional information about the object
            in a structured format. Keys can be a maximum of 64 characters long and
            values can be a maxium of 512 characters long.

            '
          type:
          - object
          - 'null'
          x-oaiTypeLabel: map
        model:
          description: 'ID of the model to use. You can use the [List models](/docs/api-reference/models/list)
            API to see all of your available models, or see our [Model overview](/docs/models/overview)
            for descriptions of them.

            '
          type: string
        name:
          description: 'The name of the assistant. The maximum length is 256 characters.

            '
          maxLength: 256
          type:
          - string
          - 'null'
        object:
          description: The object type, which is always `assistant`.
          enum:
          - assistant
          type: string
        response_format:
          $ref: '#/components/schemas/AssistantsApiResponseFormatOption'
        temperature:
          default: 1
          description: 'What sampling temperature to use, between 0 and 2. Higher
            values like 0.8 will make the output more random, while lower values like
            0.2 will make it more focused and deterministic.

            '
          example: 1
          maximum: 2
          minimum: 0
          type:
          - number
          - 'null'
        tool_resources:
          description: 'A set of resources that are used by the assistant''s tools.
            The resources are specific to the type of tool. For example, the `code_interpreter`
            tool requires a list of file IDs, while the `file_search` tool requires
            a list of vector store IDs.

            '
          properties:
            code_interpreter:
              properties:
                file_ids:
                  default: []
                  description: 'A list of [file](/docs/api-reference/files) IDs made
                    available to the `code_interpreter`` tool. There can be a maximum
                    of 20 files associated with the tool.

                    '
                  items:
                    type: string
                  maxItems: 20
                  type: array
              type: object
            file_search:
              properties:
                vector_store_ids:
                  description: 'The ID of the [vector store](/docs/api-reference/vector-stores/object)
                    attached to this assistant. There can be a maximum of 1 vector
                    store attached to the assistant.

                    '
                  items:
                    type: string
                  maxItems: 1
                  type: array
              type: object
          type:
          - object
          - 'null'
        tools:
          default: []
          description: 'A list of tool enabled on the assistant. There can be a maximum
            of 128 tools per assistant. Tools can be of types `code_interpreter`,
            `file_search`, or `function`.

            '
          items:
            oneOf:
            - $ref: '#/components/schemas/AssistantToolsCode'
            - $ref: '#/components/schemas/AssistantToolsFileSearch'
            - $ref: '#/components/schemas/AssistantToolsFunction'
            x-oaiExpandable: true
          maxItems: 128
          type: array
        top_p:
          default: 1
          description: 'An alternative to sampling with temperature, called nucleus
            sampling, where the model considers the results of the tokens with top_p
            probability mass. So 0.1 means only the tokens comprising the top 10%
            probability mass are considered.


            We generally recommend altering this or temperature but not both.

            '
          example: 1
          maximum: 1
          minimum: 0
          type:
          - number
          - 'null'
      required:
      - id
      - object
      - created_at
      - name
      - description
      - model
      - instructions
      - tools
      - metadata
      title: Assistant
      type: object
      x-oaiMeta:
        beta: true
        example: "{\n  \"id\": \"asst_abc123\",\n  \"object\": \"assistant\",\n  \"\
          created_at\": 1698984975,\n  \"name\": \"Math Tutor\",\n  \"description\"\
          : null,\n  \"model\": \"gpt-4-turbo\",\n  \"instructions\": \"You are a\
          \ personal math tutor. When asked a question, write and run Python code\
          \ to answer the question.\",\n  \"tools\": [\n    {\n      \"type\": \"\
          code_interpreter\"\n    }\n  ],\n  \"metadata\": {},\n  \"top_p\": 1.0,\n\
          \  \"temperature\": 1.0,\n  \"response_format\": \"auto\"\n}\n"
        name: The assistant object
    AssistantStreamEvent:
      description: 'Represents an event emitted when streaming a Run.


        Each event in a server-sent events stream has an `event` and `data` property:


        ```

        event: thread.created

        data: {"id": "thread_123", "object": "thread", ...}

        ```


        We emit events whenever a new object is created, transitions to a new state,
        or is being

        streamed in parts (deltas). For example, we emit `thread.run.created` when
        a new run

        is created, `thread.run.completed` when a run completes, and so on. When an
        Assistant chooses

        to create a message during a run, we emit a `thread.message.created event`,
        a

        `thread.message.in_progress` event, many `thread.message.delta` events, and
        finally a

        `thread.message.completed` event.


        We may add additional events over time, so we recommend handling unknown events
        gracefully

        in your code. See the [Assistants API quickstart](/docs/assistants/overview)
        to learn how to

        integrate the Assistants API with streaming.

        '
      oneOf:
      - $ref: '#/components/schemas/ThreadStreamEvent'
      - $ref: '#/components/schemas/RunStreamEvent'
      - $ref: '#/components/schemas/RunStepStreamEvent'
      - $ref: '#/components/schemas/MessageStreamEvent'
      - $ref: '#/components/schemas/ErrorEvent'
      - $ref: '#/components/schemas/DoneEvent'
      x-oaiMeta:
        beta: true
        name: Assistant stream events
    AssistantToolsCode:
      properties:
        type:
          description: 'The type of tool being defined: `code_interpreter`'
          enum:
          - code_interpreter
          type: string
      required:
      - type
      title: Code interpreter tool
      type: object
    AssistantToolsFileSearch:
      properties:
        file_search:
          description: Overrides for the file search tool.
          properties:
            max_num_results:
              description: 'The maximum number of results the file search tool should
                output. The default is 20 for gpt-4* models and 5 for gpt-3.5-turbo.
                This number should be between 1 and 50 inclusive.


                Note that the file search tool may output fewer than `max_num_results`
                results. See the [file search tool documentation](/docs/assistants/tools/file-search/number-of-chunks-returned)
                for more information.

                '
              maximum: 50
              minimum: 1
              type: integer
          type: object
        type:
          description: 'The type of tool being defined: `file_search`'
          enum:
          - file_search
          type: string
      required:
      - type
      title: FileSearch tool
      type: object
    AssistantToolsFileSearchTypeOnly:
      properties:
        type:
          description: 'The type of tool being defined: `file_search`'
          enum:
          - file_search
          type: string
      required:
      - type
      title: FileSearch tool
      type: object
    AssistantToolsFunction:
      properties:
        function:
          $ref: '#/components/schemas/FunctionObject'
        type:
          description: 'The type of tool being defined: `function`'
          enum:
          - function
          type: string
      required:
      - type
      - function
      title: Function tool
      type: object
    AssistantsApiResponseFormat:
      description: 'An object describing the expected output of the model. If `json_object`
        only `function` type `tools` are allowed to be passed to the Run. If `text`
        the model can return text or any value needed.

        '
      properties:
        type:
          default: text
          description: Must be one of `text` or `json_object`.
          enum:
          - text
          - json_object
          example: json_object
          type: string
      type: object
    AssistantsApiResponseFormatOption:
      description: 'Specifies the format that the model must output. Compatible with
        [GPT-4o](/docs/models/gpt-4o), [GPT-4 Turbo](/docs/models/gpt-4-turbo-and-gpt-4),
        and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.


        Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees
        the message the model generates is valid JSON.


        **Important:** when using JSON mode, you **must** also instruct the model
        to produce JSON yourself via a system or user message. Without this, the model
        may generate an unending stream of whitespace until the generation reaches
        the token limit, resulting in a long-running and seemingly "stuck" request.
        Also note that the message content may be partially cut off if `finish_reason="length"`,
        which indicates the generation exceeded `max_tokens` or the conversation exceeded
        the max context length.

        '
      oneOf:
      - description: '`auto` is the default value

          '
        enum:
        - none
        - auto
        type: string
      - $ref: '#/components/schemas/AssistantsApiResponseFormat'
      x-oaiExpandable: true
    AssistantsApiToolChoiceOption:
      description: 'Controls which (if any) tool is called by the model.

        `none` means the model will not call any tools and instead generates a message.

        `auto` is the default value and means the model can pick between generating
        a message or calling one or more tools.

        `required` means the model must call one or more tools before responding to
        the user.

        Specifying a particular tool like `{"type": "file_search"}` or `{"type": "function",
        "function": {"name": "my_function"}}` forces the model to call that tool.

        '
      oneOf:
      - description: '`none` means the model will not call any tools and instead generates
          a message. `auto` means the model can pick between generating a message
          or calling one or more tools. `required` means the model must call one or
          more tools before responding to the user.

          '
        enum:
        - none
        - auto
        - required
        type: string
      - $ref: '#/components/schemas/AssistantsNamedToolChoice'
      x-oaiExpandable: true
    AssistantsNamedToolChoice:
      description: Specifies a tool the model should use. Use to force the model to
        call a specific tool.
      properties:
        function:
          properties:
            name:
              description: The name of the function to call.
              type: string
          required:
          - name
          type: object
        type:
          description: The type of the tool. If type is `function`, the function name
            must be set
          enum:
          - function
          - code_interpreter
          - file_search
          type: string
      required:
      - type
      type: object
    AutoChunkingStrategyRequestParam:
      additionalProperties: false
      description: The default strategy. This strategy currently uses a `max_chunk_size_tokens`
        of `800` and `chunk_overlap_tokens` of `400`.
      properties:
        type:
          description: Always `auto`.
          enum:
          - auto
          type: string
      required:
      - type
      title: Auto Chunking Strategy
      type: object
    Batch:
      properties:
        cancelled_at:
          description: The Unix timestamp (in seconds) for when the batch was cancelled.
          type: integer
        cancelling_at:
          description: The Unix timestamp (in seconds) for when the batch started
            cancelling.
          type: integer
        completed_at:
          description: The Unix timestamp (in seconds) for when the batch was completed.
          type: integer
        completion_window:
          description: The time frame within which the batch should be processed.
          type: string
        created_at:
          description: The Unix timestamp (in seconds) for when the batch was created.
          type: integer
        endpoint:
          description: The OpenAI API endpoint used by the batch.
          type: string
        error_file_id:
          description: The ID of the file containing the outputs of requests with
            errors.
          type: string
        errors:
          properties:
            data:
              items:
                properties:
                  code:
                    description: An error code identifying the error type.
                    type: string
                  line:
                    description: The line number of the input file where the error
                      occurred, if applicable.
                    type:
                    - integer
                    - 'null'
                  message:
                    description: A human-readable message providing more details about
                      the error.
                    type: string
                  param:
                    description: The name of the parameter that caused the error,
                      if applicable.
                    type:
                    - string
                    - 'null'
                type: object
              type: array
            object:
              description: The object type, which is always `list`.
              type: string
          type: object
        expired_at:
          description: The Unix timestamp (in seconds) for when the batch expired.
          type: integer
        expires_at:
          description: The Unix timestamp (in seconds) for when the batch will expire.
          type: integer
        failed_at:
          description: The Unix timestamp (in seconds) for when the batch failed.
          type: integer
        finalizing_at:
          description: The Unix timestamp (in seconds) for when the batch started
            finalizing.
          type: integer
        id:
          type: string
        in_progress_at:
          description: The Unix timestamp (in seconds) for when the batch started
            processing.
          type: integer
        input_file_id:
          description: The ID of the input file for the batch.
          type: string
        metadata:
          description: 'Set of 16 key-value pairs that can be attached to an object.
            This can be useful for storing additional information about the object
            in a structured format. Keys can be a maximum of 64 characters long and
            values can be a maxium of 512 characters long.

            '
          type:
          - object
          - 'null'
          x-oaiTypeLabel: map
        object:
          description: The object type, which is always `batch`.
          enum:
          - batch
          type: string
        output_file_id:
          description: The ID of the file containing the outputs of successfully executed
            requests.
          type: string
        request_counts:
          description: The request counts for different statuses within the batch.
          properties:
            completed:
              description: Number of requests that have been completed successfully.
              type: integer
            failed:
              description: Number of requests that have failed.
              type: integer
            total:
              description: Total number of requests in the batch.
              type: integer
          required:
          - total
          - completed
          - failed
          type: object
        status:
          description: The current status of the batch.
          enum:
          - validating
          - failed
          - in_progress
          - finalizing
          - completed
          - expired
          - cancelling
          - cancelled
          type: string
      required:
      - id
      - object
      - endpoint
      - input_file_id
      - completion_window
      - status
      - created_at
      type: object
      x-oaiMeta:
        example: "{\n  \"id\": \"batch_abc123\",\n  \"object\": \"batch\",\n  \"endpoint\"\
          : \"/v1/completions\",\n  \"errors\": null,\n  \"input_file_id\": \"file-abc123\"\
          ,\n  \"completion_window\": \"24h\",\n  \"status\": \"completed\",\n  \"\
          output_file_id\": \"file-cvaTdG\",\n  \"error_file_id\": \"file-HOWS94\"\
          ,\n  \"created_at\": 1711471533,\n  \"in_progress_at\": 1711471538,\n  \"\
          expires_at\": 1711557933,\n  \"finalizing_at\": 1711493133,\n  \"completed_at\"\
          : 1711493163,\n  \"failed_at\": null,\n  \"expired_at\": null,\n  \"cancelling_at\"\
          : null,\n  \"cancelled_at\": null,\n  \"request_counts\": {\n    \"total\"\
          : 100,\n    \"completed\": 95,\n    \"failed\": 5\n  },\n  \"metadata\"\
          : {\n    \"customer_id\": \"user_123456789\",\n    \"batch_description\"\
          : \"Nightly eval job\",\n  }\n}\n"
        name: The batch object
    BatchRequestInput:
      description: The per-line object of the batch input file
      properties:
        custom_id:
          description: A developer-provided per-request id that will be used to match
            outputs to inputs. Must be unique for each request in a batch.
          type: string
        method:
          description: The HTTP method to be used for the request. Currently only
            `POST` is supported.
          enum:
          - POST
          type: string
        url:
          description: The OpenAI API relative URL to be used for the request. Currently
            `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are supported.
          type: string
      type: object
      x-oaiMeta:
        example: '{"custom_id": "request-1", "method": "POST", "url": "/v1/chat/completions",
          "body": {"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content":
          "You are a helpful assistant."}, {"role": "user", "content": "What is 2+2?"}]}}

          '
        name: The request input object
    BatchRequestOutput:
      description: The per-line object of the batch output and error files
      properties:
        custom_id:
          description: A developer-provided per-request id that will be used to match
            outputs to inputs.
          type: string
        error:
          description: For requests that failed with a non-HTTP error, this will contain
            more information on the cause of the failure.
          properties:
            code:
              description: A machine-readable error code.
              type: string
            message:
              description: A human-readable error message.
              type: string
          type:
          - object
          - 'null'
        id:
          type: string
        response:
          properties:
            body:
              description: The JSON body of the response
              type: object
              x-oaiTypeLabel: map
            request_id:
              description: An unique identifier for the OpenAI API request. Please
                include this request ID when contacting support.
              type: string
            status_code:
              description: The HTTP status code of the response
              type: integer
          type:
          - object
          - 'null'
      type: object
      x-oaiMeta:
        example: '{"id": "batch_req_wnaDys", "custom_id": "request-2", "response":
          {"status_code": 200, "request_id": "req_c187b3", "body": {"id": "chatcmpl-9758Iw",
          "object": "chat.completion", "created": 1711475054, "model": "gpt-3.5-turbo",
          "choices": [{"index": 0, "message": {"role": "assistant", "content": "2
          + 2 equals 4."}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 24,
          "completion_tokens": 15, "total_tokens": 39}, "system_fingerprint": null}},
          "error": null}

          '
        name: The request output object
    ChatCompletionFunctionCallOption:
      description: 'Specifying a particular function via `{"name": "my_function"}`
        forces the model to call that function.

        '
      properties:
        name:
          description: The name of the function to call.
          type: string
      required:
      - name
      type: object
    ChatCompletionFunctions:
      deprecated: true
      properties:
        description:
          description: A description of what the function does, used by the model
            to choose when and how to call the function.
          type: string
        name:
          description: The name of the function to be called. Must be a-z, A-Z, 0-9,
            or contain underscores and dashes, with a maximum length of 64.
          type: string
        parameters:
          $ref: '#/components/schemas/FunctionParameters'
      required:
      - name
      type: object
    ChatCompletionMessageToolCall:
      properties:
        function:
          description: The function that the model called.
          properties:
            arguments:
              description: The arguments to call the function with, as generated by
                the model in JSON format. Note that the model does not always generate
                valid JSON, and may hallucinate parameters not defined by your function
                schema. Validate the arguments in your code before calling your function.
              type: string
            name:
              description: The name of the function to call.
              type: string
          required:
          - name
          - arguments
          type: object
        id:
          description: The ID of the tool call.
          type: string
        type:
          description: The type of the tool. Currently, only `function` is supported.
          enum:
          - function
          type: string
      required:
      - id
      - type
      - function
      type: object
    ChatCompletionMessageToolCallChunk:
      properties:
        function:
          properties:
            arguments:
              description: The arguments to call the function with, as generated by
                the model in JSON format. Note that the model does not always generate
                valid JSON, and may hallucinate parameters not defined by your function
                schema. Validate the arguments in your code before calling your function.
              type: string
            name:
              description: The name of the function to call.
              type: string
          type: object
        id:
          description: The ID of the tool call.
          type: string
        index:
          type: integer
        type:
          description: The type of the tool. Currently, only `function` is supported.
          enum:
          - function
          type: string
      required:
      - index
      type: object
    ChatCompletionMessageToolCalls:
      description: The tool calls generated by the model, such as function calls.
      items:
        $ref: '#/components/schemas/ChatCompletionMessageToolCall'
      type: array
    ChatCompletionNamedToolChoice:
      description: Specifies a tool the model should use. Use to force the model to
        call a specific function.
      properties:
        function:
          properties:
            name:
              description: The name of the function to call.
              type: string
          required:
          - name
          type: object
        type:
          description: The type of the tool. Currently, only `function` is supported.
          enum:
          - function
          type: string
      required:
      - type
      - function
      type: object
    ChatCompletionRequestAssistantMessage:
      properties:
        content:
          description: 'The contents of the assistant message. Required unless `tool_calls`
            or `function_call` is specified.

            '
          type:
          - string
          - 'null'
        function_call:
          deprecated: true
          description: Deprecated and replaced by `tool_calls`. The name and arguments
            of a function that should be called, as generated by the model.
          properties:
            arguments:
              description: The arguments to call the function with, as generated by
                the model in JSON format. Note that the model does not always generate
                valid JSON, and may hallucinate parameters not defined by your function
                schema. Validate the arguments in your code before calling your function.
              type: string
            name:
              description: The name of the function to call.
              type: string
          required:
          - arguments
          - name
          type:
          - object
          - 'null'
        name:
          description: An optional name for the participant. Provides the model information
            to differentiate between participants of the same role.
          type: string
        role:
          description: The role of the messages author, in this case `assistant`.
          enum:
          - assistant
          type: string
        tool_calls:
          $ref: '#/components/schemas/ChatCompletionMessageToolCalls'
      required:
      - role
      title: Assistant message
      type: object
    ChatCompletionRequestFunctionMessage:
      deprecated: true
      properties:
        content:
          description: The contents of the function message.
          type:
          - string
          - 'null'
        name:
          description: The name of the function to call.
          type: string
        role:
          description: The role of the messages author, in this case `function`.
          enum:
          - function
          type: string
      required:
      - role
      - content
      - name
      title: Function message
      type: object
    ChatCompletionRequestMessage:
      oneOf:
      - $ref: '#/components/schemas/ChatCompletionRequestSystemMessage'
      - $ref: '#/components/schemas/ChatCompletionRequestUserMessage'
      - $ref: '#/components/schemas/ChatCompletionRequestAssistantMessage'
      - $ref: '#/components/schemas/ChatCompletionRequestToolMessage'
      - $ref: '#/components/schemas/ChatCompletionRequestFunctionMessage'
      x-oaiExpandable: true
    ChatCompletionRequestMessageContentPart:
      oneOf:
      - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartText'
      - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartImage'
      x-oaiExpandable: true
    ChatCompletionRequestMessageContentPartImage:
      properties:
        image_url:
          properties:
            detail:
              default: auto
              description: Specifies the detail level of the image. Learn more in
                the [Vision guide](/docs/guides/vision/low-or-high-fidelity-image-understanding).
              enum:
              - auto
              - low
              - high
              type: string
            url:
              description: Either a URL of the image or the base64 encoded image data.
              format: uri
              type: string
          required:
          - url
          type: object
        type:
          description: The type of the content part.
          enum:
          - image_url
          type: string
      required:
      - type
      - image_url
      title: Image content part
      type: object
    ChatCompletionRequestMessageContentPartText:
      properties:
        text:
          description: The text content.
          type: string
        type:
          description: The type of the content part.
          enum:
          - text
          type: string
      required:
      - type
      - text
      title: Text content part
      type: object
    ChatCompletionRequestSystemMessage:
      properties:
        content:
          description: The contents of the system message.
          type: string
        name:
          description: An optional name for the participant. Provides the model information
            to differentiate between participants of the same role.
          type: string
        role:
          description: The role of the messages author, in this case `system`.
          enum:
          - system
          type: string
      required:
      - content
      - role
      title: System message
      type: object
    ChatCompletionRequestToolMessage:
      properties:
        content:
          description: The contents of the tool message.
          type: string
        role:
          description: The role of the messages author, in this case `tool`.
          enum:
          - tool
          type: string
        tool_call_id:
          description: Tool call that this message is responding to.
          type: string
      required:
      - role
      - content
      - tool_call_id
      title: Tool message
      type: object
    ChatCompletionRequestUserMessage:
      properties:
        content:
          description: 'The contents of the user message.

            '
          oneOf:
          - description: The text contents of the message.
            title: Text content
            type: string
          - description: An array of content parts with a defined type, each can be
              of type `text` or `image_url` when passing in images. You can pass multiple
              images by adding multiple `image_url` content parts. Image input is
              only supported when using the `gpt-4-visual-preview` model.
            items:
              $ref: '#/components/schemas/ChatCompletionRequestMessageContentPart'
            minItems: 1
            title: Array of content parts
            type: array
          x-oaiExpandable: true
        name:
          description: An optional name for the participant. Provides the model information
            to differentiate between participants of the same role.
          type: string
        role:
          description: The role of the messages author, in this case `user`.
          enum:
          - user
          type: string
      required:
      - content
      - role
      title: User message
      type: object
    ChatCompletionResponseMessage:
      description: A chat completion message generated by the model.
      properties:
        content:
          description: The contents of the message.
          type:
          - string
          - 'null'
        function_call:
          deprecated: true
          description: Deprecated and replaced by `tool_calls`. The name and arguments
            of a function that should be called, as generated by the model.
          properties:
            arguments:
              description: The arguments to call the function with, as generated by
                the model in JSON format. Note that the model does not always generate
                valid JSON, and may hallucinate parameters not defined by your function
                schema. Validate the arguments in your code before calling your function.
              type: string
            name:
              description: The name of the function to call.
              type: string
          required:
          - name
          - arguments
          type: object
        role:
          description: The role of the author of this message.
          enum:
          - assistant
          type: string
        tool_calls:
          $ref: '#/components/schemas/ChatCompletionMessageToolCalls'
      required:
      - role
      - content
      type: object
    ChatCompletionRole:
      description: The role of the author of a message
      enum:
      - system
      - user
      - assistant
      - tool
      - function
      type: string
    ChatCompletionStreamOptions:
      default: null
      description: 'Options for streaming response. Only set this when you set `stream:
        true`.

        '
      properties:
        include_usage:
          description: 'If set, an additional chunk will be streamed before the `data:
            [DONE]` message. The `usage` field on this chunk shows the token usage
            statistics for the entire request, and the `choices` field will always
            be an empty array. All other chunks will also include a `usage` field,
            but with a null value.

            '
          type: boolean
      type:
      - object
      - 'null'
    ChatCompletionStreamResponseDelta:
      description: A chat completion delta generated by streamed model responses.
      properties:
        content:
          description: The contents of the chunk message.
          type:
          - string
          - 'null'
        function_call:
          deprecated: true
          description: Deprecated and replaced by `tool_calls`. The name and arguments
            of a function that should be called, as generated by the model.
          properties:
            arguments:
              description: The arguments to call the function with, as generated by
                the model in JSON format. Note that the model does not always generate
                valid JSON, and may hallucinate parameters not defined by your function
                schema. Validate the arguments in your code before calling your function.
              type: string
            name:
              description: The name of the function to call.
              type: string
          type: object
        role:
          description: The role of the author of this message.
          enum:
          - system
          - user
          - assistant
          - tool
          type: string
        tool_calls:
          items:
            $ref: '#/components/schemas/ChatCompletionMessageToolCallChunk'
          type: array
      type: object
    ChatCompletionTokenLogprob:
      properties:
        bytes: &id001
          description: A list of integers representing the UTF-8 bytes representation
            of the token. Useful in instances where characters are represented by
            multiple tokens and their byte representations must be combined to generate
            the correct text representation. Can be `null` if there is no bytes representation
            for the token.
          items:
            type: integer
          type:
          - array
          - 'null'
        logprob: &id002
          description: The log probability of this token, if it is within the top
            20 most likely tokens. Otherwise, the value `-9999.0` is used to signify
            that the token is very unlikely.
          type: number
        token: &id003
          description: The token.
          type: string
        top_logprobs:
          description: List of the most likely tokens and their log probability, at
            this token position. In rare cases, there may be fewer than the number
            of requested `top_logprobs` returned.
          items:
            properties:
              bytes: *id001
              logprob: *id002
              token: *id003
            required:
            - token
            - logprob
            - bytes
            type: object
          type: array
      required:
      - token
      - logprob
      - bytes
      - top_logprobs
      type: object
    ChatCompletionTool:
      properties:
        function:
          $ref: '#/components/schemas/FunctionObject'
        type:
          description: The type of the tool. Currently, only `function` is supported.
          enum:
          - function
          type: string
      required:
      - type
      - function
      type: object
    ChatCompletionToolChoiceOption:
      description: 'Controls which (if any) tool is called by the model.

        `none` means the model will not call any tool and instead generates a message.

        `auto` means the model can pick between generating a message or calling one
        or more tools.

        `required` means the model must call one or more tools.

        Specifying a particular tool via `{"type": "function", "function": {"name":
        "my_function"}}` forces the model to call that tool.


        `none` is the default when no tools are present. `auto` is the default if
        tools are present.

        '
      oneOf:
      - description: '`none` means the model will not call any tool and instead generates
          a message. `auto` means the model can pick between generating a message
          or calling one or more tools. `required` means the model must call one or
          more tools.

          '
        enum:
        - none
        - auto
        - required
        type: string
      - $ref: '#/components/schemas/ChatCompletionNamedToolChoice'
      x-oaiExpandable: true
    ChunkingStrategyRequestParam:
      description: The chunking strategy used to chunk the file(s). If not set, will
        use the `auto` strategy.
      oneOf:
      - $ref: '#/components/schemas/AutoChunkingStrategyRequestParam'
      - $ref: '#/components/schemas/StaticChunkingStrategyRequestParam'
      type: object
      x-oaiExpandable: true
    CompletionUsage:
      description: Usage statistics for the completion request.
      properties:
        completion_tokens:
          description: Number of tokens in the generated completion.
          type: integer
        prompt_tokens:
          description: Number of tokens in the prompt.
          type: integer
        total_tokens:
          description: Total number of tokens used in the request (prompt + completion).
          type: integer
      required:
      - prompt_tokens
      - completion_tokens
      - total_tokens
      type: object
    CreateAssistantRequest:
      additionalProperties: false
      properties:
        description:
          description: 'The description of the assistant. The maximum length is 512
            characters.

            '
          maxLength: 512
          type:
          - string
          - 'null'
        instructions:
          description: 'The system instructions that the assistant uses. The maximum
            length is 256,000 characters.

            '
          maxLength: 256000
          type:
          - string
          - 'null'
        metadata:
          description: 'Set of 16 key-value pairs that can be attached to an object.
            This can be useful for storing additional information about the object
            in a structured format. Keys can be a maximum of 64 characters long and
            values can be a maxium of 512 characters long.

            '
          type:
          - object
          - 'null'
          x-oaiTypeLabel: map
        model:
          anyOf:
          - type: string
          - enum:
            - gpt-4o
            - gpt-4o-2024-05-13
            - gpt-4-turbo
            - gpt-4-turbo-2024-04-09
            - gpt-4-0125-preview
            - gpt-4-turbo-preview
            - gpt-4-1106-preview
            - gpt-4-vision-preview
            - gpt-4
            - gpt-4-0314
            - gpt-4-0613
            - gpt-4-32k
            - gpt-4-32k-0314
            - gpt-4-32k-0613
            - gpt-3.5-turbo
            - gpt-3.5-turbo-16k
            - gpt-3.5-turbo-0613
            - gpt-3.5-turbo-1106
            - gpt-3.5-turbo-0125
            - gpt-3.5-turbo-16k-0613
            type: string
          description: 'ID of the model to use. You can use the [List models](/docs/api-reference/models/list)
            API to see all of your available models, or see our [Model overview](/docs/models/overview)
            for descriptions of them.

            '
          example: gpt-4-turbo
          x-oaiTypeLabel: string
        name:
          description: 'The name of the assistant. The maximum length is 256 characters.

            '
          maxLength: 256
          type:
          - string
          - 'null'
        response_format:
          $ref: '#/components/schemas/AssistantsApiResponseFormatOption'
        temperature:
          default: 1
          description: 'What sampling temperature to use, between 0 and 2. Higher
            values like 0.8 will make the output more random, while lower values like
            0.2 will make it more focused and deterministic.

            '
          example: 1
          maximum: 2
          minimum: 0
          type:
          - number
          - 'null'
        tool_resources:
          description: 'A set of resources that are used by the assistant''s tools.
            The resources are specific to the type of tool. For example, the `code_interpreter`
            tool requires a list of file IDs, while the `file_search` tool requires
            a list of vector store IDs.

            '
          properties:
            code_interpreter:
              properties:
                file_ids:
                  default: []
                  description: 'A list of [file](/docs/api-reference/files) IDs made
                    available to the `code_interpreter` tool. There can be a maximum
                    of 20 files associated with the tool.

                    '
                  items:
                    type: string
                  maxItems: 20
                  type: array
              type: object
            file_search:
              oneOf:
              - required:
                - vector_store_ids
              - required:
                - vector_stores
              properties:
                vector_store_ids:
                  description: 'The [vector store](/docs/api-reference/vector-stores/object)
                    attached to this assistant. There can be a maximum of 1 vector
                    store attached to the assistant.

                    '
                  items:
                    type: string
                  maxItems: 1
                  type: array
                vector_stores:
                  description: 'A helper to create a [vector store](/docs/api-reference/vector-stores/object)
                    with file_ids and attach it to this assistant. There can be a
                    maximum of 1 vector store attached to the assistant.

                    '
                  items:
                    properties:
                      chunking_strategy:
                        description: The chunking strategy used to chunk the file(s).
                          If not set, will use the `auto` strategy.
                        oneOf:
                        - additionalProperties: false
                          description: The default strategy. This strategy currently
                            uses a `max_chunk_size_tokens` of `800` and `chunk_overlap_tokens`
                            of `400`.
                          properties:
                            type:
                              description: Always `auto`.
                              enum:
                              - auto
                              type: string
                          required:
                          - type
                          title: Auto Chunking Strategy
                          type: object
                        - additionalProperties: false
                          properties:
                            static:
                              additionalProperties: false
                              properties:
                                chunk_overlap_tokens:
                                  description: 'The number of tokens that overlap
                                    between chunks. The default value is `400`.


                                    Note that the overlap must not exceed half of
                                    `max_chunk_size_tokens`.

                                    '
                                  type: integer
                                max_chunk_size_tokens:
                                  description: The maximum number of tokens in each
                                    chunk. The default value is `800`. The minimum
                                    value is `100` and the maximum value is `4096`.
                                  maximum: 4096
                                  minimum: 100
                                  type: integer
                              required:
                              - max_chunk_size_tokens
                              - chunk_overlap_tokens
                              type: object
                            type:
                              description: Always `static`.
                              enum:
                              - static
                              type: string
                          required:
                          - type
                          - static
                          title: Static Chunking Strategy
                          type: object
                        type: object
                        x-oaiExpandable: true
                      file_ids:
                        description: 'A list of [file](/docs/api-reference/files)
                          IDs to add to the vector store. There can be a maximum of
                          10000 files in a vector store.

                          '
                        items:
                          type: string
                        maxItems: 10000
                        type: array
                      metadata:
                        description: 'Set of 16 key-value pairs that can be attached
                          to a vector store. This can be useful for storing additional
                          information about the vector store in a structured format.
                          Keys can be a maximum of 64 characters long and values can
                          be a maxium of 512 characters long.

                          '
                        type: object
                        x-oaiTypeLabel: map
                    type: object
                  maxItems: 1
                  type: array
              type: object
          type:
          - object
          - 'null'
        tools:
          default: []
          description: 'A list of tool enabled on the assistant. There can be a maximum
            of 128 tools per assistant. Tools can be of types `code_interpreter`,
            `file_search`, or `function`.

            '
          items:
            oneOf:
            - $ref: '#/components/schemas/AssistantToolsCode'
            - $ref: '#/components/schemas/AssistantToolsFileSearch'
            - $ref: '#/components/schemas/AssistantToolsFunction'
            x-oaiExpandable: true
          maxItems: 128
          type: array
        top_p:
          default: 1
          description: 'An alternative to sampling with temperature, called nucleus
            sampling, where the model considers the results of the tokens with top_p
            probability mass. So 0.1 means only the tokens comprising the top 10%
            probability mass are considered.


            We generally recommend altering this or temperature but not both.

            '
          example: 1
          maximum: 1
          minimum: 0
          type:
          - number
          - 'null'
      required:
      - model
      type: object
    CreateChatCompletionFunctionResponse:
      description: Represents a chat completion response returned by model, based
        on the provided input.
      properties:
        choices:
          description: A list of chat completion choices. Can be more than one if
            `n` is greater than 1.
          items:
            properties:
              finish_reason:
                description: 'The reason the model stopped generating tokens. This
                  will be `stop` if the model hit a natural stop point or a provided
                  stop sequence, `length` if the maximum number of tokens specified
                  in the request was reached, `content_filter` if content was omitted
                  due to a flag from our content filters, or `function_call` if the
                  model called a function.

                  '
                enum:
                - stop
                - length
                - function_call
                - content_filter
                type: string
              index:
                description: The index of the choice in the list of choices.
                type: integer
              message:
                $ref: '#/components/schemas/ChatCompletionResponseMessage'
            required:
            - finish_reason
            - index
            - message
            - logprobs
            type: object
          type: array
        created:
          description: The Unix timestamp (in seconds) of when the chat completion
            was created.
          type: integer
        id:
          description: A unique identifier for the chat completion.
          type: string
        model:
          description: The model used for the chat completion.
          type: string
        object:
          description: The object type, which is always `chat.completion`.
          enum:
          - chat.completion
          type: string
        system_fingerprint:
          description: 'This fingerprint represents the backend configuration that
            the model runs with.


            Can be used in conjunction with the `seed` request parameter to understand
            when backend changes have been made that might impact determinism.

            '
          type: string
        usage:
          $ref: '#/components/schemas/CompletionUsage'
      required:
      - choices
      - created
      - id
      - model
      - object
      type: object
      x-oaiMeta:
        example: "{\n  \"id\": \"chatcmpl-abc123\",\n  \"object\": \"chat.completion\"\
          ,\n  \"created\": 1699896916,\n  \"model\": \"gpt-3.5-turbo-0125\",\n  \"\
          choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n       \
          \ \"role\": \"assistant\",\n        \"content\": null,\n        \"tool_calls\"\
          : [\n          {\n            \"id\": \"call_abc123\",\n            \"type\"\
          : \"function\",\n            \"function\": {\n              \"name\": \"\
          get_current_weather\",\n              \"arguments\": \"{\\n\\\"location\\\
          \": \\\"Boston, MA\\\"\\n}\"\n            }\n          }\n        ]\n  \
          \    },\n      \"logprobs\": null,\n      \"finish_reason\": \"tool_calls\"\
          \n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 82,\n    \"completion_tokens\"\
          : 17,\n    \"total_tokens\": 99\n  }\n}\n"
        group: chat
        name: The chat completion object
    CreateChatCompletionImageResponse:
      description: Represents a streamed chunk of a chat completion response returned
        by model, based on the provided input.
      type: object
      x-oaiMeta:
        example: "{\n  \"id\": \"chatcmpl-123\",\n  \"object\": \"chat.completion\"\
          ,\n  \"created\": 1677652288,\n  \"model\": \"gpt-3.5-turbo-0125\",\n  \"\
          system_fingerprint\": \"fp_44709d6fcb\",\n  \"choices\": [{\n    \"index\"\
          : 0,\n    \"message\": {\n      \"role\": \"assistant\",\n      \"content\"\
          : \"\\n\\nThis image shows a wooden boardwalk extending through a lush green\
          \ marshland.\",\n    },\n    \"logprobs\": null,\n    \"finish_reason\"\
          : \"stop\"\n  }],\n  \"usage\": {\n    \"prompt_tokens\": 9,\n    \"completion_tokens\"\
          : 12,\n    \"total_tokens\": 21\n  }\n}\n"
        group: chat
        name: The chat completion chunk object
    CreateChatCompletionRequest:
      properties:
        frequency_penalty:
          default: 0
          description: 'Number between -2.0 and 2.0. Positive values penalize new
            tokens based on their existing frequency in the text so far, decreasing
            the model''s likelihood to repeat the same line verbatim.


            [See more information about frequency and presence penalties.](/docs/guides/text-generation/parameter-details)

            '
          maximum: 2
          minimum: -2
          type:
          - number
          - 'null'
        function_call:
          deprecated: true
          description: 'Deprecated in favor of `tool_choice`.


            Controls which (if any) function is called by the model.

            `none` means the model will not call a function and instead generates
            a message.

            `auto` means the model can pick between generating a message or calling
            a function.

            Specifying a particular function via `{"name": "my_function"}` forces
            the model to call that function.


            `none` is the default when no functions are present. `auto` is the default
            if functions are present.

            '
          oneOf:
          - description: '`none` means the model will not call a function and instead
              generates a message. `auto` means the model can pick between generating
              a message or calling a function.

              '
            enum:
            - none
            - auto
            type: string
          - $ref: '#/components/schemas/ChatCompletionFunctionCallOption'
          x-oaiExpandable: true
        functions:
          deprecated: true
          description: 'Deprecated in favor of `tools`.


            A list of functions the model may generate JSON inputs for.

            '
          items:
            $ref: '#/components/schemas/ChatCompletionFunctions'
          maxItems: 128
          minItems: 1
          type: array
        logit_bias:
          additionalProperties:
            type: integer
          default: null
          description: 'Modify the likelihood of specified tokens appearing in the
            completion.


            Accepts a JSON object that maps tokens (specified by their token ID in
            the tokenizer) to an associated bias value from -100 to 100. Mathematically,
            the bias is added to the logits generated by the model prior to sampling.
            The exact effect will vary per model, but values between -1 and 1 should
            decrease or increase likelihood of selection; values like -100 or 100
            should result in a ban or exclusive selection of the relevant token.

            '
          type:
          - object
          - 'null'
          x-oaiTypeLabel: map
        logprobs:
          default: false
          description: Whether to return log probabilities of the output tokens or
            not. If true, returns the log probabilities of each output token returned
            in the `content` of `message`.
          type:
          - boolean
          - 'null'
        max_tokens:
          description: 'The maximum number of [tokens](/tokenizer) that can be generated
            in the chat completion.


            The total length of input tokens and generated tokens is limited by the
            model''s context length. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken)
            for counting tokens.

            '
          type:
          - integer
          - 'null'
        messages:
          description: A list of messages comprising the conversation so far. [Example
            Python code](https://cookbook.openai.com/examples/how_to_format_inputs_to_chatgpt_models).
          items:
            $ref: '#/components/schemas/ChatCompletionRequestMessage'
          minItems: 1
          type: array
        model:
          anyOf:
          - type: string
          - enum:
            - gpt-4o
            - gpt-4o-2024-05-13
            - gpt-4-turbo
            - gpt-4-turbo-2024-04-09
            - gpt-4-0125-preview
            - gpt-4-turbo-preview
            - gpt-4-1106-preview
            - gpt-4-vision-preview
            - gpt-4
            - gpt-4-0314
            - gpt-4-0613
            - gpt-4-32k
            - gpt-4-32k-0314
            - gpt-4-32k-0613
            - gpt-3.5-turbo
            - gpt-3.5-turbo-16k
            - gpt-3.5-turbo-0301
            - gpt-3.5-turbo-0613
            - gpt-3.5-turbo-1106
            - gpt-3.5-turbo-0125
            - gpt-3.5-turbo-16k-0613
            type: string
          description: ID of the model to use. See the [model endpoint compatibility](/docs/models/model-endpoint-compatibility)
            table for details on which models work with the Chat API.
          example: gpt-4-turbo
          x-oaiTypeLabel: string
        n:
          default: 1
          description: How many chat completion choices to generate for each input
            message. Note that you will be charged based on the number of generated
            tokens across all of the choices. Keep `n` as `1` to minimize costs.
          example: 1
          maximum: 128
          minimum: 1
          type:
          - integer
          - 'null'
        parallel_tool_calls:
          $ref: '#/components/schemas/ParallelToolCalls'
        presence_penalty:
          default: 0
          description: 'Number between -2.0 and 2.0. Positive values penalize new
            tokens based on whether they appear in the text so far, increasing the
            model''s likelihood to talk about new topics.


            [See more information about frequency and presence penalties.](/docs/guides/text-generation/parameter-details)

            '
          maximum: 2
          minimum: -2
          type:
          - number
          - 'null'
        response_format:
          description: 'An object specifying the format that the model must output.
            Compatible with [GPT-4 Turbo](/docs/models/gpt-4-and-gpt-4-turbo) and
            all GPT-3.5 Turbo models newer than `gpt-3.5-turbo-1106`.


            Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees
            the message the model generates is valid JSON.


            **Important:** when using JSON mode, you **must** also instruct the model
            to produce JSON yourself via a system or user message. Without this, the
            model may generate an unending stream of whitespace until the generation
            reaches the token limit, resulting in a long-running and seemingly "stuck"
            request. Also note that the message content may be partially cut off if
            `finish_reason="length"`, which indicates the generation exceeded `max_tokens`
            or the conversation exceeded the max context length.

            '
          properties:
            type:
              default: text
              description: Must be one of `text` or `json_object`.
              enum:
              - text
              - json_object
              example: json_object
              type: string
          type: object
        seed:
          description: 'This feature is in Beta.

            If specified, our system will make a best effort to sample deterministically,
            such that repeated requests with the same `seed` and parameters should
            return the same result.

            Determinism is not guaranteed, and you should refer to the `system_fingerprint`
            response parameter to monitor changes in the backend.

            '
          maximum: 9223372036854775807
          minimum: -9223372036854775808
          type:
          - integer
          - 'null'
          x-oaiMeta:
            beta: true
        stop:
          default: null
          description: 'Up to 4 sequences where the API will stop generating further
            tokens.

            '
          oneOf:
          - type:
            - string
            - 'null'
          - items:
              type: string
            maxItems: 4
            minItems: 1
            type: array
        stream:
          default: false
          description: 'If set, partial message deltas will be sent, like in ChatGPT.
            Tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)
            as they become available, with the stream terminated by a `data: [DONE]`
            message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).

            '
          type:
          - boolean
          - 'null'
        stream_options:
          $ref: '#/components/schemas/ChatCompletionStreamOptions'
        temperature:
          default: 1
          description: 'What sampling temperature to use, between 0 and 2. Higher
            values like 0.8 will make the output more random, while lower values like
            0.2 will make it more focused and deterministic.


            We generally recommend altering this or `top_p` but not both.

            '
          example: 1
          maximum: 2
          minimum: 0
          type:
          - number
          - 'null'
        tool_choice:
          $ref: '#/components/schemas/ChatCompletionToolChoiceOption'
        tools:
          description: 'A list of tools the model may call. Currently, only functions
            are supported as a tool. Use this to provide a list of functions the model
            may generate JSON inputs for. A max of 128 functions are supported.

            '
          items:
            $ref: '#/components/schemas/ChatCompletionTool'
          type: array
        top_logprobs:
          description: An integer between 0 and 20 specifying the number of most likely
            tokens to return at each token position, each with an associated log probability.
            `logprobs` must be set to `true` if this parameter is used.
          maximum: 20
          minimum: 0
          type:
          - integer
          - 'null'
        top_p:
          default: 1
          description: 'An alternative to sampling with temperature, called nucleus
            sampling, where the model considers the results of the tokens with top_p
            probability mass. So 0.1 means only the tokens comprising the top 10%
            probability mass are considered.


            We generally recommend altering this or `temperature` but not both.

            '
          example: 1
          maximum: 1
          minimum: 0
          type:
          - number
          - 'null'
        user: &id005
          description: 'A unique identifier representing your end-user, which can
            help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).

            '
          example: user-1234
          type: string
      required:
      - model
      - messages
      type: object
    CreateChatCompletionResponse:
      description: Represents a chat completion response returned by model, based
        on the provided input.
      properties:
        choices:
          description: A list of chat completion choices. Can be more than one if
            `n` is greater than 1.
          items:
            properties:
              finish_reason:
                description: 'The reason the model stopped generating tokens. This
                  will be `stop` if the model hit a natural stop point or a provided
                  stop sequence,

                  `length` if the maximum number of tokens specified in the request
                  was reached,

                  `content_filter` if content was omitted due to a flag from our content
                  filters,

                  `tool_calls` if the model called a tool, or `function_call` (deprecated)
                  if the model called a function.

                  '
                enum:
                - stop
                - length
                - tool_calls
                - content_filter
                - function_call
                type: string
              index:
                description: The index of the choice in the list of choices.
                type: integer
              logprobs: &id004
                description: Log probability information for the choice.
                properties:
                  content:
                    description: A list of message content tokens with log probability
                      information.
                    items:
                      $ref: '#/components/schemas/ChatCompletionTokenLogprob'
                    type:
                    - array
                    - 'null'
                required:
                - content
                type:
                - object
                - 'null'
              message:
                $ref: '#/components/schemas/ChatCompletionResponseMessage'
            required:
            - finish_reason
            - index
            - message
            - logprobs
            type: object
          type: array
        created:
          description: The Unix timestamp (in seconds) of when the chat completion
            was created.
          type: integer
        id:
          description: A unique identifier for the chat completion.
          type: string
        model:
          description: The model used for the chat completion.
          type: string
        object:
          description: The object type, which is always `chat.completion`.
          enum:
          - chat.completion
          type: string
        system_fingerprint:
          description: 'This fingerprint represents the backend configuration that
            the model runs with.


            Can be used in conjunction with the `seed` request parameter to understand
            when backend changes have been made that might impact determinism.

            '
          type: string
        usage:
          $ref: '#/components/schemas/CompletionUsage'
      required:
      - choices
      - created
      - id
      - model
      - object
      type: object
      x-oaiMeta:
        example: "{\n  \"id\": \"chatcmpl-123\",\n  \"object\": \"chat.completion\"\
          ,\n  \"created\": 1677652288,\n  \"model\": \"gpt-3.5-turbo-0125\",\n  \"\
          system_fingerprint\": \"fp_44709d6fcb\",\n  \"choices\": [{\n    \"index\"\
          : 0,\n    \"message\": {\n      \"role\": \"assistant\",\n      \"content\"\
          : \"\\n\\nHello there, how may I assist you today?\",\n    },\n    \"logprobs\"\
          : null,\n    \"finish_reason\": \"stop\"\n  }],\n  \"usage\": {\n    \"\
          prompt_tokens\": 9,\n    \"completion_tokens\": 12,\n    \"total_tokens\"\
          : 21\n  }\n}\n"
        group: chat
        name: The chat completion object
    CreateChatCompletionStreamResponse:
      description: Represents a streamed chunk of a chat completion response returned
        by model, based on the provided input.
      properties:
        choices:
          description: 'A list of chat completion choices. Can contain more than one
            elements if `n` is greater than 1. Can also be empty for the

            last chunk if you set `stream_options: {"include_usage": true}`.

            '
          items:
            properties:
              delta:
                $ref: '#/components/schemas/ChatCompletionStreamResponseDelta'
              finish_reason:
                description: 'The reason the model stopped generating tokens. This
                  will be `stop` if the model hit a natural stop point or a provided
                  stop sequence,

                  `length` if the maximum number of tokens specified in the request
                  was reached,

                  `content_filter` if content was omitted due to a flag from our content
                  filters,

                  `tool_calls` if the model called a tool, or `function_call` (deprecated)
                  if the model called a function.

                  '
                enum:
                - stop
                - length
                - tool_calls
                - content_filter
                - function_call
                type:
                - string
                - 'null'
              index:
                description: The index of the choice in the list of choices.
                type: integer
              logprobs: *id004
            required:
            - delta
            - finish_reason
            - index
            type: object
          type: array
        created:
          description: The Unix timestamp (in seconds) of when the chat completion
            was created. Each chunk has the same timestamp.
          type: integer
        id:
          description: A unique identifier for the chat completion. Each chunk has
            the same ID.
          type: string
        model:
          description: The model to generate the completion.
          type: string
        object:
          description: The object type, which is always `chat.completion.chunk`.
          enum:
          - chat.completion.chunk
          type: string
        system_fingerprint:
          description: 'This fingerprint represents the backend configuration that
            the model runs with.

            Can be used in conjunction with the `seed` request parameter to understand
            when backend changes have been made that might impact determinism.

            '
          type: string
        usage:
          description: 'An optional field that will only be present when you set `stream_options:
            {"include_usage": true}` in your request.

            When present, it contains a null value except for the last chunk which
            contains the token usage statistics for the entire request.

            '
          properties:
            completion_tokens:
              description: Number of tokens in the generated completion.
              type: integer
            prompt_tokens:
              description: Number of tokens in the prompt.
              type: integer
            total_tokens:
              description: Total number of tokens used in the request (prompt + completion).
              type: integer
          required:
          - prompt_tokens
          - completion_tokens
          - total_tokens
          type: object
      required:
      - choices
      - created
      - id
      - model
      - object
      type: object
      x-oaiMeta:
        example: '{"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-3.5-turbo-0125",
          "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}


          {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-3.5-turbo-0125",
          "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"content":"Hello"},"logprobs":null,"finish_reason":null}]}


          ....


          {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-3.5-turbo-0125",
          "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}

          '
        group: chat
        name: The chat completion chunk object
    CreateCompletionRequest:
      properties:
        best_of:
          default: 1
          description: "Generates `best_of` completions server-side and returns the\
            \ \"best\" (the one with the highest log probability per token). Results\
            \ cannot be streamed.\n\nWhen used with `n`, `best_of` controls the number\
            \ of candidate completions and `n` specifies how many to return \u2013\
            \ `best_of` must be greater than `n`.\n\n**Note:** Because this parameter\
            \ generates many completions, it can quickly consume your token quota.\
            \ Use carefully and ensure that you have reasonable settings for `max_tokens`\
            \ and `stop`.\n"
          maximum: 20
          minimum: 0
          type:
          - integer
          - 'null'
        echo:
          default: false
          description: 'Echo back the prompt in addition to the completion

            '
          type:
          - boolean
          - 'null'
        frequency_penalty:
          default: 0
          description: 'Number between -2.0 and 2.0. Positive values penalize new
            tokens based on their existing frequency in the text so far, decreasing
            the model''s likelihood to repeat the same line verbatim.


            [See more information about frequency and presence penalties.](/docs/guides/text-generation/parameter-details)

            '
          maximum: 2
          minimum: -2
          type:
          - number
          - 'null'
        logit_bias:
          additionalProperties:
            type: integer
          default: null
          description: 'Modify the likelihood of specified tokens appearing in the
            completion.


            Accepts a JSON object that maps tokens (specified by their token ID in
            the GPT tokenizer) to an associated bias value from -100 to 100. You can
            use this [tokenizer tool](/tokenizer?view=bpe) to convert text to token
            IDs. Mathematically, the bias is added to the logits generated by the
            model prior to sampling. The exact effect will vary per model, but values
            between -1 and 1 should decrease or increase likelihood of selection;
            values like -100 or 100 should result in a ban or exclusive selection
            of the relevant token.


            As an example, you can pass `{"50256": -100}` to prevent the <|endoftext|>
            token from being generated.

            '
          type:
          - object
          - 'null'
          x-oaiTypeLabel: map
        logprobs:
          default: null
          description: 'Include the log probabilities on the `logprobs` most likely
            output tokens, as well the chosen tokens. For example, if `logprobs` is
            5, the API will return a list of the 5 most likely tokens. The API will
            always return the `logprob` of the sampled token, so there may be up to
            `logprobs+1` elements in the response.


            The maximum value for `logprobs` is 5.

            '
          maximum: 5
          minimum: 0
          type:
          - integer
          - 'null'
        max_tokens:
          default: 16
          description: 'The maximum number of [tokens](/tokenizer) that can be generated
            in the completion.


            The token count of your prompt plus `max_tokens` cannot exceed the model''s
            context length. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken)
            for counting tokens.

            '
          example: 16
          minimum: 0
          type:
          - integer
          - 'null'
        model:
          anyOf:
          - type: string
          - enum:
            - gpt-3.5-turbo-instruct
            - davinci-002
            - babbage-002
            type: string
          description: 'ID of the model to use. You can use the [List models](/docs/api-reference/models/list)
            API to see all of your available models, or see our [Model overview](/docs/models/overview)
            for descriptions of them.

            '
          x-oaiTypeLabel: string
        n:
          default: 1
          description: 'How many completions to generate for each prompt.


            **Note:** Because this parameter generates many completions, it can quickly
            consume your token quota. Use carefully and ensure that you have reasonable
            settings for `max_tokens` and `stop`.

            '
          example: 1
          maximum: 128
          minimum: 1
          type:
          - integer
          - 'null'
        presence_penalty:
          default: 0
          description: 'Number between -2.0 and 2.0. Positive values penalize new
            tokens based on whether they appear in the text so far, increasing the
            model''s likelihood to talk about new topics.


            [See more information about frequency and presence penalties.](/docs/guides/text-generation/parameter-details)

            '
          maximum: 2
          minimum: -2
          type:
          - number
          - 'null'
        prompt:
          default: <|endoftext|>
          description: 'The prompt(s) to generate completions for, encoded as a string,
            array of strings, array of tokens, or array of token arrays.


            Note that <|endoftext|> is the document separator that the model sees
            during training, so if a prompt is not specified the model will generate
            as if from the beginning of a new document.

            '
          oneOf:
          - default: ''
            example: This is a test.
            type: string
          - items:
              default: ''
              example: This is a test.
              type: string
            type: array
          - example: '[1212, 318, 257, 1332, 13]'
            items:
              type: integer
            minItems: 1
            type: array
          - example: '[[1212, 318, 257, 1332, 13]]'
            items:
              items:
                type: integer
              minItems: 1
              type: array
            minItems: 1
            type: array
        seed:
          description: 'If specified, our system will make a best effort to sample
            deterministically, such that repeated requests with the same `seed` and
            parameters should return the same result.


            Determinism is not guaranteed, and you should refer to the `system_fingerprint`
            response parameter to monitor changes in the backend.

            '
          maximum: 9223372036854775807
          minimum: -9223372036854775808
          type:
          - integer
          - 'null'
        stop:
          default: null
          description: 'Up to 4 sequences where the API will stop generating further
            tokens. The returned text will not contain the stop sequence.

            '
          oneOf:
          - default: <|endoftext|>
            example: '

              '
            type:
            - string
            - 'null'
          - items:
              example: '["\n"]'
              type: string
            maxItems: 4
            minItems: 1
            type: array
        stream:
          default: false
          description: 'Whether to stream back partial progress. If set, tokens will
            be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)
            as they become available, with the stream terminated by a `data: [DONE]`
            message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).

            '
          type:
          - boolean
          - 'null'
        stream_options:
          $ref: '#/components/schemas/ChatCompletionStreamOptions'
        suffix:
          default: null
          description: 'The suffix that comes after a completion of inserted text.


            This parameter is only supported for `gpt-3.5-turbo-instruct`.

            '
          example: test.
          type:
          - string
          - 'null'
        temperature:
          default: 1
          description: 'What sampling temperature to use, between 0 and 2. Higher
            values like 0.8 will make the output more random, while lower values like
            0.2 will make it more focused and deterministic.


            We generally recommend altering this or `top_p` but not both.

            '
          example: 1
          maximum: 2
          minimum: 0
          type:
          - number
          - 'null'
        top_p:
          default: 1
          description: 'An alternative to sampling with temperature, called nucleus
            sampling, where the model considers the results of the tokens with top_p
            probability mass. So 0.1 means only the tokens comprising the top 10%
            probability mass are considered.


            We generally recommend altering this or `temperature` but not both.

            '
          example: 1
          maximum: 1
          minimum: 0
          type:
          - number
          - 'null'
        user: *id005
      required:
      - model
      - prompt
      type: object
    CreateCompletionResponse:
      description: 'Represents a completion response from the API. Note: both the
        streamed and non-streamed response objects share the same shape (unlike the
        chat endpoint).

        '
      properties:
        choices:
          description: The list of completion choices the model generated for the
            input prompt.
          items:
            properties:
              finish_reason:
                description: 'The reason the model stopped generating tokens. This
                  will be `stop` if the model hit a natural stop point or a provided
                  stop sequence,

                  `length` if the maximum number of tokens specified in the request
                  was reached,

                  or `content_filter` if content was omitted due to a flag from our
                  content filters.

                  '
                enum:
                - stop
                - length
                - content_filter
                type: string
              index:
                type: integer
              logprobs:
                properties:
                  text_offset:
                    items:
                      type: integer
                    type: array
                  token_logprobs:
                    items:
                      type: number
                    type: array
                  tokens:
                    items:
                      type: string
                    type: array
                  top_logprobs:
                    items:
                      additionalProperties:
                        type: number
                      type: object
                    type: array
                type:
                - object
                - 'null'
              text:
                type: string
            required:
            - finish_reason
            - index
            - logprobs
            - text
            type: object
          type: array
        created:
          description: The Unix timestamp (in seconds) of when the completion was
            created.
          type: integer
        id:
          description: A unique identifier for the completion.
          type: string
        model:
          description: The model used for completion.
          type: string
        object:
          description: The object type, which is always "text_completion"
          enum:
          - text_completion
          type: string
        system_fingerprint:
          description: 'This fingerprint represents the backend configuration that
            the model runs with.


            Can be used in conjunction with the `seed` request parameter to understand
            when backend changes have been made that might impact determinism.

            '
          type: string
        usage:
          $ref: '#/components/schemas/CompletionUsage'
      required:
      - id
      - object
      - created
      - model
      - choices
      type: object
      x-oaiMeta:
        example: "{\n  \"id\": \"cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7\",\n  \"object\": \"\
          text_completion\",\n  \"created\": 1589478378,\n  \"model\": \"gpt-4-turbo\"\
          ,\n  \"choices\": [\n    {\n      \"text\": \"\\n\\nThis is indeed a test\"\
          ,\n      \"index\": 0,\n      \"logprobs\": null,\n      \"finish_reason\"\
          : \"length\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 5,\n \
          \   \"completion_tokens\": 7,\n    \"total_tokens\": 12\n  }\n}\n"
        legacy: true
        name: The completion object
    CreateEmbeddingRequest:
      additionalProperties: false
      properties:
        dimensions:
          description: 'The number of dimensions the resulting output embeddings should
            have. Only supported in `text-embedding-3` and later models.

            '
          minimum: 1
          type: integer
        encoding_format:
          default: float
          description: The format to return the embeddings in. Can be either `float`
            or [`base64`](https://pypi.org/project/pybase64/).
          enum:
          - float
          - base64
          example: float
          type: string
        input:
          description: 'Input text to embed, encoded as a string or array of tokens.
            To embed multiple inputs in a single request, pass an array of strings
            or array of token arrays. The input must not exceed the max input tokens
            for the model (8192 tokens for `text-embedding-ada-002`), cannot be an
            empty string, and any array must be 2048 dimensions or less. [Example
            Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken)
            for counting tokens.

            '
          example: The quick brown fox jumped over the lazy dog
          oneOf:
          - default: ''
            description: The string that will be turned into an embedding.
            example: This is a test.
            title: string
            type: string
          - description: The array of strings that will be turned into an embedding.
            items:
              default: ''
              example: '[''This is a test.'']'
              type: string
            maxItems: 2048
            minItems: 1
            title: array
            type: array
          - description: The array of integers that will be turned into an embedding.
            example: '[1212, 318, 257, 1332, 13]'
            items:
              type: integer
            maxItems: 2048
            minItems: 1
            title: array
            type: array
          - description: The array of arrays containing integers that will be turned
              into an embedding.
            example: '[[1212, 318, 257, 1332, 13]]'
            items:
              items:
                type: integer
              minItems: 1
              type: array
            maxItems: 2048
            minItems: 1
            title: array
            type: array
          x-oaiExpandable: true
        model:
          anyOf:
          - type: string
          - enum:
            - text-embedding-ada-002
            - text-embedding-3-small
            - text-embedding-3-large
            type: string
          description: 'ID of the model to use. You can use the [List models](/docs/api-reference/models/list)
            API to see all of your available models, or see our [Model overview](/docs/models/overview)
            for descriptions of them.

            '
          example: text-embedding-3-small
          x-oaiTypeLabel: string
        user: *id005
      required:
      - model
      - input
      type: object
    CreateEmbeddingResponse:
      properties:
        data:
          description: The list of embeddings generated by the model.
          items:
            $ref: '#/components/schemas/Embedding'
          type: array
        model:
          description: The name of the model used to generate the embedding.
          type: string
        object:
          description: The object type, which is always "list".
          enum:
          - list
          type: string
        usage:
          description: The usage information for the request.
          properties:
            prompt_tokens:
              description: The number of tokens used by the prompt.
              type: integer
            total_tokens:
              description: The total number of tokens used by the request.
              type: integer
          required:
          - prompt_tokens
          - total_tokens
          type: object
      required:
      - object
      - model
      - data
      - usage
      type: object
    CreateFileRequest:
      additionalProperties: false
      properties:
        file:
          description: 'The File object (not file name) to be uploaded.

            '
          format: binary
          type: string
        purpose:
          description: 'The intended purpose of the uploaded file.


            Use "assistants" for [Assistants](/docs/api-reference/assistants) and
            [Message](/docs/api-reference/messages) files, "vision" for Assistants
            image file inputs, "batch" for [Batch API](/docs/guides/batch), and "fine-tune"
            for [Fine-tuning](/docs/api-reference/fine-tuning).

            '
          enum:
          - assistants
          - batch
          - fine-tune
          - vision
          type: string
      required:
      - file
      - purpose
      type: object
    CreateFineTuningJobRequest:
      properties:
        hyperparameters:
          description: The hyperparameters used for the fine-tuning job.
          properties:
            batch_size:
              default: auto
              description: 'Number of examples in each batch. A larger batch size
                means that model parameters

                are updated less frequently, but with lower variance.

                '
              oneOf:
              - enum:
                - auto
                type: string
              - maximum: 256
                minimum: 1
                type: integer
            learning_rate_multiplier:
              default: auto
              description: 'Scaling factor for the learning rate. A smaller learning
                rate may be useful to avoid

                overfitting.

                '
              oneOf:
              - enum:
                - auto
                type: string
              - exclusiveMinimum: 0.0
                minimum: 0
                type: number
            n_epochs:
              default: auto
              description: 'The number of epochs to train the model for. An epoch
                refers to one full cycle

                through the training dataset.

                '
              oneOf:
              - enum:
                - auto
                type: string
              - maximum: 50
                minimum: 1
                type: integer
          type: object
        integrations:
          description: A list of integrations to enable for your fine-tuning job.
          items:
            properties:
              type:
                description: 'The type of integration to enable. Currently, only "wandb"
                  (Weights and Biases) is supported.

                  '
                oneOf:
                - enum:
                  - wandb
                  type: string
              wandb:
                description: 'The settings for your integration with Weights and Biases.
                  This payload specifies the project that

                  metrics will be sent to. Optionally, you can set an explicit display
                  name for your run, add tags

                  to your run, and set a default entity (team, username, etc) to be
                  associated with your run.

                  '
                properties:
                  entity:
                    description: 'The entity to use for the run. This allows you to
                      set the team or username of the WandB user that you would

                      like associated with the run. If not set, the default entity
                      for the registered WandB API key is used.

                      '
                    type:
                    - string
                    - 'null'
                  name:
                    description: 'A display name to set for the run. If not set, we
                      will use the Job ID as the name.

                      '
                    type:
                    - string
                    - 'null'
                  project:
                    description: 'The name of the project that the new run will be
                      created under.

                      '
                    example: my-wandb-project
                    type: string
                  tags:
                    description: 'A list of tags to be attached to the newly created
                      run. These tags are passed through directly to WandB. Some

                      default tags are generated by OpenAI: "openai/finetune", "openai/{base-model}",
                      "openai/{ftjob-abcdef}".

                      '
                    items:
                      example: custom-tag
                      type: string
                    type: array
                required:
                - project
                type: object
            required:
            - type
            - wandb
            type: object
          type:
          - array
          - 'null'
        model:
          anyOf:
          - type: string
          - enum:
            - babbage-002
            - davinci-002
            - gpt-3.5-turbo
            type: string
          description: 'The name of the model to fine-tune. You can select one of
            the

            [supported models](/docs/guides/fine-tuning/what-models-can-be-fine-tuned).

            '
          example: gpt-3.5-turbo
          x-oaiTypeLabel: string
        seed:
          description: 'The seed controls the reproducibility of the job. Passing
            in the same seed and job parameters should produce the same results, but
            may differ in rare cases.

            If a seed is not specified, one will be generated for you.

            '
          example: 42
          maximum: 2147483647
          minimum: 0
          type:
          - integer
          - 'null'
        suffix:
          default: null
          description: 'A string of up to 18 characters that will be added to your
            fine-tuned model name.


            For example, a `suffix` of "custom-model-name" would produce a model name
            like `ft:gpt-3.5-turbo:openai:custom-model-name:7p4lURel`.

            '
          maxLength: 40
          minLength: 1
          type:
          - string
          - 'null'
        training_file:
          description: 'The ID of an uploaded file that contains training data.


            See [upload file](/docs/api-reference/files/create) for how to upload
            a file.


            Your dataset must be formatted as a JSONL file. Additionally, you must
            upload your file with the purpose `fine-tune`.


            The contents of the file should differ depending on if the model uses
            the [chat](/docs/api-reference/fine-tuning/chat-input) or [completions](/docs/api-reference/fine-tuning/completions-input)
            format.


            See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.

            '
          example: file-abc123
          type: string
        validation_file:
          description: 'The ID of an uploaded file that contains validation data.


            If you provide this file, the data is used to generate validation

            metrics periodically during fine-tuning. These metrics can be viewed in

            the fine-tuning results file.

            The same data should not be present in both train and validation files.


            Your dataset must be formatted as a JSONL file. You must upload your file
            with the purpose `fine-tune`.


            See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.

            '
          example: file-abc123
          type:
          - string
          - 'null'
      required:
      - model
      - training_file
      type: object
    CreateImageEditRequest:
      properties:
        image:
          description: The image to edit. Must be a valid PNG file, less than 4MB,
            and square. If mask is not provided, image must have transparency, which
            will be used as the mask.
          format: binary
          type: string
        mask:
          description: An additional image whose fully transparent areas (e.g. where
            alpha is zero) indicate where `image` should be edited. Must be a valid
            PNG file, less than 4MB, and have the same dimensions as `image`.
          format: binary
          type: string
        model:
          anyOf:
          - type: string
          - enum:
            - dall-e-2
            type: string
          default: dall-e-2
          description: The model to use for image generation. Only `dall-e-2` is supported
            at this time.
          example: dall-e-2
          x-oaiTypeLabel: string
        n:
          default: 1
          description: The number of images to generate. Must be between 1 and 10.
          example: 1
          maximum: 10
          minimum: 1
          type:
          - integer
          - 'null'
        prompt:
          description: A text description of the desired image(s). The maximum length
            is 1000 characters.
          example: A cute baby sea otter wearing a beret
          type: string
        response_format: &id006
          default: url
          description: The format in which the generated images are returned. Must
            be one of `url` or `b64_json`. URLs are only valid for 60 minutes after
            the image has been generated.
          enum:
          - url
          - b64_json
          example: url
          type:
          - string
          - 'null'
        size: &id008
          default: 1024x1024
          description: The size of the generated images. Must be one of `256x256`,
            `512x512`, or `1024x1024`.
          enum:
          - 256x256
          - 512x512
          - 1024x1024
          example: 1024x1024
          type:
          - string
          - 'null'
        user: *id005
      required:
      - prompt
      - image
      type: object
    CreateImageRequest:
      properties:
        model:
          anyOf:
          - type: string
          - enum:
            - dall-e-2
            - dall-e-3
            type: string
          default: dall-e-2
          description: The model to use for image generation.
          example: dall-e-3
          x-oaiTypeLabel: string
        n: &id007
          default: 1
          description: The number of images to generate. Must be between 1 and 10.
            For `dall-e-3`, only `n=1` is supported.
          example: 1
          maximum: 10
          minimum: 1
          type:
          - integer
          - 'null'
        prompt:
          description: A text description of the desired image(s). The maximum length
            is 1000 characters for `dall-e-2` and 4000 characters for `dall-e-3`.
          example: A cute baby sea otter
          type: string
        quality:
          default: standard
          description: The quality of the image that will be generated. `hd` creates
            images with finer details and greater consistency across the image. This
            param is only supported for `dall-e-3`.
          enum:
          - standard
          - hd
          example: standard
          type: string
        response_format: *id006
        size:
          default: 1024x1024
          description: The size of the generated images. Must be one of `256x256`,
            `512x512`, or `1024x1024` for `dall-e-2`. Must be one of `1024x1024`,
            `1792x1024`, or `1024x1792` for `dall-e-3` models.
          enum:
          - 256x256
          - 512x512
          - 1024x1024
          - 1792x1024
          - 1024x1792
          example: 1024x1024
          type:
          - string
          - 'null'
        style:
          default: vivid
          description: The style of the generated images. Must be one of `vivid` or
            `natural`. Vivid causes the model to lean towards generating hyper-real
            and dramatic images. Natural causes the model to produce more natural,
            less hyper-real looking images. This param is only supported for `dall-e-3`.
          enum:
          - vivid
          - natural
          example: vivid
          type:
          - string
          - 'null'
        user: *id005
      required:
      - prompt
      type: object
    CreateImageVariationRequest:
      properties:
        image:
          description: The image to use as the basis for the variation(s). Must be
            a valid PNG file, less than 4MB, and square.
          format: binary
          type: string
        model:
          anyOf:
          - type: string
          - enum:
            - dall-e-2
            type: string
          default: dall-e-2
          description: The model to use for image generation. Only `dall-e-2` is supported
            at this time.
          example: dall-e-2
          x-oaiTypeLabel: string
        n: *id007
        response_format: *id006
        size: *id008
        user: *id005
      required:
      - image
      type: object
    CreateMessageRequest:
      additionalProperties: false
      properties:
        attachments:
          description: A list of files attached to the message, and the tools they
            should be added to.
          items:
            properties:
              file_id:
                description: The ID of the file to attach to the message.
                type: string
              tools:
                description: The tools to add this file to.
                items:
                  oneOf:
                  - $ref: '#/components/schemas/AssistantToolsCode'
                  - $ref: '#/components/schemas/AssistantToolsFileSearchTypeOnly'
                  x-oaiExpandable: true
                type: array
            type: object
          required:
          - file_id
          - tools
          type:
          - array
          - 'null'
        content:
          oneOf:
          - description: The text contents of the message.
            title: Text content
            type: string
          - description: An array of content parts with a defined type, each can be
              of type `text` or images can be passed with `image_url` or `image_file`.
              Image types are only supported on [Vision-compatible models](/docs/models/overview).
            items:
              oneOf:
              - $ref: '#/components/schemas/MessageContentImageFileObject'
              - $ref: '#/components/schemas/MessageContentImageUrlObject'
              - $ref: '#/components/schemas/MessageRequestContentTextObject'
              x-oaiExpandable: true
            minItems: 1
            title: Array of content parts
            type: array
          x-oaiExpandable: true
        metadata:
          description: 'Set of 16 key-value pairs that can be attached to an object.
            This can be useful for storing additional information about the object
            in a structured format. Keys can be a maximum of 64 characters long and
            values can be a maxium of 512 characters long.

            '
          type:
          - object
          - 'null'
          x-oaiTypeLabel: map
        role:
          description: 'The role of the entity that is creating the message. Allowed
            values include:

            - `user`: Indicates the message is sent by an actual user and should be
            used in most cases to represent user-generated messages.

            - `assistant`: Indicates the message is generated by the assistant. Use
            this value to insert messages from the assistant into the conversation.

            '
          enum:
          - user
          - assistant
          type: string
      required:
      - role
      - content
      type: object
    CreateModerationRequest:
      properties:
        input:
          description: The input text to classify
          oneOf:
          - default: ''
            example: I want to kill them.
            type: string
          - items:
              default: ''
              example: I want to kill them.
              type: string
            type: array
        model:
          anyOf:
          - type: string
          - enum:
            - text-moderation-latest
            - text-moderation-stable
            type: string
          default: text-moderation-latest
          description: 'Two content moderations models are available: `text-moderation-stable`
            and `text-moderation-latest`.


            The default is `text-moderation-latest` which will be automatically upgraded
            over time. This ensures you are always using our most accurate model.
            If you use `text-moderation-stable`, we will provide advanced notice before
            updating the model. Accuracy of `text-moderation-stable` may be slightly
            lower than for `text-moderation-latest`.

            '
          example: text-moderation-stable
          x-oaiTypeLabel: string
      required:
      - input
      type: object
    CreateModerationResponse:
      description: Represents if a given text input is potentially harmful.
      properties:
        id:
          description: The unique identifier for the moderation request.
          type: string
        model:
          description: The model used to generate the moderation results.
          type: string
        results:
          description: A list of moderation objects.
          items:
            properties:
              categories:
                description: A list of the categories, and whether they are flagged
                  or not.
                properties:
                  harassment:
                    description: Content that expresses, incites, or promotes harassing
                      language towards any target.
                    type: boolean
                  harassment/threatening:
                    description: Harassment content that also includes violence or
                      serious harm towards any target.
                    type: boolean
                  hate:
                    description: Content that expresses, incites, or promotes hate
                      based on race, gender, ethnicity, religion, nationality, sexual
                      orientation, disability status, or caste. Hateful content aimed
                      at non-protected groups (e.g., chess players) is harassment.
                    type: boolean
                  hate/threatening:
                    description: Hateful content that also includes violence or serious
                      harm towards the targeted group based on race, gender, ethnicity,
                      religion, nationality, sexual orientation, disability status,
                      or caste.
                    type: boolean
                  self-harm:
                    description: Content that promotes, encourages, or depicts acts
                      of self-harm, such as suicide, cutting, and eating disorders.
                    type: boolean
                  self-harm/instructions:
                    description: Content that encourages performing acts of self-harm,
                      such as suicide, cutting, and eating disorders, or that gives
                      instructions or advice on how to commit such acts.
                    type: boolean
                  self-harm/intent:
                    description: Content where the speaker expresses that they are
                      engaging or intend to engage in acts of self-harm, such as suicide,
                      cutting, and eating disorders.
                    type: boolean
                  sexual:
                    description: Content meant to arouse sexual excitement, such as
                      the description of sexual activity, or that promotes sexual
                      services (excluding sex education and wellness).
                    type: boolean
                  sexual/minors:
                    description: Sexual content that includes an individual who is
                      under 18 years old.
                    type: boolean
                  violence:
                    description: Content that depicts death, violence, or physical
                      injury.
                    type: boolean
                  violence/graphic:
                    description: Content that depicts death, violence, or physical
                      injury in graphic detail.
                    type: boolean
                required:
                - hate
                - hate/threatening
                - harassment
                - harassment/threatening
                - self-harm
                - self-harm/intent
                - self-harm/instructions
                - sexual
                - sexual/minors
                - violence
                - violence/graphic
                type: object
              category_scores:
                description: A list of the categories along with their scores as predicted
                  by model.
                properties:
                  harassment:
                    description: The score for the category 'harassment'.
                    type: number
                  harassment/threatening:
                    description: The score for the category 'harassment/threatening'.
                    type: number
                  hate:
                    description: The score for the category 'hate'.
                    type: number
                  hate/threatening:
                    description: The score for the category 'hate/threatening'.
                    type: number
                  self-harm:
                    description: The score for the category 'self-harm'.
                    type: number
                  self-harm/instructions:
                    description: The score for the category 'self-harm/instructions'.
                    type: number
                  self-harm/intent:
                    description: The score for the category 'self-harm/intent'.
                    type: number
                  sexual:
                    description: The score for the category 'sexual'.
                    type: number
                  sexual/minors:
                    description: The score for the category 'sexual/minors'.
                    type: number
                  violence:
                    description: The score for the category 'violence'.
                    type: number
                  violence/graphic:
                    description: The score for the category 'violence/graphic'.
                    type: number
                required:
                - hate
                - hate/threatening
                - harassment
                - harassment/threatening
                - self-harm
                - self-harm/intent
                - self-harm/instructions
                - sexual
                - sexual/minors
                - violence
                - violence/graphic
                type: object
              flagged:
                description: Whether any of the below categories are flagged.
                type: boolean
            required:
            - flagged
            - categories
            - category_scores
            type: object
          type: array
      required:
      - id
      - model
      - results
      type: object
      x-oaiMeta:
        example: "{\n  \"id\": \"modr-XXXXX\",\n  \"model\": \"text-moderation-005\"\
          ,\n  \"results\": [\n    {\n      \"flagged\": true,\n      \"categories\"\
          : {\n        \"sexual\": false,\n        \"hate\": false,\n        \"harassment\"\
          : false,\n        \"self-harm\": false,\n        \"sexual/minors\": false,\n\
          \        \"hate/threatening\": false,\n        \"violence/graphic\": false,\n\
          \        \"self-harm/intent\": false,\n        \"self-harm/instructions\"\
          : false,\n        \"harassment/threatening\": true,\n        \"violence\"\
          : true,\n      },\n      \"category_scores\": {\n        \"sexual\": 1.2282071e-06,\n\
          \        \"hate\": 0.010696256,\n        \"harassment\": 0.29842457,\n \
          \       \"self-harm\": 1.5236925e-08,\n        \"sexual/minors\": 5.7246268e-08,\n\
          \        \"hate/threatening\": 0.0060676364,\n        \"violence/graphic\"\
          : 4.435014e-06,\n        \"self-harm/intent\": 8.098441e-10,\n        \"\
          self-harm/instructions\": 2.8498655e-11,\n        \"harassment/threatening\"\
          : 0.63055265,\n        \"violence\": 0.99011886,\n      }\n    }\n  ]\n\
          }\n"
        name: The moderation object
    CreateRunRequest:
      additionalProperties: false
      properties:
        additional_instructions:
          description: Appends additional instructions at the end of the instructions
            for the run. This is useful for modifying the behavior on a per-run basis
            without overriding other instructions.
          type:
          - string
          - 'null'
        additional_messages:
          description: Adds additional messages to the thread before creating the
            run.
          items:
            $ref: '#/components/schemas/CreateMessageRequest'
          type:
          - array
          - 'null'
        assistant_id:
          description: The ID of the [assistant](/docs/api-reference/assistants) to
            use to execute this run.
          type: string
        instructions:
          description: Overrides the [instructions](/docs/api-reference/assistants/createAssistant)
            of the assistant. This is useful for modifying the behavior on a per-run
            basis.
          type:
          - string
          - 'null'
        max_completion_tokens:
          description: 'The maximum number of completion tokens that may be used over
            the course of the run. The run will make a best effort to use only the
            number of completion tokens specified, across multiple turns of the run.
            If the run exceeds the number of completion tokens specified, the run
            will end with status `incomplete`. See `incomplete_details` for more info.

            '
          minimum: 256
          type:
          - integer
          - 'null'
        max_prompt_tokens:
          description: 'The maximum number of prompt tokens that may be used over
            the course of the run. The run will make a best effort to use only the
            number of prompt tokens specified, across multiple turns of the run. If
            the run exceeds the number of prompt tokens specified, the run will end
            with status `incomplete`. See `incomplete_details` for more info.

            '
          minimum: 256
          type:
          - integer
          - 'null'
        metadata:
          description: 'Set of 16 key-value pairs that can be attached to an object.
            This can be useful for storing additional information about the object
            in a structured format. Keys can be a maximum of 64 characters long and
            values can be a maxium of 512 characters long.

            '
          type:
          - object
          - 'null'
          x-oaiTypeLabel: map
        model:
          anyOf:
          - type: string
          - enum:
            - gpt-4o
            - gpt-4o-2024-05-13
            - gpt-4-turbo
            - gpt-4-turbo-2024-04-09
            - gpt-4-0125-preview
            - gpt-4-turbo-preview
            - gpt-4-1106-preview
            - gpt-4-vision-preview
            - gpt-4
            - gpt-4-0314
            - gpt-4-0613
            - gpt-4-32k
            - gpt-4-32k-0314
            - gpt-4-32k-0613
            - gpt-3.5-turbo
            - gpt-3.5-turbo-16k
            - gpt-3.5-turbo-0613
            - gpt-3.5-turbo-1106
            - gpt-3.5-turbo-0125
            - gpt-3.5-turbo-16k-0613
            type: string
          description: The ID of the [Model](/docs/api-reference/models) to be used
            to execute this run. If a value is provided here, it will override the
            model associated with the assistant. If not, the model associated with
            the assistant will be used.
          example: gpt-4-turbo
          x-oaiTypeLabel: string
        parallel_tool_calls:
          $ref: '#/components/schemas/ParallelToolCalls'
        response_format:
          $ref: '#/components/schemas/AssistantsApiResponseFormatOption'
        stream:
          description: 'If `true`, returns a stream of events that happen during the
            Run as server-sent events, terminating when the Run enters a terminal
            state with a `data: [DONE]` message.

            '
          type:
          - boolean
          - 'null'
        temperature:
          default: 1
          description: 'What sampling temperature to use, between 0 and 2. Higher
            values like 0.8 will make the output more random, while lower values like
            0.2 will make it more focused and deterministic.

            '
          example: 1
          maximum: 2
          minimum: 0
          type:
          - number
          - 'null'
        tool_choice:
          $ref: '#/components/schemas/AssistantsApiToolChoiceOption'
        tools:
          description: Override the tools the assistant can use for this run. This
            is useful for modifying the behavior on a per-run basis.
          items:
            oneOf:
            - $ref: '#/components/schemas/AssistantToolsCode'
            - $ref: '#/components/schemas/AssistantToolsFileSearch'
            - $ref: '#/components/schemas/AssistantToolsFunction'
            x-oaiExpandable: true
          maxItems: 20
          type:
          - array
          - 'null'
        top_p:
          default: 1
          description: 'An alternative to sampling with temperature, called nucleus
            sampling, where the model considers the results of the tokens with top_p
            probability mass. So 0.1 means only the tokens comprising the top 10%
            probability mass are considered.


            We generally recommend altering this or temperature but not both.

            '
          example: 1
          maximum: 1
          minimum: 0
          type:
          - number
          - 'null'
        truncation_strategy:
          $ref: '#/components/schemas/TruncationObject'
      required:
      - thread_id
      - assistant_id
      type: object
    CreateSpeechRequest:
      additionalProperties: false
      properties:
        input:
          description: The text to generate audio for. The maximum length is 4096
            characters.
          maxLength: 4096
          type: string
        model:
          anyOf:
          - type: string
          - enum:
            - tts-1
            - tts-1-hd
            type: string
          description: 'One of the available [TTS models](/docs/models/tts): `tts-1`
            or `tts-1-hd`

            '
          x-oaiTypeLabel: string
        response_format:
          default: mp3
          description: The format to audio in. Supported formats are `mp3`, `opus`,
            `aac`, `flac`, `wav`, and `pcm`.
          enum:
          - mp3
          - opus
          - aac
          - flac
          - wav
          - pcm
          type: string
        speed:
          default: 1.0
          description: The speed of the generated audio. Select a value from `0.25`
            to `4.0`. `1.0` is the default.
          maximum: 4.0
          minimum: 0.25
          type: number
        voice:
          description: The voice to use when generating the audio. Supported voices
            are `alloy`, `echo`, `fable`, `onyx`, `nova`, and `shimmer`. Previews
            of the voices are available in the [Text to speech guide](/docs/guides/text-to-speech/voice-options).
          enum:
          - alloy
          - echo
          - fable
          - onyx
          - nova
          - shimmer
          type: string
      required:
      - model
      - input
      - voice
      type: object
    CreateThreadAndRunRequest:
      additionalProperties: false
      properties:
        assistant_id:
          description: The ID of the [assistant](/docs/api-reference/assistants) to
            use to execute this run.
          type: string
        instructions:
          description: Override the default system message of the assistant. This
            is useful for modifying the behavior on a per-run basis.
          type:
          - string
          - 'null'
        max_completion_tokens:
          description: 'The maximum number of completion tokens that may be used over
            the course of the run. The run will make a best effort to use only the
            number of completion tokens specified, across multiple turns of the run.
            If the run exceeds the number of completion tokens specified, the run
            will end with status `incomplete`. See `incomplete_details` for more info.

            '
          minimum: 256
          type:
          - integer
          - 'null'
        max_prompt_tokens:
          description: 'The maximum number of prompt tokens that may be used over
            the course of the run. The run will make a best effort to use only the
            number of prompt tokens specified, across multiple turns of the run. If
            the run exceeds the number of prompt tokens specified, the run will end
            with status `incomplete`. See `incomplete_details` for more info.

            '
          minimum: 256
          type:
          - integer
          - 'null'
        metadata:
          description: 'Set of 16 key-value pairs that can be attached to an object.
            This can be useful for storing additional information about the object
            in a structured format. Keys can be a maximum of 64 characters long and
            values can be a maxium of 512 characters long.

            '
          type:
          - object
          - 'null'
          x-oaiTypeLabel: map
        model:
          anyOf:
          - type: string
          - enum:
            - gpt-4o
            - gpt-4o-2024-05-13
            - gpt-4-turbo
            - gpt-4-turbo-2024-04-09
            - gpt-4-0125-preview
            - gpt-4-turbo-preview
            - gpt-4-1106-preview
            - gpt-4-vision-preview
            - gpt-4
            - gpt-4-0314
            - gpt-4-0613
            - gpt-4-32k
            - gpt-4-32k-0314
            - gpt-4-32k-0613
            - gpt-3.5-turbo
            - gpt-3.5-turbo-16k
            - gpt-3.5-turbo-0613
            - gpt-3.5-turbo-1106
            - gpt-3.5-turbo-0125
            - gpt-3.5-turbo-16k-0613
            type: string
          description: The ID of the [Model](/docs/api-reference/models) to be used
            to execute this run. If a value is provided here, it will override the
            model associated with the assistant. If not, the model associated with
            the assistant will be used.
          example: gpt-4-turbo
          x-oaiTypeLabel: string
        parallel_tool_calls:
          $ref: '#/components/schemas/ParallelToolCalls'
        response_format:
          $ref: '#/components/schemas/AssistantsApiResponseFormatOption'
        stream:
          description: 'If `true`, returns a stream of events that happen during the
            Run as server-sent events, terminating when the Run enters a terminal
            state with a `data: [DONE]` message.

            '
          type:
          - boolean
          - 'null'
        temperature:
          default: 1
          description: 'What sampling temperature to use, between 0 and 2. Higher
            values like 0.8 will make the output more random, while lower values like
            0.2 will make it more focused and deterministic.

            '
          example: 1
          maximum: 2
          minimum: 0
          type:
          - number
          - 'null'
        thread:
          $ref: '#/components/schemas/CreateThreadRequest'
          description: If no thread is provided, an empty thread will be created.
        tool_choice:
          $ref: '#/components/schemas/AssistantsApiToolChoiceOption'
        tool_resources:
          description: 'A set of resources that are used by the assistant''s tools.
            The resources are specific to the type of tool. For example, the `code_interpreter`
            tool requires a list of file IDs, while the `file_search` tool requires
            a list of vector store IDs.

            '
          properties:
            code_interpreter:
              properties:
                file_ids:
                  default: []
                  description: 'A list of [file](/docs/api-reference/files) IDs made
                    available to the `code_interpreter` tool. There can be a maximum
                    of 20 files associated with the tool.

                    '
                  items:
                    type: string
                  maxItems: 20
                  type: array
              type: object
            file_search:
              properties:
                vector_store_ids:
                  description: 'The ID of the [vector store](/docs/api-reference/vector-stores/object)
                    attached to this assistant. There can be a maximum of 1 vector
                    store attached to the assistant.

                    '
                  items:
                    type: string
                  maxItems: 1
                  type: array
              type: object
          type:
          - object
          - 'null'
        tools:
          description: Override the tools the assistant can use for this run. This
            is useful for modifying the behavior on a per-run basis.
          items:
            oneOf:
            - $ref: '#/components/schemas/AssistantToolsCode'
            - $ref: '#/components/schemas/AssistantToolsFileSearch'
            - $ref: '#/components/schemas/AssistantToolsFunction'
          maxItems: 20
          type:
          - array
          - 'null'
        top_p:
          default: 1
          description: 'An alternative to sampling with temperature, called nucleus
            sampling, where the model considers the results of the tokens with top_p
            probability mass. So 0.1 means only the tokens comprising the top 10%
            probability mass are considered.


            We generally recommend altering this or temperature but not both.

            '
          example: 1
          maximum: 1
          minimum: 0
          type:
          - number
          - 'null'
        truncation_strategy:
          $ref: '#/components/schemas/TruncationObject'
      required:
      - thread_id
      - assistant_id
      type: object
    CreateThreadRequest:
      additionalProperties: false
      properties:
        messages:
          description: A list of [messages](/docs/api-reference/messages) to start
            the thread with.
          items:
            $ref: '#/components/schemas/CreateMessageRequest'
          type: array
        metadata:
          description: 'Set of 16 key-value pairs that can be attached to an object.
            This can be useful for storing additional information about the object
            in a structured format. Keys can be a maximum of 64 characters long and
            values can be a maxium of 512 characters long.

            '
          type:
          - object
          - 'null'
          x-oaiTypeLabel: map
        tool_resources:
          description: 'A set of resources that are made available to the assistant''s
            tools in this thread. The resources are specific to the type of tool.
            For example, the `code_interpreter` tool requires a list of file IDs,
            while the `file_search` tool requires a list of vector store IDs.

            '
          properties:
            code_interpreter:
              properties:
                file_ids:
                  default: []
                  description: 'A list of [file](/docs/api-reference/files) IDs made
                    available to the `code_interpreter` tool. There can be a maximum
                    of 20 files associated with the tool.

                    '
                  items:
                    type: string
                  maxItems: 20
                  type: array
              type: object
            file_search:
              oneOf:
              - required:
                - vector_store_ids
              - required:
                - vector_stores
              properties:
                vector_store_ids:
                  description: 'The [vector store](/docs/api-reference/vector-stores/object)
                    attached to this thread. There can be a maximum of 1 vector store
                    attached to the thread.

                    '
                  items:
                    type: string
                  maxItems: 1
                  type: array
                vector_stores:
                  description: 'A helper to create a [vector store](/docs/api-reference/vector-stores/object)
                    with file_ids and attach it to this thread. There can be a maximum
                    of 1 vector store attached to the thread.

                    '
                  items:
                    properties:
                      chunking_strategy:
                        description: The chunking strategy used to chunk the file(s).
                          If not set, will use the `auto` strategy.
                        oneOf:
                        - additionalProperties: false
                          description: The default strategy. This strategy currently
                            uses a `max_chunk_size_tokens` of `800` and `chunk_overlap_tokens`
                            of `400`.
                          properties:
                            type:
                              description: Always `auto`.
                              enum:
                              - auto
                              type: string
                          required:
                          - type
                          title: Auto Chunking Strategy
                          type: object
                        - additionalProperties: false
                          properties:
                            static:
                              additionalProperties: false
                              properties:
                                chunk_overlap_tokens:
                                  description: 'The number of tokens that overlap
                                    between chunks. The default value is `400`.


                                    Note that the overlap must not exceed half of
                                    `max_chunk_size_tokens`.

                                    '
                                  type: integer
                                max_chunk_size_tokens:
                                  description: The maximum number of tokens in each
                                    chunk. The default value is `800`. The minimum
                                    value is `100` and the maximum value is `4096`.
                                  maximum: 4096
                                  minimum: 100
                                  type: integer
                              required:
                              - max_chunk_size_tokens
                              - chunk_overlap_tokens
                              type: object
                            type:
                              description: Always `static`.
                              enum:
                              - static
                              type: string
                          required:
                          - type
                          - static
                          title: Static Chunking Strategy
                          type: object
                        type: object
                        x-oaiExpandable: true
                      file_ids:
                        description: 'A list of [file](/docs/api-reference/files)
                          IDs to add to the vector store. There can be a maximum of
                          10000 files in a vector store.

                          '
                        items:
                          type: string
                        maxItems: 10000
                        type: array
                      metadata:
                        description: 'Set of 16 key-value pairs that can be attached
                          to a vector store. This can be useful for storing additional
                          information about the vector store in a structured format.
                          Keys can be a maximum of 64 characters long and values can
                          be a maxium of 512 characters long.

                          '
                        type: object
                        x-oaiTypeLabel: map
                    type: object
                    x-oaiExpandable: true
                  maxItems: 1
                  type: array
              type: object
          type:
          - object
          - 'null'
      type: object
    CreateTranscriptionRequest:
      additionalProperties: false
      properties:
        file:
          description: 'The audio file object (not file name) to transcribe, in one
            of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.

            '
          format: binary
          type: string
          x-oaiTypeLabel: file
        language:
          description: 'The language of the input audio. Supplying the input language
            in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes)
            format will improve accuracy and latency.

            '
          type: string
        model:
          anyOf:
          - type: string
          - enum:
            - whisper-1
            type: string
          description: 'ID of the model to use. Only `whisper-1` (which is powered
            by our open source Whisper V2 model) is currently available.

            '
          example: whisper-1
          x-oaiTypeLabel: string
        prompt:
          description: 'An optional text to guide the model''s style or continue a
            previous audio segment. The [prompt](/docs/guides/speech-to-text/prompting)
            should match the audio language.

            '
          type: string
        response_format:
          default: json
          description: 'The format of the transcript output, in one of these options:
            `json`, `text`, `srt`, `verbose_json`, or `vtt`.

            '
          enum:
          - json
          - text
          - srt
          - verbose_json
          - vtt
          type: string
        temperature:
          default: 0
          description: 'The sampling temperature, between 0 and 1. Higher values like
            0.8 will make the output more random, while lower values like 0.2 will
            make it more focused and deterministic. If set to 0, the model will use
            [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically
            increase the temperature until certain thresholds are hit.

            '
          type: number
        timestamp_granularities[]:
          default:
          - segment
          description: 'The timestamp granularities to populate for this transcription.
            `response_format` must be set `verbose_json` to use timestamp granularities.
            Either or both of these options are supported: `word`, or `segment`. Note:
            There is no additional latency for segment timestamps, but generating
            word timestamps incurs additional latency.

            '
          items:
            enum:
            - word
            - segment
            type: string
          type: array
      required:
      - file
      - model
      type: object
    CreateTranscriptionResponseJson:
      description: Represents a transcription response returned by model, based on
        the provided input.
      properties:
        text:
          description: The transcribed text.
          type: string
      required:
      - text
      type: object
      x-oaiMeta:
        example: "{\n  \"text\": \"Imagine the wildest idea that you've ever had,\
          \ and you're curious about how it might scale to something that's a 100,\
          \ a 1,000 times bigger. This is a place where you can get to do that.\"\n\
          }\n"
        group: audio
        name: The transcription object (JSON)
    CreateTranscriptionResponseVerboseJson:
      description: Represents a verbose json transcription response returned by model,
        based on the provided input.
      properties:
        duration:
          description: The duration of the input audio.
          type: string
        language:
          description: The language of the input audio.
          type: string
        segments:
          description: Segments of the transcribed text and their corresponding details.
          items:
            $ref: '#/components/schemas/TranscriptionSegment'
          type: array
        text:
          description: The transcribed text.
          type: string
        words:
          description: Extracted words and their corresponding timestamps.
          items:
            $ref: '#/components/schemas/TranscriptionWord'
          type: array
      required:
      - language
      - duration
      - text
      type: object
      x-oaiMeta:
        example: "{\n  \"task\": \"transcribe\",\n  \"language\": \"english\",\n \
          \ \"duration\": 8.470000267028809,\n  \"text\": \"The beach was a popular\
          \ spot on a hot summer day. People were swimming in the ocean, building\
          \ sandcastles, and playing beach volleyball.\",\n  \"segments\": [\n   \
          \ {\n      \"id\": 0,\n      \"seek\": 0,\n      \"start\": 0.0,\n     \
          \ \"end\": 3.319999933242798,\n      \"text\": \" The beach was a popular\
          \ spot on a hot summer day.\",\n      \"tokens\": [\n        50364, 440,\
          \ 7534, 390, 257, 3743, 4008, 322, 257, 2368, 4266, 786, 13, 50530\n   \
          \   ],\n      \"temperature\": 0.0,\n      \"avg_logprob\": -0.2860786020755768,\n\
          \      \"compression_ratio\": 1.2363636493682861,\n      \"no_speech_prob\"\
          : 0.00985979475080967\n    },\n    ...\n  ]\n}\n"
        group: audio
        name: The transcription object (Verbose JSON)
    CreateTranslationRequest:
      additionalProperties: false
      properties:
        file:
          description: 'The audio file object (not file name) translate, in one of
            these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.

            '
          format: binary
          type: string
          x-oaiTypeLabel: file
        model:
          anyOf:
          - type: string
          - enum:
            - whisper-1
            type: string
          description: 'ID of the model to use. Only `whisper-1` (which is powered
            by our open source Whisper V2 model) is currently available.

            '
          example: whisper-1
          x-oaiTypeLabel: string
        prompt:
          description: 'An optional text to guide the model''s style or continue a
            previous audio segment. The [prompt](/docs/guides/speech-to-text/prompting)
            should be in English.

            '
          type: string
        response_format:
          default: json
          description: 'The format of the transcript output, in one of these options:
            `json`, `text`, `srt`, `verbose_json`, or `vtt`.

            '
          type: string
        temperature:
          default: 0
          description: 'The sampling temperature, between 0 and 1. Higher values like
            0.8 will make the output more random, while lower values like 0.2 will
            make it more focused and deterministic. If set to 0, the model will use
            [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically
            increase the temperature until certain thresholds are hit.

            '
          type: number
      required:
      - file
      - model
      type: object
    CreateTranslationResponseJson:
      properties:
        text:
          type: string
      required:
      - text
      type: object
    CreateTranslationResponseVerboseJson:
      properties:
        duration:
          description: The duration of the input audio.
          type: string
        language:
          description: The language of the output translation (always `english`).
          type: string
        segments:
          description: Segments of the translated text and their corresponding details.
          items:
            $ref: '#/components/schemas/TranscriptionSegment'
          type: array
        text:
          description: The translated text.
          type: string
      required:
      - language
      - duration
      - text
      type: object
    CreateVectorStoreFileBatchRequest:
      additionalProperties: false
      properties:
        chunking_strategy:
          $ref: '#/components/schemas/ChunkingStrategyRequestParam'
        file_ids:
          description: A list of [File](/docs/api-reference/files) IDs that the vector
            store should use. Useful for tools like `file_search` that can access
            files.
          items:
            type: string
          maxItems: 500
          minItems: 1
          type: array
      required:
      - file_ids
      type: object
    CreateVectorStoreFileRequest:
      additionalProperties: false
      properties:
        chunking_strategy:
          $ref: '#/components/schemas/ChunkingStrategyRequestParam'
        file_id:
          description: A [File](/docs/api-reference/files) ID that the vector store
            should use. Useful for tools like `file_search` that can access files.
          type: string
      required:
      - file_id
      type: object
    CreateVectorStoreRequest:
      additionalProperties: false
      properties:
        chunking_strategy:
          description: The chunking strategy used to chunk the file(s). If not set,
            will use the `auto` strategy. Only applicable if `file_ids` is non-empty.
          oneOf:
          - $ref: '#/components/schemas/AutoChunkingStrategyRequestParam'
          - $ref: '#/components/schemas/StaticChunkingStrategyRequestParam'
          type: object
          x-oaiExpandable: true
        expires_after:
          $ref: '#/components/schemas/VectorStoreExpirationAfter'
        file_ids:
          description: A list of [File](/docs/api-reference/files) IDs that the vector
            store should use. Useful for tools like `file_search` that can access
            files.
          items:
            type: string
          maxItems: 500
          type: array
        metadata:
          description: 'Set of 16 key-value pairs that can be attached to an object.
            This can be useful for storing additional information about the object
            in a structured format. Keys can be a maximum of 64 characters long and
            values can be a maxium of 512 characters long.

            '
          type:
          - object
          - 'null'
          x-oaiTypeLabel: map
        name:
          description: The name of the vector store.
          type: string
      type: object
    DeleteAssistantResponse:
      properties:
        deleted:
          type: boolean
        id:
          type: string
        object:
          enum:
          - assistant.deleted
          type: string
      required:
      - id
      - object
      - deleted
      type: object
    DeleteFileResponse:
      properties:
        deleted:
          type: boolean
        id:
          type: string
        object:
          enum:
          - file
          type: string
      required:
      - id
      - object
      - deleted
      type: object
    DeleteMessageResponse:
      properties:
        deleted:
          type: boolean
        id:
          type: string
        object:
          enum:
          - thread.message.deleted
          type: string
      required:
      - id
      - object
      - deleted
      type: object
    DeleteModelResponse:
      properties:
        deleted:
          type: boolean
        id:
          type: string
        object:
          type: string
      required:
      - id
      - object
      - deleted
      type: object
    DeleteThreadResponse:
      properties:
        deleted:
          type: boolean
        id:
          type: string
        object:
          enum:
          - thread.deleted
          type: string
      required:
      - id
      - object
      - deleted
      type: object
    DeleteVectorStoreFileResponse:
      properties:
        deleted:
          type: boolean
        id:
          type: string
        object:
          enum:
          - vector_store.file.deleted
          type: string
      required:
      - id
      - object
      - deleted
      type: object
    DeleteVectorStoreResponse:
      properties:
        deleted:
          type: boolean
        id:
          type: string
        object:
          enum:
          - vector_store.deleted
          type: string
      required:
      - id
      - object
      - deleted
      type: object
    DoneEvent:
      description: Occurs when a stream ends.
      properties:
        data:
          enum:
          - '[DONE]'
          type: string
        event:
          enum:
          - done
          type: string
      required:
      - event
      - data
      type: object
      x-oaiMeta:
        dataDescription: '`data` is `[DONE]`'
    Embedding:
      description: 'Represents an embedding vector returned by embedding endpoint.

        '
      properties:
        embedding:
          description: 'The embedding vector, which is a list of floats. The length
            of vector depends on the model as listed in the [embedding guide](/docs/guides/embeddings).

            '
          items:
            type: number
          type: array
        index:
          description: The index of the embedding in the list of embeddings.
          type: integer
        object:
          description: The object type, which is always "embedding".
          enum:
          - embedding
          type: string
      required:
      - index
      - object
      - embedding
      type: object
      x-oaiMeta:
        example: "{\n  \"object\": \"embedding\",\n  \"embedding\": [\n    0.0023064255,\n\
          \    -0.009327292,\n    .... (1536 floats total for ada-002)\n    -0.0028842222,\n\
          \  ],\n  \"index\": 0\n}\n"
        name: The embedding object
    Error:
      properties:
        code:
          type:
          - string
          - 'null'
        message:
          type: string
        param:
          type:
          - string
          - 'null'
        type:
          type: string
      required:
      - type
      - message
      - param
      - code
      type: object
    ErrorEvent:
      description: Occurs when an [error](/docs/guides/error-codes/api-errors) occurs.
        This can happen due to an internal server error or a timeout.
      properties:
        data:
          $ref: '#/components/schemas/Error'
        event:
          enum:
          - error
          type: string
      required:
      - event
      - data
      type: object
      x-oaiMeta:
        dataDescription: '`data` is an [error](/docs/guides/error-codes/api-errors)'
    ErrorResponse:
      properties:
        error:
          $ref: '#/components/schemas/Error'
      required:
      - error
      type: object
    FineTuneChatCompletionRequestAssistantMessage:
      allOf:
      - deprecated: false
        properties:
          weight:
            description: Controls whether the assistant message is trained against
              (0 or 1)
            enum:
            - 0
            - 1
            type: integer
        title: Assistant message
        type: object
      - $ref: '#/components/schemas/ChatCompletionRequestAssistantMessage'
      required:
      - role
    FineTuningIntegration:
      properties:
        type:
          description: The type of the integration being enabled for the fine-tuning
            job
          enum:
          - wandb
          type: string
        wandb:
          description: 'The settings for your integration with Weights and Biases.
            This payload specifies the project that

            metrics will be sent to. Optionally, you can set an explicit display name
            for your run, add tags

            to your run, and set a default entity (team, username, etc) to be associated
            with your run.

            '
          properties:
            entity:
              description: 'The entity to use for the run. This allows you to set
                the team or username of the WandB user that you would

                like associated with the run. If not set, the default entity for the
                registered WandB API key is used.

                '
              type:
              - string
              - 'null'
            name:
              description: 'A display name to set for the run. If not set, we will
                use the Job ID as the name.

                '
              type:
              - string
              - 'null'
            project:
              description: 'The name of the project that the new run will be created
                under.

                '
              example: my-wandb-project
              type: string
            tags:
              description: 'A list of tags to be attached to the newly created run.
                These tags are passed through directly to WandB. Some

                default tags are generated by OpenAI: "openai/finetune", "openai/{base-model}",
                "openai/{ftjob-abcdef}".

                '
              items:
                example: custom-tag
                type: string
              type: array
          required:
          - project
          type: object
      required:
      - type
      - wandb
      title: Fine-Tuning Job Integration
      type: object
    FineTuningJob:
      description: 'The `fine_tuning.job` object represents a fine-tuning job that
        has been created through the API.

        '
      properties:
        created_at:
          description: The Unix timestamp (in seconds) for when the fine-tuning job
            was created.
          type: integer
        error:
          description: For fine-tuning jobs that have `failed`, this will contain
            more information on the cause of the failure.
          properties:
            code:
              description: A machine-readable error code.
              type: string
            message:
              description: A human-readable error message.
              type: string
            param:
              description: The parameter that was invalid, usually `training_file`
                or `validation_file`. This field will be null if the failure was not
                parameter-specific.
              type:
              - string
              - 'null'
          required:
          - code
          - message
          - param
          type:
          - object
          - 'null'
        estimated_finish:
          description: The Unix timestamp (in seconds) for when the fine-tuning job
            is estimated to finish. The value will be null if the fine-tuning job
            is not running.
          type:
          - integer
          - 'null'
        fine_tuned_model:
          description: The name of the fine-tuned model that is being created. The
            value will be null if the fine-tuning job is still running.
          type:
          - string
          - 'null'
        finished_at:
          description: The Unix timestamp (in seconds) for when the fine-tuning job
            was finished. The value will be null if the fine-tuning job is still running.
          type:
          - integer
          - 'null'
        hyperparameters:
          description: The hyperparameters used for the fine-tuning job. See the [fine-tuning
            guide](/docs/guides/fine-tuning) for more details.
          properties:
            n_epochs:
              default: auto
              description: 'The number of epochs to train the model for. An epoch
                refers to one full cycle through the training dataset.

                "auto" decides the optimal number of epochs based on the size of the
                dataset. If setting the number manually, we support any number between
                1 and 50 epochs.'
              oneOf:
              - enum:
                - auto
                type: string
              - maximum: 50
                minimum: 1
                type: integer
          required:
          - n_epochs
          type: object
        id:
          description: The object identifier, which can be referenced in the API endpoints.
          type: string
        integrations:
          description: A list of integrations to enable for this fine-tuning job.
          items:
            oneOf:
            - $ref: '#/components/schemas/FineTuningIntegration'
            x-oaiExpandable: true
          maxItems: 5
          type:
          - array
          - 'null'
        model:
          description: The base model that is being fine-tuned.
          type: string
        object:
          description: The object type, which is always "fine_tuning.job".
          enum:
          - fine_tuning.job
          type: string
        organization_id:
          description: The organization that owns the fine-tuning job.
          type: string
        result_files:
          description: The compiled results file ID(s) for the fine-tuning job. You
            can retrieve the results with the [Files API](/docs/api-reference/files/retrieve-contents).
          items:
            example: file-abc123
            type: string
          type: array
        seed:
          description: The seed used for the fine-tuning job.
          type: integer
        status:
          description: The current status of the fine-tuning job, which can be either
            `validating_files`, `queued`, `running`, `succeeded`, `failed`, or `cancelled`.
          enum:
          - validating_files
          - queued
          - running
          - succeeded
          - failed
          - cancelled
          type: string
        trained_tokens:
          description: The total number of billable tokens processed by this fine-tuning
            job. The value will be null if the fine-tuning job is still running.
          type:
          - integer
          - 'null'
        training_file:
          description: The file ID used for training. You can retrieve the training
            data with the [Files API](/docs/api-reference/files/retrieve-contents).
          type: string
        validation_file:
          description: The file ID used for validation. You can retrieve the validation
            results with the [Files API](/docs/api-reference/files/retrieve-contents).
          type:
          - string
          - 'null'
      required:
      - created_at
      - error
      - finished_at
      - fine_tuned_model
      - hyperparameters
      - id
      - model
      - object
      - organization_id
      - result_files
      - status
      - trained_tokens
      - training_file
      - validation_file
      - seed
      title: FineTuningJob
      type: object
      x-oaiMeta:
        example: "{\n  \"object\": \"fine_tuning.job\",\n  \"id\": \"ftjob-abc123\"\
          ,\n  \"model\": \"davinci-002\",\n  \"created_at\": 1692661014,\n  \"finished_at\"\
          : 1692661190,\n  \"fine_tuned_model\": \"ft:davinci-002:my-org:custom_suffix:7q8mpxmy\"\
          ,\n  \"organization_id\": \"org-123\",\n  \"result_files\": [\n      \"\
          file-abc123\"\n  ],\n  \"status\": \"succeeded\",\n  \"validation_file\"\
          : null,\n  \"training_file\": \"file-abc123\",\n  \"hyperparameters\": {\n\
          \      \"n_epochs\": 4,\n      \"batch_size\": 1,\n      \"learning_rate_multiplier\"\
          : 1.0\n  },\n  \"trained_tokens\": 5768,\n  \"integrations\": [],\n  \"\
          seed\": 0,\n  \"estimated_finish\": 0\n}\n"
        name: The fine-tuning job object
    FineTuningJobCheckpoint:
      description: 'The `fine_tuning.job.checkpoint` object represents a model checkpoint
        for a fine-tuning job that is ready to use.

        '
      properties:
        created_at:
          description: The Unix timestamp (in seconds) for when the checkpoint was
            created.
          type: integer
        fine_tuned_model_checkpoint:
          description: The name of the fine-tuned checkpoint model that is created.
          type: string
        fine_tuning_job_id:
          description: The name of the fine-tuning job that this checkpoint was created
            from.
          type: string
        id:
          description: The checkpoint identifier, which can be referenced in the API
            endpoints.
          type: string
        metrics:
          description: Metrics at the step number during the fine-tuning job.
          properties:
            full_valid_loss:
              type: number
            full_valid_mean_token_accuracy:
              type: number
            step:
              type: number
            train_loss:
              type: number
            train_mean_token_accuracy:
              type: number
            valid_loss:
              type: number
            valid_mean_token_accuracy:
              type: number
          type: object
        object:
          description: The object type, which is always "fine_tuning.job.checkpoint".
          enum:
          - fine_tuning.job.checkpoint
          type: string
        step_number:
          description: The step number that the checkpoint was created at.
          type: integer
      required:
      - created_at
      - fine_tuning_job_id
      - fine_tuned_model_checkpoint
      - id
      - metrics
      - object
      - step_number
      title: FineTuningJobCheckpoint
      type: object
      x-oaiMeta:
        example: "{\n  \"object\": \"fine_tuning.job.checkpoint\",\n  \"id\": \"ftckpt_qtZ5Gyk4BLq1SfLFWp3RtO3P\"\
          ,\n  \"created_at\": 1712211699,\n  \"fine_tuned_model_checkpoint\": \"\
          ft:gpt-3.5-turbo-0125:my-org:custom_suffix:9ABel2dg:ckpt-step-88\",\n  \"\
          fine_tuning_job_id\": \"ftjob-fpbNQ3H1GrMehXRf8cO97xTN\",\n  \"metrics\"\
          : {\n    \"step\": 88,\n    \"train_loss\": 0.478,\n    \"train_mean_token_accuracy\"\
          : 0.924,\n    \"valid_loss\": 10.112,\n    \"valid_mean_token_accuracy\"\
          : 0.145,\n    \"full_valid_loss\": 0.567,\n    \"full_valid_mean_token_accuracy\"\
          : 0.944\n  },\n  \"step_number\": 88\n}\n"
        name: The fine-tuning job checkpoint object
    FineTuningJobEvent:
      description: Fine-tuning job event object
      properties:
        created_at:
          type: integer
        id:
          type: string
        level:
          enum:
          - info
          - warn
          - error
          type: string
        message:
          type: string
        object:
          enum:
          - fine_tuning.job.event
          type: string
      required:
      - id
      - object
      - created_at
      - level
      - message
      type: object
      x-oaiMeta:
        example: "{\n  \"object\": \"fine_tuning.job.event\",\n  \"id\": \"ftevent-abc123\"\
          \n  \"created_at\": 1677610602,\n  \"level\": \"info\",\n  \"message\":\
          \ \"Created fine-tuning job\"\n}\n"
        name: The fine-tuning job event object
    FinetuneChatRequestInput:
      description: The per-line training example of a fine-tuning input file for chat
        models
      properties:
        functions:
          deprecated: true
          description: A list of functions the model may generate JSON inputs for.
          items:
            $ref: '#/components/schemas/ChatCompletionFunctions'
          maxItems: 128
          minItems: 1
          type: array
        messages:
          items:
            oneOf:
            - $ref: '#/components/schemas/ChatCompletionRequestSystemMessage'
            - $ref: '#/components/schemas/ChatCompletionRequestUserMessage'
            - $ref: '#/components/schemas/FineTuneChatCompletionRequestAssistantMessage'
            - $ref: '#/components/schemas/ChatCompletionRequestToolMessage'
            - $ref: '#/components/schemas/ChatCompletionRequestFunctionMessage'
            x-oaiExpandable: true
          minItems: 1
          type: array
        parallel_tool_calls:
          $ref: '#/components/schemas/ParallelToolCalls'
        tools:
          description: A list of tools the model may generate JSON inputs for.
          items:
            $ref: '#/components/schemas/ChatCompletionTool'
          type: array
      type: object
      x-oaiMeta:
        example: "{\n  \"messages\": [\n    { \"role\": \"user\", \"content\": \"\
          What is the weather in San Francisco?\" },\n    {\n      \"role\": \"assistant\"\
          ,\n      \"tool_calls\": [\n        {\n          \"id\": \"call_id\",\n\
          \          \"type\": \"function\",\n          \"function\": {\n        \
          \    \"name\": \"get_current_weather\",\n            \"arguments\": \"{\\\
          \"location\\\": \\\"San Francisco, USA\\\", \\\"format\\\": \\\"celsius\\\
          \"}\"\n          }\n        }\n      ]\n    }\n  ],\n  \"parallel_tool_calls\"\
          : false,\n  \"tools\": [\n    {\n      \"type\": \"function\",\n      \"\
          function\": {\n        \"name\": \"get_current_weather\",\n        \"description\"\
          : \"Get the current weather\",\n        \"parameters\": {\n          \"\
          type\": \"object\",\n          \"properties\": {\n            \"location\"\
          : {\n                \"type\": \"string\",\n                \"description\"\
          : \"The city and country, eg. San Francisco, USA\"\n            },\n   \
          \         \"format\": { \"type\": \"string\", \"enum\": [\"celsius\", \"\
          fahrenheit\"] }\n          },\n          \"required\": [\"location\", \"\
          format\"]\n        }\n      }\n    }\n  ]\n}\n"
        name: Training format for chat models
    FinetuneCompletionRequestInput:
      description: The per-line training example of a fine-tuning input file for completions
        models
      properties:
        completion:
          description: The desired completion for this training example.
          type: string
        prompt:
          description: The input prompt for this training example.
          type: string
      type: object
      x-oaiMeta:
        example: "{\n  \"prompt\": \"What is the answer to 2+2\",\n  \"completion\"\
          : \"4\"\n}\n"
        name: Training format for completions models
    FunctionObject:
      properties:
        description:
          description: A description of what the function does, used by the model
            to choose when and how to call the function.
          type: string
        name:
          description: The name of the function to be called. Must be a-z, A-Z, 0-9,
            or contain underscores and dashes, with a maximum length of 64.
          type: string
        parameters:
          $ref: '#/components/schemas/FunctionParameters'
      required:
      - name
      type: object
    FunctionParameters:
      additionalProperties: true
      description: "The parameters the functions accepts, described as a JSON Schema\
        \ object. See the [guide](/docs/guides/function-calling) for examples, and\
        \ the [JSON Schema reference](https://json-schema.org/understanding-json-schema/)\
        \ for documentation about the format. \n\nOmitting `parameters` defines a\
        \ function with an empty parameter list."
      type: object
    Image:
      description: Represents the url or the content of an image generated by the
        OpenAI API.
      properties:
        b64_json:
          description: The base64-encoded JSON of the generated image, if `response_format`
            is `b64_json`.
          type: string
        revised_prompt:
          description: The prompt that was used to generate the image, if there was
            any revision to the prompt.
          type: string
        url:
          description: The URL of the generated image, if `response_format` is `url`
            (default).
          type: string
      type: object
      x-oaiMeta:
        example: "{\n  \"url\": \"...\",\n  \"revised_prompt\": \"...\"\n}\n"
        name: The image object
    ImagesResponse:
      properties:
        created:
          type: integer
        data:
          items:
            $ref: '#/components/schemas/Image'
          type: array
      required:
      - created
      - data
    ListAssistantsResponse:
      properties:
        data:
          items:
            $ref: '#/components/schemas/AssistantObject'
          type: array
        first_id:
          example: asst_abc123
          type: string
        has_more:
          example: false
          type: boolean
        last_id:
          example: asst_abc456
          type: string
        object:
          example: list
          type: string
      required:
      - object
      - data
      - first_id
      - last_id
      - has_more
      type: object
      x-oaiMeta:
        example: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\":\
          \ \"asst_abc123\",\n      \"object\": \"assistant\",\n      \"created_at\"\
          : 1698982736,\n      \"name\": \"Coding Tutor\",\n      \"description\"\
          : null,\n      \"model\": \"gpt-4-turbo\",\n      \"instructions\": \"You\
          \ are a helpful assistant designed to make me better at coding!\",\n   \
          \   \"tools\": [],\n      \"tool_resources\": {},\n      \"metadata\": {},\n\
          \      \"top_p\": 1.0,\n      \"temperature\": 1.0,\n      \"response_format\"\
          : \"auto\"\n    },\n    {\n      \"id\": \"asst_abc456\",\n      \"object\"\
          : \"assistant\",\n      \"created_at\": 1698982718,\n      \"name\": \"\
          My Assistant\",\n      \"description\": null,\n      \"model\": \"gpt-4-turbo\"\
          ,\n      \"instructions\": \"You are a helpful assistant designed to make\
          \ me better at coding!\",\n      \"tools\": [],\n      \"tool_resources\"\
          : {},\n      \"metadata\": {},\n      \"top_p\": 1.0,\n      \"temperature\"\
          : 1.0,\n      \"response_format\": \"auto\"\n    },\n    {\n      \"id\"\
          : \"asst_abc789\",\n      \"object\": \"assistant\",\n      \"created_at\"\
          : 1698982643,\n      \"name\": null,\n      \"description\": null,\n   \
          \   \"model\": \"gpt-4-turbo\",\n      \"instructions\": null,\n      \"\
          tools\": [],\n      \"tool_resources\": {},\n      \"metadata\": {},\n \
          \     \"top_p\": 1.0,\n      \"temperature\": 1.0,\n      \"response_format\"\
          : \"auto\"\n    }\n  ],\n  \"first_id\": \"asst_abc123\",\n  \"last_id\"\
          : \"asst_abc789\",\n  \"has_more\": false\n}\n"
        group: chat
        name: List assistants response object
    ListBatchesResponse:
      properties:
        data:
          items:
            $ref: '#/components/schemas/Batch'
          type: array
        first_id:
          example: batch_abc123
          type: string
        has_more:
          type: boolean
        last_id:
          example: batch_abc456
          type: string
        object:
          enum:
          - list
          type: string
      required:
      - object
      - data
      - has_more
      type: object
    ListFilesResponse:
      properties:
        data:
          items:
            $ref: '#/components/schemas/OpenAIFile'
          type: array
        object:
          enum:
          - list
          type: string
      required:
      - object
      - data
      type: object
    ListFineTuningJobCheckpointsResponse:
      properties:
        data:
          items:
            $ref: '#/components/schemas/FineTuningJobCheckpoint'
          type: array
        first_id:
          type:
          - string
          - 'null'
        has_more:
          type: boolean
        last_id:
          type:
          - string
          - 'null'
        object:
          enum:
          - list
          type: string
      required:
      - object
      - data
      - has_more
      type: object
    ListFineTuningJobEventsResponse:
      properties:
        data:
          items:
            $ref: '#/components/schemas/FineTuningJobEvent'
          type: array
        object:
          enum:
          - list
          type: string
      required:
      - object
      - data
      type: object
    ListMessagesResponse:
      properties:
        data:
          items:
            $ref: '#/components/schemas/MessageObject'
          type: array
        first_id:
          example: msg_abc123
          type: string
        has_more:
          example: false
          type: boolean
        last_id:
          example: msg_abc123
          type: string
        object:
          example: list
          type: string
      required:
      - object
      - data
      - first_id
      - last_id
      - has_more
    ListModelsResponse:
      properties:
        data:
          items:
            $ref: '#/components/schemas/Model'
          type: array
        object:
          enum:
          - list
          type: string
      required:
      - object
      - data
      type: object
    ListPaginatedFineTuningJobsResponse:
      properties:
        data:
          items:
            $ref: '#/components/schemas/FineTuningJob'
          type: array
        has_more:
          type: boolean
        object:
          enum:
          - list
          type: string
      required:
      - object
      - data
      - has_more
      type: object
    ListRunStepsResponse:
      properties:
        data:
          items:
            $ref: '#/components/schemas/RunStepObject'
          type: array
        first_id:
          example: step_abc123
          type: string
        has_more:
          example: false
          type: boolean
        last_id:
          example: step_abc456
          type: string
        object:
          example: list
          type: string
      required:
      - object
      - data
      - first_id
      - last_id
      - has_more
    ListRunsResponse:
      properties:
        data:
          items:
            $ref: '#/components/schemas/RunObject'
          type: array
        first_id:
          example: run_abc123
          type: string
        has_more:
          example: false
          type: boolean
        last_id:
          example: run_abc456
          type: string
        object:
          example: list
          type: string
      required:
      - object
      - data
      - first_id
      - last_id
      - has_more
      type: object
    ListThreadsResponse:
      properties:
        data:
          items:
            $ref: '#/components/schemas/ThreadObject'
          type: array
        first_id:
          example: asst_abc123
          type: string
        has_more:
          example: false
          type: boolean
        last_id:
          example: asst_abc456
          type: string
        object:
          example: list
          type: string
      required:
      - object
      - data
      - first_id
      - last_id
      - has_more
    ListVectorStoreFilesResponse:
      properties:
        data:
          items:
            $ref: '#/components/schemas/VectorStoreFileObject'
          type: array
        first_id:
          example: file-abc123
          type: string
        has_more:
          example: false
          type: boolean
        last_id:
          example: file-abc456
          type: string
        object:
          example: list
          type: string
      required:
      - object
      - data
      - first_id
      - last_id
      - has_more
    ListVectorStoresResponse:
      properties:
        data:
          items:
            $ref: '#/components/schemas/VectorStoreObject'
          type: array
        first_id:
          example: vs_abc123
          type: string
        has_more:
          example: false
          type: boolean
        last_id:
          example: vs_abc456
          type: string
        object:
          example: list
          type: string
      required:
      - object
      - data
      - first_id
      - last_id
      - has_more
    MessageContentImageFileObject:
      description: References an image [File](/docs/api-reference/files) in the content
        of a message.
      properties:
        image_file:
          properties:
            detail:
              default: auto
              description: Specifies the detail level of the image if specified by
                the user. `low` uses fewer tokens, you can opt in to high resolution
                using `high`.
              enum:
              - auto
              - low
              - high
              type: string
            file_id:
              description: The [File](/docs/api-reference/files) ID of the image in
                the message content. Set `purpose="vision"` when uploading the File
                if you need to later display the file content.
              type: string
          required:
          - file_id
          type: object
        type:
          description: Always `image_file`.
          enum:
          - image_file
          type: string
      required:
      - type
      - image_file
      title: Image file
      type: object
    MessageContentImageUrlObject:
      description: References an image URL in the content of a message.
      properties:
        image_url:
          properties:
            detail:
              default: auto
              description: Specifies the detail level of the image. `low` uses fewer
                tokens, you can opt in to high resolution using `high`. Default value
                is `auto`
              enum:
              - auto
              - low
              - high
              type: string
            url:
              description: 'The external URL of the image, must be a supported image
                types: jpeg, jpg, png, gif, webp.'
              format: uri
              type: string
          required:
          - url
          type: object
        type:
          description: The type of the content part.
          enum:
          - image_url
          type: string
      required:
      - type
      - image_url
      title: Image URL
      type: object
    MessageContentTextAnnotationsFileCitationObject:
      description: A citation within the message that points to a specific quote from
        a specific File associated with the assistant or the message. Generated when
        the assistant uses the "file_search" tool to search files.
      properties:
        end_index:
          minimum: 0
          type: integer
        file_citation:
          properties:
            file_id:
              description: The ID of the specific File the citation is from.
              type: string
          required:
          - file_id
          type: object
        start_index:
          minimum: 0
          type: integer
        text:
          description: The text in the message content that needs to be replaced.
          type: string
        type:
          description: Always `file_citation`.
          enum:
          - file_citation
          type: string
      required:
      - type
      - text
      - file_citation
      - start_index
      - end_index
      title: File citation
      type: object
    MessageContentTextAnnotationsFilePathObject:
      description: A URL for the file that's generated when the assistant used the
        `code_interpreter` tool to generate a file.
      properties:
        end_index:
          minimum: 0
          type: integer
        file_path:
          properties:
            file_id:
              description: The ID of the file that was generated.
              type: string
          required:
          - file_id
          type: object
        start_index:
          minimum: 0
          type: integer
        text:
          description: The text in the message content that needs to be replaced.
          type: string
        type:
          description: Always `file_path`.
          enum:
          - file_path
          type: string
      required:
      - type
      - text
      - file_path
      - start_index
      - end_index
      title: File path
      type: object
    MessageContentTextObject:
      description: The text content that is part of a message.
      properties:
        text:
          properties:
            annotations:
              items:
                oneOf:
                - $ref: '#/components/schemas/MessageContentTextAnnotationsFileCitationObject'
                - $ref: '#/components/schemas/MessageContentTextAnnotationsFilePathObject'
                x-oaiExpandable: true
              type: array
            value:
              description: The data that makes up the text.
              type: string
          required:
          - value
          - annotations
          type: object
        type:
          description: Always `text`.
          enum:
          - text
          type: string
      required:
      - type
      - text
      title: Text
      type: object
    MessageDeltaContentImageFileObject:
      description: References an image [File](/docs/api-reference/files) in the content
        of a message.
      properties:
        image_file:
          properties:
            detail:
              default: auto
              description: Specifies the detail level of the image if specified by
                the user. `low` uses fewer tokens, you can opt in to high resolution
                using `high`.
              enum:
              - auto
              - low
              - high
              type: string
            file_id:
              description: The [File](/docs/api-reference/files) ID of the image in
                the message content. Set `purpose="vision"` when uploading the File
                if you need to later display the file content.
              type: string
          type: object
        index:
          description: The index of the content part in the message.
          type: integer
        type:
          description: Always `image_file`.
          enum:
          - image_file
          type: string
      required:
      - index
      - type
      title: Image file
      type: object
    MessageDeltaContentImageUrlObject:
      description: References an image URL in the content of a message.
      properties:
        image_url:
          properties:
            detail:
              default: auto
              description: Specifies the detail level of the image. `low` uses fewer
                tokens, you can opt in to high resolution using `high`.
              enum:
              - auto
              - low
              - high
              type: string
            url:
              description: 'The URL of the image, must be a supported image types:
                jpeg, jpg, png, gif, webp.'
              type: string
          type: object
        index:
          description: The index of the content part in the message.
          type: integer
        type:
          description: Always `image_url`.
          enum:
          - image_url
          type: string
      required:
      - index
      - type
      title: Image URL
      type: object
    MessageDeltaContentTextAnnotationsFileCitationObject:
      description: A citation within the message that points to a specific quote from
        a specific File associated with the assistant or the message. Generated when
        the assistant uses the "file_search" tool to search files.
      properties:
        end_index:
          minimum: 0
          type: integer
        file_citation:
          properties:
            file_id:
              description: The ID of the specific File the citation is from.
              type: string
            quote:
              description: The specific quote in the file.
              type: string
          type: object
        index:
          description: The index of the annotation in the text content part.
          type: integer
        start_index:
          minimum: 0
          type: integer
        text:
          description: The text in the message content that needs to be replaced.
          type: string
        type:
          description: Always `file_citation`.
          enum:
          - file_citation
          type: string
      required:
      - index
      - type
      title: File citation
      type: object
    MessageDeltaContentTextAnnotationsFilePathObject:
      description: A URL for the file that's generated when the assistant used the
        `code_interpreter` tool to generate a file.
      properties:
        end_index:
          minimum: 0
          type: integer
        file_path:
          properties:
            file_id:
              description: The ID of the file that was generated.
              type: string
          type: object
        index:
          description: The index of the annotation in the text content part.
          type: integer
        start_index:
          minimum: 0
          type: integer
        text:
          description: The text in the message content that needs to be replaced.
          type: string
        type:
          description: Always `file_path`.
          enum:
          - file_path
          type: string
      required:
      - index
      - type
      title: File path
      type: object
    MessageDeltaContentTextObject:
      description: The text content that is part of a message.
      properties:
        index:
          description: The index of the content part in the message.
          type: integer
        text:
          properties:
            annotations:
              items:
                oneOf:
                - $ref: '#/components/schemas/MessageDeltaContentTextAnnotationsFileCitationObject'
                - $ref: '#/components/schemas/MessageDeltaContentTextAnnotationsFilePathObject'
                x-oaiExpandable: true
              type: array
            value:
              description: The data that makes up the text.
              type: string
          type: object
        type:
          description: Always `text`.
          enum:
          - text
          type: string
      required:
      - index
      - type
      title: Text
      type: object
    MessageDeltaObject:
      description: 'Represents a message delta i.e. any changed fields on a message
        during streaming.

        '
      properties:
        delta:
          description: The delta containing the fields that have changed on the Message.
          properties:
            content:
              description: The content of the message in array of text and/or images.
              items:
                oneOf:
                - $ref: '#/components/schemas/MessageDeltaContentImageFileObject'
                - $ref: '#/components/schemas/MessageDeltaContentTextObject'
                - $ref: '#/components/schemas/MessageDeltaContentImageUrlObject'
                x-oaiExpandable: true
              type: array
            role:
              description: The entity that produced the message. One of `user` or
                `assistant`.
              enum:
              - user
              - assistant
              type: string
          type: object
        id:
          description: The identifier of the message, which can be referenced in API
            endpoints.
          type: string
        object:
          description: The object type, which is always `thread.message.delta`.
          enum:
          - thread.message.delta
          type: string
      required:
      - id
      - object
      - delta
      title: Message delta object
      type: object
      x-oaiMeta:
        beta: true
        example: "{\n  \"id\": \"msg_123\",\n  \"object\": \"thread.message.delta\"\
          ,\n  \"delta\": {\n    \"content\": [\n      {\n        \"index\": 0,\n\
          \        \"type\": \"text\",\n        \"text\": { \"value\": \"Hello\",\
          \ \"annotations\": [] }\n      }\n    ]\n  }\n}\n"
        name: The message delta object
    MessageObject:
      description: Represents a message within a [thread](/docs/api-reference/threads).
      properties:
        assistant_id:
          description: If applicable, the ID of the [assistant](/docs/api-reference/assistants)
            that authored this message.
          type:
          - string
          - 'null'
        attachments:
          description: A list of files attached to the message, and the tools they
            were added to.
          items:
            properties:
              file_id:
                description: The ID of the file to attach to the message.
                type: string
              tools:
                description: The tools to add this file to.
                items:
                  oneOf:
                  - $ref: '#/components/schemas/AssistantToolsCode'
                  - $ref: '#/components/schemas/AssistantToolsFileSearchTypeOnly'
                  x-oaiExpandable: true
                type: array
            type: object
          type:
          - array
          - 'null'
        completed_at:
          description: The Unix timestamp (in seconds) for when the message was completed.
          type:
          - integer
          - 'null'
        content:
          description: The content of the message in array of text and/or images.
          items:
            oneOf:
            - $ref: '#/components/schemas/MessageContentImageFileObject'
            - $ref: '#/components/schemas/MessageContentImageUrlObject'
            - $ref: '#/components/schemas/MessageContentTextObject'
            x-oaiExpandable: true
          type: array
        created_at:
          description: The Unix timestamp (in seconds) for when the message was created.
          type: integer
        id:
          description: The identifier, which can be referenced in API endpoints.
          type: string
        incomplete_at:
          description: The Unix timestamp (in seconds) for when the message was marked
            as incomplete.
          type:
          - integer
          - 'null'
        incomplete_details:
          description: On an incomplete message, details about why the message is
            incomplete.
          properties:
            reason:
              description: The reason the message is incomplete.
              enum:
              - content_filter
              - max_tokens
              - run_cancelled
              - run_expired
              - run_failed
              type: string
          required:
          - reason
          type:
          - object
          - 'null'
        metadata:
          description: 'Set of 16 key-value pairs that can be attached to an object.
            This can be useful for storing additional information about the object
            in a structured format. Keys can be a maximum of 64 characters long and
            values can be a maxium of 512 characters long.

            '
          type:
          - object
          - 'null'
          x-oaiTypeLabel: map
        object:
          description: The object type, which is always `thread.message`.
          enum:
          - thread.message
          type: string
        role:
          description: The entity that produced the message. One of `user` or `assistant`.
          enum:
          - user
          - assistant
          type: string
        run_id:
          description: The ID of the [run](/docs/api-reference/runs) associated with
            the creation of this message. Value is `null` when messages are created
            manually using the create message or create thread endpoints.
          type:
          - string
          - 'null'
        status:
          description: The status of the message, which can be either `in_progress`,
            `incomplete`, or `completed`.
          enum:
          - in_progress
          - incomplete
          - completed
          type: string
        thread_id:
          description: The [thread](/docs/api-reference/threads) ID that this message
            belongs to.
          type: string
      required:
      - id
      - object
      - created_at
      - thread_id
      - status
      - incomplete_details
      - completed_at
      - incomplete_at
      - role
      - content
      - assistant_id
      - run_id
      - attachments
      - metadata
      title: The message object
      type: object
      x-oaiMeta:
        beta: true
        example: "{\n  \"id\": \"msg_abc123\",\n  \"object\": \"thread.message\",\n\
          \  \"created_at\": 1698983503,\n  \"thread_id\": \"thread_abc123\",\n  \"\
          role\": \"assistant\",\n  \"content\": [\n    {\n      \"type\": \"text\"\
          ,\n      \"text\": {\n        \"value\": \"Hi! How can I help you today?\"\
          ,\n        \"annotations\": []\n      }\n    }\n  ],\n  \"assistant_id\"\
          : \"asst_abc123\",\n  \"run_id\": \"run_abc123\",\n  \"attachments\": [],\n\
          \  \"metadata\": {}\n}\n"
        name: The message object
    MessageRequestContentTextObject:
      description: The text content that is part of a message.
      properties:
        text:
          description: Text content to be sent to the model
          type: string
        type:
          description: Always `text`.
          enum:
          - text
          type: string
      required:
      - type
      - text
      title: Text
      type: object
    MessageStreamEvent:
      oneOf:
      - description: Occurs when a [message](/docs/api-reference/messages/object)
          is created.
        properties:
          data:
            $ref: '#/components/schemas/MessageObject'
          event:
            enum:
            - thread.message.created
            type: string
        required:
        - event
        - data
        type: object
        x-oaiMeta:
          dataDescription: '`data` is a [message](/docs/api-reference/messages/object)'
      - description: Occurs when a [message](/docs/api-reference/messages/object)
          moves to an `in_progress` state.
        properties:
          data:
            $ref: '#/components/schemas/MessageObject'
          event:
            enum:
            - thread.message.in_progress
            type: string
        required:
        - event
        - data
        type: object
        x-oaiMeta:
          dataDescription: '`data` is a [message](/docs/api-reference/messages/object)'
      - description: Occurs when parts of a [Message](/docs/api-reference/messages/object)
          are being streamed.
        properties:
          data:
            $ref: '#/components/schemas/MessageDeltaObject'
          event:
            enum:
            - thread.message.delta
            type: string
        required:
        - event
        - data
        type: object
        x-oaiMeta:
          dataDescription: '`data` is a [message delta](/docs/api-reference/assistants-streaming/message-delta-object)'
      - description: Occurs when a [message](/docs/api-reference/messages/object)
          is completed.
        properties:
          data:
            $ref: '#/components/schemas/MessageObject'
          event:
            enum:
            - thread.message.completed
            type: string
        required:
        - event
        - data
        type: object
        x-oaiMeta:
          dataDescription: '`data` is a [message](/docs/api-reference/messages/object)'
      - description: Occurs when a [message](/docs/api-reference/messages/object)
          ends before it is completed.
        properties:
          data:
            $ref: '#/components/schemas/MessageObject'
          event:
            enum:
            - thread.message.incomplete
            type: string
        required:
        - event
        - data
        type: object
        x-oaiMeta:
          dataDescription: '`data` is a [message](/docs/api-reference/messages/object)'
    Model:
      description: Describes an OpenAI model offering that can be used with the API.
      properties:
        created:
          description: The Unix timestamp (in seconds) when the model was created.
          type: integer
        id:
          description: The model identifier, which can be referenced in the API endpoints.
          type: string
        object:
          description: The object type, which is always "model".
          enum:
          - model
          type: string
        owned_by:
          description: The organization that owns the model.
          type: string
      required:
      - id
      - object
      - created
      - owned_by
      title: Model
      x-oaiMeta:
        example: "{\n  \"id\": \"VAR_model_id\",\n  \"object\": \"model\",\n  \"created\"\
          : 1686935002,\n  \"owned_by\": \"openai\"\n}\n"
        name: The model object
    ModifyAssistantRequest:
      additionalProperties: false
      properties:
        description:
          description: 'The description of the assistant. The maximum length is 512
            characters.

            '
          maxLength: 512
          type:
          - string
          - 'null'
        instructions:
          description: 'The system instructions that the assistant uses. The maximum
            length is 256,000 characters.

            '
          maxLength: 256000
          type:
          - string
          - 'null'
        metadata:
          description: 'Set of 16 key-value pairs that can be attached to an object.
            This can be useful for storing additional information about the object
            in a structured format. Keys can be a maximum of 64 characters long and
            values can be a maxium of 512 characters long.

            '
          type:
          - object
          - 'null'
          x-oaiTypeLabel: map
        model:
          anyOf:
          - type: string
          description: 'ID of the model to use. You can use the [List models](/docs/api-reference/models/list)
            API to see all of your available models, or see our [Model overview](/docs/models/overview)
            for descriptions of them.

            '
        name:
          description: 'The name of the assistant. The maximum length is 256 characters.

            '
          maxLength: 256
          type:
          - string
          - 'null'
        response_format:
          $ref: '#/components/schemas/AssistantsApiResponseFormatOption'
        temperature:
          default: 1
          description: 'What sampling temperature to use, between 0 and 2. Higher
            values like 0.8 will make the output more random, while lower values like
            0.2 will make it more focused and deterministic.

            '
          example: 1
          maximum: 2
          minimum: 0
          type:
          - number
          - 'null'
        tool_resources:
          description: 'A set of resources that are used by the assistant''s tools.
            The resources are specific to the type of tool. For example, the `code_interpreter`
            tool requires a list of file IDs, while the `file_search` tool requires
            a list of vector store IDs.

            '
          properties:
            code_interpreter:
              properties:
                file_ids:
                  default: []
                  description: 'Overrides the list of [file](/docs/api-reference/files)
                    IDs made available to the `code_interpreter` tool. There can be
                    a maximum of 20 files associated with the tool.

                    '
                  items:
                    type: string
                  maxItems: 20
                  type: array
              type: object
            file_search:
              properties:
                vector_store_ids:
                  description: 'Overrides the [vector store](/docs/api-reference/vector-stores/object)
                    attached to this assistant. There can be a maximum of 1 vector
                    store attached to the assistant.

                    '
                  items:
                    type: string
                  maxItems: 1
                  type: array
              type: object
          type:
          - object
          - 'null'
        tools:
          default: []
          description: 'A list of tool enabled on the assistant. There can be a maximum
            of 128 tools per assistant. Tools can be of types `code_interpreter`,
            `file_search`, or `function`.

            '
          items:
            oneOf:
            - $ref: '#/components/schemas/AssistantToolsCode'
            - $ref: '#/components/schemas/AssistantToolsFileSearch'
            - $ref: '#/components/schemas/AssistantToolsFunction'
            x-oaiExpandable: true
          maxItems: 128
          type: array
        top_p:
          default: 1
          description: 'An alternative to sampling with temperature, called nucleus
            sampling, where the model considers the results of the tokens with top_p
            probability mass. So 0.1 means only the tokens comprising the top 10%
            probability mass are considered.


            We generally recommend altering this or temperature but not both.

            '
          example: 1
          maximum: 1
          minimum: 0
          type:
          - number
          - 'null'
      type: object
    ModifyMessageRequest:
      additionalProperties: false
      properties:
        metadata:
          description: 'Set of 16 key-value pairs that can be attached to an object.
            This can be useful for storing additional information about the object
            in a structured format. Keys can be a maximum of 64 characters long and
            values can be a maxium of 512 characters long.

            '
          type:
          - object
          - 'null'
          x-oaiTypeLabel: map
      type: object
    ModifyRunRequest:
      additionalProperties: false
      properties:
        metadata:
          description: 'Set of 16 key-value pairs that can be attached to an object.
            This can be useful for storing additional information about the object
            in a structured format. Keys can be a maximum of 64 characters long and
            values can be a maxium of 512 characters long.

            '
          type:
          - object
          - 'null'
          x-oaiTypeLabel: map
      type: object
    ModifyThreadRequest:
      additionalProperties: false
      properties:
        metadata:
          description: 'Set of 16 key-value pairs that can be attached to an object.
            This can be useful for storing additional information about the object
            in a structured format. Keys can be a maximum of 64 characters long and
            values can be a maxium of 512 characters long.

            '
          type:
          - object
          - 'null'
          x-oaiTypeLabel: map
        tool_resources:
          description: 'A set of resources that are made available to the assistant''s
            tools in this thread. The resources are specific to the type of tool.
            For example, the `code_interpreter` tool requires a list of file IDs,
            while the `file_search` tool requires a list of vector store IDs.

            '
          properties:
            code_interpreter:
              properties:
                file_ids:
                  default: []
                  description: 'A list of [file](/docs/api-reference/files) IDs made
                    available to the `code_interpreter` tool. There can be a maximum
                    of 20 files associated with the tool.

                    '
                  items:
                    type: string
                  maxItems: 20
                  type: array
              type: object
            file_search:
              properties:
                vector_store_ids:
                  description: 'The [vector store](/docs/api-reference/vector-stores/object)
                    attached to this thread. There can be a maximum of 1 vector store
                    attached to the thread.

                    '
                  items:
                    type: string
                  maxItems: 1
                  type: array
              type: object
          type:
          - object
          - 'null'
      type: object
    OpenAIFile:
      description: The `File` object represents a document that has been uploaded
        to OpenAI.
      properties:
        bytes:
          description: The size of the file, in bytes.
          type: integer
        created_at:
          description: The Unix timestamp (in seconds) for when the file was created.
          type: integer
        filename:
          description: The name of the file.
          type: string
        id:
          description: The file identifier, which can be referenced in the API endpoints.
          type: string
        object:
          description: The object type, which is always `file`.
          enum:
          - file
          type: string
        purpose:
          description: The intended purpose of the file. Supported values are `assistants`,
            `assistants_output`, `batch`, `batch_output`, `fine-tune`, `fine-tune-results`
            and `vision`.
          enum:
          - assistants
          - assistants_output
          - batch
          - batch_output
          - fine-tune
          - fine-tune-results
          - vision
          type: string
        status:
          deprecated: true
          description: Deprecated. The current status of the file, which can be either
            `uploaded`, `processed`, or `error`.
          enum:
          - uploaded
          - processed
          - error
          type: string
        status_details:
          deprecated: true
          description: Deprecated. For details on why a fine-tuning training file
            failed validation, see the `error` field on `fine_tuning.job`.
          type: string
      required:
      - id
      - object
      - bytes
      - created_at
      - filename
      - purpose
      - status
      title: OpenAIFile
      x-oaiMeta:
        example: "{\n  \"id\": \"file-abc123\",\n  \"object\": \"file\",\n  \"bytes\"\
          : 120000,\n  \"created_at\": 1677610602,\n  \"filename\": \"salesOverview.pdf\"\
          ,\n  \"purpose\": \"assistants\",\n}\n"
        name: The file object
    OtherChunkingStrategyResponseParam:
      additionalProperties: false
      description: This is returned when the chunking strategy is unknown. Typically,
        this is because the file was indexed before the `chunking_strategy` concept
        was introduced in the API.
      properties:
        type:
          description: Always `other`.
          enum:
          - other
          type: string
      required:
      - type
      title: Other Chunking Strategy
      type: object
    ParallelToolCalls:
      default: true
      description: Whether to enable [parallel function calling](/docs/guides/function-calling/parallel-function-calling)
        during tool use.
      type: boolean
    RunCompletionUsage:
      description: Usage statistics related to the run. This value will be `null`
        if the run is not in a terminal state (i.e. `in_progress`, `queued`, etc.).
      properties:
        completion_tokens:
          description: Number of completion tokens used over the course of the run.
          type: integer
        prompt_tokens:
          description: Number of prompt tokens used over the course of the run.
          type: integer
        total_tokens:
          description: Total number of tokens used (prompt + completion).
          type: integer
      required:
      - prompt_tokens
      - completion_tokens
      - total_tokens
      type:
      - object
      - 'null'
    RunObject:
      description: Represents an execution run on a [thread](/docs/api-reference/threads).
      properties:
        assistant_id:
          description: The ID of the [assistant](/docs/api-reference/assistants) used
            for execution of this run.
          type: string
        cancelled_at:
          description: The Unix timestamp (in seconds) for when the run was cancelled.
          type:
          - integer
          - 'null'
        completed_at:
          description: The Unix timestamp (in seconds) for when the run was completed.
          type:
          - integer
          - 'null'
        created_at:
          description: The Unix timestamp (in seconds) for when the run was created.
          type: integer
        expires_at:
          description: The Unix timestamp (in seconds) for when the run will expire.
          type:
          - integer
          - 'null'
        failed_at:
          description: The Unix timestamp (in seconds) for when the run failed.
          type:
          - integer
          - 'null'
        id:
          description: The identifier, which can be referenced in API endpoints.
          type: string
        incomplete_details:
          description: Details on why the run is incomplete. Will be `null` if the
            run is not incomplete.
          properties:
            reason:
              description: The reason why the run is incomplete. This will point to
                which specific token limit was reached over the course of the run.
              enum:
              - max_completion_tokens
              - max_prompt_tokens
              type: string
          type:
          - object
          - 'null'
        instructions:
          description: The instructions that the [assistant](/docs/api-reference/assistants)
            used for this run.
          type: string
        last_error:
          description: The last error associated with this run. Will be `null` if
            there are no errors.
          properties:
            code:
              description: One of `server_error`, `rate_limit_exceeded`, or `invalid_prompt`.
              enum:
              - server_error
              - rate_limit_exceeded
              - invalid_prompt
              type: string
            message:
              description: A human-readable description of the error.
              type: string
          required:
          - code
          - message
          type:
          - object
          - 'null'
        max_completion_tokens:
          description: 'The maximum number of completion tokens specified to have
            been used over the course of the run.

            '
          minimum: 256
          type:
          - integer
          - 'null'
        max_prompt_tokens:
          description: 'The maximum number of prompt tokens specified to have been
            used over the course of the run.

            '
          minimum: 256
          type:
          - integer
          - 'null'
        metadata:
          description: 'Set of 16 key-value pairs that can be attached to an object.
            This can be useful for storing additional information about the object
            in a structured format. Keys can be a maximum of 64 characters long and
            values can be a maxium of 512 characters long.

            '
          type:
          - object
          - 'null'
          x-oaiTypeLabel: map
        model:
          description: The model that the [assistant](/docs/api-reference/assistants)
            used for this run.
          type: string
        object:
          description: The object type, which is always `thread.run`.
          enum:
          - thread.run
          type: string
        parallel_tool_calls:
          $ref: '#/components/schemas/ParallelToolCalls'
        required_action:
          description: Details on the action required to continue the run. Will be
            `null` if no action is required.
          properties:
            submit_tool_outputs:
              description: Details on the tool outputs needed for this run to continue.
              properties:
                tool_calls:
                  description: A list of the relevant tool calls.
                  items:
                    $ref: '#/components/schemas/RunToolCallObject'
                  type: array
              required:
              - tool_calls
              type: object
            type:
              description: For now, this is always `submit_tool_outputs`.
              enum:
              - submit_tool_outputs
              type: string
          required:
          - type
          - submit_tool_outputs
          type:
          - object
          - 'null'
        response_format:
          $ref: '#/components/schemas/AssistantsApiResponseFormatOption'
        started_at:
          description: The Unix timestamp (in seconds) for when the run was started.
          type:
          - integer
          - 'null'
        status:
          description: The status of the run, which can be either `queued`, `in_progress`,
            `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`, `incomplete`,
            or `expired`.
          enum:
          - queued
          - in_progress
          - requires_action
          - cancelling
          - cancelled
          - failed
          - completed
          - incomplete
          - expired
          type: string
        temperature:
          description: The sampling temperature used for this run. If not set, defaults
            to 1.
          type:
          - number
          - 'null'
        thread_id:
          description: The ID of the [thread](/docs/api-reference/threads) that was
            executed on as a part of this run.
          type: string
        tool_choice:
          $ref: '#/components/schemas/AssistantsApiToolChoiceOption'
        tools:
          default: []
          description: The list of tools that the [assistant](/docs/api-reference/assistants)
            used for this run.
          items:
            oneOf:
            - $ref: '#/components/schemas/AssistantToolsCode'
            - $ref: '#/components/schemas/AssistantToolsFileSearch'
            - $ref: '#/components/schemas/AssistantToolsFunction'
            x-oaiExpandable: true
          maxItems: 20
          type: array
        top_p:
          description: The nucleus sampling value used for this run. If not set, defaults
            to 1.
          type:
          - number
          - 'null'
        truncation_strategy:
          $ref: '#/components/schemas/TruncationObject'
        usage:
          $ref: '#/components/schemas/RunCompletionUsage'
      required:
      - id
      - object
      - created_at
      - thread_id
      - assistant_id
      - status
      - required_action
      - last_error
      - expires_at
      - started_at
      - cancelled_at
      - failed_at
      - completed_at
      - model
      - instructions
      - tools
      - metadata
      - usage
      - incomplete_details
      - max_prompt_tokens
      - max_completion_tokens
      - truncation_strategy
      - tool_choice
      - parallel_tool_calls
      - response_format
      title: A run on a thread
      type: object
      x-oaiMeta:
        beta: true
        example: "{\n  \"id\": \"run_abc123\",\n  \"object\": \"thread.run\",\n  \"\
          created_at\": 1698107661,\n  \"assistant_id\": \"asst_abc123\",\n  \"thread_id\"\
          : \"thread_abc123\",\n  \"status\": \"completed\",\n  \"started_at\": 1699073476,\n\
          \  \"expires_at\": null,\n  \"cancelled_at\": null,\n  \"failed_at\": null,\n\
          \  \"completed_at\": 1699073498,\n  \"last_error\": null,\n  \"model\":\
          \ \"gpt-4-turbo\",\n  \"instructions\": null,\n  \"tools\": [{\"type\":\
          \ \"file_search\"}, {\"type\": \"code_interpreter\"}],\n  \"metadata\":\
          \ {},\n  \"incomplete_details\": null,\n  \"usage\": {\n    \"prompt_tokens\"\
          : 123,\n    \"completion_tokens\": 456,\n    \"total_tokens\": 579\n  },\n\
          \  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"max_prompt_tokens\": 1000,\n\
          \  \"max_completion_tokens\": 1000,\n  \"truncation_strategy\": {\n    \"\
          type\": \"auto\",\n    \"last_messages\": null\n  },\n  \"response_format\"\
          : \"auto\",\n  \"tool_choice\": \"auto\",\n  \"parallel_tool_calls\": true\n\
          }\n"
        name: The run object
    RunStepCompletionUsage:
      description: Usage statistics related to the run step. This value will be `null`
        while the run step's status is `in_progress`.
      properties:
        completion_tokens:
          description: Number of completion tokens used over the course of the run
            step.
          type: integer
        prompt_tokens:
          description: Number of prompt tokens used over the course of the run step.
          type: integer
        total_tokens:
          description: Total number of tokens used (prompt + completion).
          type: integer
      required:
      - prompt_tokens
      - completion_tokens
      - total_tokens
      type:
      - object
      - 'null'
    RunStepDeltaObject:
      description: 'Represents a run step delta i.e. any changed fields on a run step
        during streaming.

        '
      properties:
        delta:
          description: The delta containing the fields that have changed on the run
            step.
          properties:
            step_details:
              description: The details of the run step.
              oneOf:
              - $ref: '#/components/schemas/RunStepDeltaStepDetailsMessageCreationObject'
              - $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsObject'
              type: object
              x-oaiExpandable: true
          type: object
        id:
          description: The identifier of the run step, which can be referenced in
            API endpoints.
          type: string
        object:
          description: The object type, which is always `thread.run.step.delta`.
          enum:
          - thread.run.step.delta
          type: string
      required:
      - id
      - object
      - delta
      title: Run step delta object
      type: object
      x-oaiMeta:
        beta: true
        example: "{\n  \"id\": \"step_123\",\n  \"object\": \"thread.run.step.delta\"\
          ,\n  \"delta\": {\n    \"step_details\": {\n      \"type\": \"tool_calls\"\
          ,\n      \"tool_calls\": [\n        {\n          \"index\": 0,\n       \
          \   \"id\": \"call_123\",\n          \"type\": \"code_interpreter\",\n \
          \         \"code_interpreter\": { \"input\": \"\", \"outputs\": [] }\n \
          \       }\n      ]\n    }\n  }\n}\n"
        name: The run step delta object
    RunStepDeltaStepDetailsMessageCreationObject:
      description: Details of the message creation by the run step.
      properties:
        message_creation:
          properties:
            message_id:
              description: The ID of the message that was created by this run step.
              type: string
          type: object
        type:
          description: Always `message_creation`.
          enum:
          - message_creation
          type: string
      required:
      - type
      title: Message creation
      type: object
    RunStepDeltaStepDetailsToolCallsCodeObject:
      description: Details of the Code Interpreter tool call the run step was involved
        in.
      properties:
        code_interpreter:
          description: The Code Interpreter tool call definition.
          properties:
            input:
              description: The input to the Code Interpreter tool call.
              type: string
            outputs:
              description: The outputs from the Code Interpreter tool call. Code Interpreter
                can output one or more items, including text (`logs`) or images (`image`).
                Each of these are represented by a different object type.
              items:
                oneOf:
                - $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeOutputLogsObject'
                - $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeOutputImageObject'
                type: object
                x-oaiExpandable: true
              type: array
          type: object
        id:
          description: The ID of the tool call.
          type: string
        index:
          description: The index of the tool call in the tool calls array.
          type: integer
        type:
          description: The type of tool call. This is always going to be `code_interpreter`
            for this type of tool call.
          enum:
          - code_interpreter
          type: string
      required:
      - index
      - type
      title: Code interpreter tool call
      type: object
    RunStepDeltaStepDetailsToolCallsCodeOutputImageObject:
      properties:
        image:
          properties:
            file_id:
              description: The [file](/docs/api-reference/files) ID of the image.
              type: string
          type: object
        index:
          description: The index of the output in the outputs array.
          type: integer
        type:
          description: Always `image`.
          enum:
          - image
          type: string
      required:
      - index
      - type
      title: Code interpreter image output
      type: object
    RunStepDeltaStepDetailsToolCallsCodeOutputLogsObject:
      description: Text output from the Code Interpreter tool call as part of a run
        step.
      properties:
        index:
          description: The index of the output in the outputs array.
          type: integer
        logs:
          description: The text output from the Code Interpreter tool call.
          type: string
        type:
          description: Always `logs`.
          enum:
          - logs
          type: string
      required:
      - index
      - type
      title: Code interpreter log output
      type: object
    RunStepDeltaStepDetailsToolCallsFileSearchObject:
      properties:
        file_search:
          description: For now, this is always going to be an empty object.
          type: object
          x-oaiTypeLabel: map
        id:
          description: The ID of the tool call object.
          type: string
        index:
          description: The index of the tool call in the tool calls array.
          type: integer
        type:
          description: The type of tool call. This is always going to be `file_search`
            for this type of tool call.
          enum:
          - file_search
          type: string
      required:
      - index
      - type
      - file_search
      title: File search tool call
      type: object
    RunStepDeltaStepDetailsToolCallsFunctionObject:
      properties:
        function:
          description: The definition of the function that was called.
          properties:
            arguments:
              description: The arguments passed to the function.
              type: string
            name:
              description: The name of the function.
              type: string
            output:
              description: The output of the function. This will be `null` if the
                outputs have not been [submitted](/docs/api-reference/runs/submitToolOutputs)
                yet.
              type:
              - string
              - 'null'
          type: object
        id:
          description: The ID of the tool call object.
          type: string
        index:
          description: The index of the tool call in the tool calls array.
          type: integer
        type:
          description: The type of tool call. This is always going to be `function`
            for this type of tool call.
          enum:
          - function
          type: string
      required:
      - index
      - type
      title: Function tool call
      type: object
    RunStepDeltaStepDetailsToolCallsObject:
      description: Details of the tool call.
      properties:
        tool_calls:
          description: 'An array of tool calls the run step was involved in. These
            can be associated with one of three types of tools: `code_interpreter`,
            `file_search`, or `function`.

            '
          items:
            oneOf:
            - $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeObject'
            - $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsFileSearchObject'
            - $ref: '#/components/schemas/RunStepDeltaStepDetailsToolCallsFunctionObject'
            x-oaiExpandable: true
          type: array
        type:
          description: Always `tool_calls`.
          enum:
          - tool_calls
          type: string
      required:
      - type
      title: Tool calls
      type: object
    RunStepDetailsMessageCreationObject:
      description: Details of the message creation by the run step.
      properties:
        message_creation:
          properties:
            message_id:
              description: The ID of the message that was created by this run step.
              type: string
          required:
          - message_id
          type: object
        type:
          description: Always `message_creation`.
          enum:
          - message_creation
          type: string
      required:
      - type
      - message_creation
      title: Message creation
      type: object
    RunStepDetailsToolCallsCodeObject:
      description: Details of the Code Interpreter tool call the run step was involved
        in.
      properties:
        code_interpreter:
          description: The Code Interpreter tool call definition.
          properties:
            input:
              description: The input to the Code Interpreter tool call.
              type: string
            outputs:
              description: The outputs from the Code Interpreter tool call. Code Interpreter
                can output one or more items, including text (`logs`) or images (`image`).
                Each of these are represented by a different object type.
              items:
                oneOf:
                - $ref: '#/components/schemas/RunStepDetailsToolCallsCodeOutputLogsObject'
                - $ref: '#/components/schemas/RunStepDetailsToolCallsCodeOutputImageObject'
                type: object
                x-oaiExpandable: true
              type: array
          required:
          - input
          - outputs
          type: object
        id:
          description: The ID of the tool call.
          type: string
        type:
          description: The type of tool call. This is always going to be `code_interpreter`
            for this type of tool call.
          enum:
          - code_interpreter
          type: string
      required:
      - id
      - type
      - code_interpreter
      title: Code Interpreter tool call
      type: object
    RunStepDetailsToolCallsCodeOutputImageObject:
      properties:
        image:
          properties:
            file_id:
              description: The [file](/docs/api-reference/files) ID of the image.
              type: string
          required:
          - file_id
          type: object
        type:
          description: Always `image`.
          enum:
          - image
          type: string
      required:
      - type
      - image
      title: Code Interpreter image output
      type: object
    RunStepDetailsToolCallsCodeOutputLogsObject:
      description: Text output from the Code Interpreter tool call as part of a run
        step.
      properties:
        logs:
          description: The text output from the Code Interpreter tool call.
          type: string
        type:
          description: Always `logs`.
          enum:
          - logs
          type: string
      required:
      - type
      - logs
      title: Code Interpreter log output
      type: object
    RunStepDetailsToolCallsFileSearchObject:
      properties:
        file_search:
          description: For now, this is always going to be an empty object.
          type: object
          x-oaiTypeLabel: map
        id:
          description: The ID of the tool call object.
          type: string
        type:
          description: The type of tool call. This is always going to be `file_search`
            for this type of tool call.
          enum:
          - file_search
          type: string
      required:
      - id
      - type
      - file_search
      title: File search tool call
      type: object
    RunStepDetailsToolCallsFunctionObject:
      properties:
        function:
          description: The definition of the function that was called.
          properties:
            arguments:
              description: The arguments passed to the function.
              type: string
            name:
              description: The name of the function.
              type: string
            output:
              description: The output of the function. This will be `null` if the
                outputs have not been [submitted](/docs/api-reference/runs/submitToolOutputs)
                yet.
              type:
              - string
              - 'null'
          required:
          - name
          - arguments
          - output
          type: object
        id:
          description: The ID of the tool call object.
          type: string
        type:
          description: The type of tool call. This is always going to be `function`
            for this type of tool call.
          enum:
          - function
          type: string
      required:
      - id
      - type
      - function
      title: Function tool call
      type: object
    RunStepDetailsToolCallsObject:
      description: Details of the tool call.
      properties:
        tool_calls:
          description: 'An array of tool calls the run step was involved in. These
            can be associated with one of three types of tools: `code_interpreter`,
            `file_search`, or `function`.

            '
          items:
            oneOf:
            - $ref: '#/components/schemas/RunStepDetailsToolCallsCodeObject'
            - $ref: '#/components/schemas/RunStepDetailsToolCallsFileSearchObject'
            - $ref: '#/components/schemas/RunStepDetailsToolCallsFunctionObject'
            x-oaiExpandable: true
          type: array
        type:
          description: Always `tool_calls`.
          enum:
          - tool_calls
          type: string
      required:
      - type
      - tool_calls
      title: Tool calls
      type: object
    RunStepObject:
      description: 'Represents a step in execution of a run.

        '
      properties:
        assistant_id:
          description: The ID of the [assistant](/docs/api-reference/assistants) associated
            with the run step.
          type: string
        cancelled_at:
          description: The Unix timestamp (in seconds) for when the run step was cancelled.
          type:
          - integer
          - 'null'
        completed_at:
          description: The Unix timestamp (in seconds) for when the run step completed.
          type:
          - integer
          - 'null'
        created_at:
          description: The Unix timestamp (in seconds) for when the run step was created.
          type: integer
        expired_at:
          description: The Unix timestamp (in seconds) for when the run step expired.
            A step is considered expired if the parent run is expired.
          type:
          - integer
          - 'null'
        failed_at:
          description: The Unix timestamp (in seconds) for when the run step failed.
          type:
          - integer
          - 'null'
        id:
          description: The identifier of the run step, which can be referenced in
            API endpoints.
          type: string
        last_error:
          description: The last error associated with this run step. Will be `null`
            if there are no errors.
          properties:
            code:
              description: One of `server_error` or `rate_limit_exceeded`.
              enum:
              - server_error
              - rate_limit_exceeded
              type: string
            message:
              description: A human-readable description of the error.
              type: string
          required:
          - code
          - message
          type:
          - object
          - 'null'
        metadata:
          description: 'Set of 16 key-value pairs that can be attached to an object.
            This can be useful for storing additional information about the object
            in a structured format. Keys can be a maximum of 64 characters long and
            values can be a maxium of 512 characters long.

            '
          type:
          - object
          - 'null'
          x-oaiTypeLabel: map
        object:
          description: The object type, which is always `thread.run.step`.
          enum:
          - thread.run.step
          type: string
        run_id:
          description: The ID of the [run](/docs/api-reference/runs) that this run
            step is a part of.
          type: string
        status:
          description: The status of the run step, which can be either `in_progress`,
            `cancelled`, `failed`, `completed`, or `expired`.
          enum:
          - in_progress
          - cancelled
          - failed
          - completed
          - expired
          type: string
        step_details:
          description: The details of the run step.
          oneOf:
          - $ref: '#/components/schemas/RunStepDetailsMessageCreationObject'
          - $ref: '#/components/schemas/RunStepDetailsToolCallsObject'
          type: object
          x-oaiExpandable: true
        thread_id:
          description: The ID of the [thread](/docs/api-reference/threads) that was
            run.
          type: string
        type:
          description: The type of run step, which can be either `message_creation`
            or `tool_calls`.
          enum:
          - message_creation
          - tool_calls
          type: string
        usage:
          $ref: '#/components/schemas/RunStepCompletionUsage'
      required:
      - id
      - object
      - created_at
      - assistant_id
      - thread_id
      - run_id
      - type
      - status
      - step_details
      - last_error
      - expired_at
      - cancelled_at
      - failed_at
      - completed_at
      - metadata
      - usage
      title: Run steps
      type: object
      x-oaiMeta:
        beta: true
        example: "{\n  \"id\": \"step_abc123\",\n  \"object\": \"thread.run.step\"\
          ,\n  \"created_at\": 1699063291,\n  \"run_id\": \"run_abc123\",\n  \"assistant_id\"\
          : \"asst_abc123\",\n  \"thread_id\": \"thread_abc123\",\n  \"type\": \"\
          message_creation\",\n  \"status\": \"completed\",\n  \"cancelled_at\": null,\n\
          \  \"completed_at\": 1699063291,\n  \"expired_at\": null,\n  \"failed_at\"\
          : null,\n  \"last_error\": null,\n  \"step_details\": {\n    \"type\": \"\
          message_creation\",\n    \"message_creation\": {\n      \"message_id\":\
          \ \"msg_abc123\"\n    }\n  },\n  \"usage\": {\n    \"prompt_tokens\": 123,\n\
          \    \"completion_tokens\": 456,\n    \"total_tokens\": 579\n  }\n}\n"
        name: The run step object
    RunStepStreamEvent:
      oneOf:
      - description: Occurs when a [run step](/docs/api-reference/runs/step-object)
          is created.
        properties:
          data:
            $ref: '#/components/schemas/RunStepObject'
          event:
            enum:
            - thread.run.step.created
            type: string
        required:
        - event
        - data
        type: object
        x-oaiMeta:
          dataDescription: '`data` is a [run step](/docs/api-reference/runs/step-object)'
      - description: Occurs when a [run step](/docs/api-reference/runs/step-object)
          moves to an `in_progress` state.
        properties:
          data:
            $ref: '#/components/schemas/RunStepObject'
          event:
            enum:
            - thread.run.step.in_progress
            type: string
        required:
        - event
        - data
        type: object
        x-oaiMeta:
          dataDescription: '`data` is a [run step](/docs/api-reference/runs/step-object)'
      - description: Occurs when parts of a [run step](/docs/api-reference/runs/step-object)
          are being streamed.
        properties:
          data:
            $ref: '#/components/schemas/RunStepDeltaObject'
          event:
            enum:
            - thread.run.step.delta
            type: string
        required:
        - event
        - data
        type: object
        x-oaiMeta:
          dataDescription: '`data` is a [run step delta](/docs/api-reference/assistants-streaming/run-step-delta-object)'
      - description: Occurs when a [run step](/docs/api-reference/runs/step-object)
          is completed.
        properties:
          data:
            $ref: '#/components/schemas/RunStepObject'
          event:
            enum:
            - thread.run.step.completed
            type: string
        required:
        - event
        - data
        type: object
        x-oaiMeta:
          dataDescription: '`data` is a [run step](/docs/api-reference/runs/step-object)'
      - description: Occurs when a [run step](/docs/api-reference/runs/step-object)
          fails.
        properties:
          data:
            $ref: '#/components/schemas/RunStepObject'
          event:
            enum:
            - thread.run.step.failed
            type: string
        required:
        - event
        - data
        type: object
        x-oaiMeta:
          dataDescription: '`data` is a [run step](/docs/api-reference/runs/step-object)'
      - description: Occurs when a [run step](/docs/api-reference/runs/step-object)
          is cancelled.
        properties:
          data:
            $ref: '#/components/schemas/RunStepObject'
          event:
            enum:
            - thread.run.step.cancelled
            type: string
        required:
        - event
        - data
        type: object
        x-oaiMeta:
          dataDescription: '`data` is a [run step](/docs/api-reference/runs/step-object)'
      - description: Occurs when a [run step](/docs/api-reference/runs/step-object)
          expires.
        properties:
          data:
            $ref: '#/components/schemas/RunStepObject'
          event:
            enum:
            - thread.run.step.expired
            type: string
        required:
        - event
        - data
        type: object
        x-oaiMeta:
          dataDescription: '`data` is a [run step](/docs/api-reference/runs/step-object)'
    RunStreamEvent:
      oneOf:
      - description: Occurs when a new [run](/docs/api-reference/runs/object) is created.
        properties:
          data:
            $ref: '#/components/schemas/RunObject'
          event:
            enum:
            - thread.run.created
            type: string
        required:
        - event
        - data
        type: object
        x-oaiMeta:
          dataDescription: '`data` is a [run](/docs/api-reference/runs/object)'
      - description: Occurs when a [run](/docs/api-reference/runs/object) moves to
          a `queued` status.
        properties:
          data:
            $ref: '#/components/schemas/RunObject'
          event:
            enum:
            - thread.run.queued
            type: string
        required:
        - event
        - data
        type: object
        x-oaiMeta:
          dataDescription: '`data` is a [run](/docs/api-reference/runs/object)'
      - description: Occurs when a [run](/docs/api-reference/runs/object) moves to
          an `in_progress` status.
        properties:
          data:
            $ref: '#/components/schemas/RunObject'
          event:
            enum:
            - thread.run.in_progress
            type: string
        required:
        - event
        - data
        type: object
        x-oaiMeta:
          dataDescription: '`data` is a [run](/docs/api-reference/runs/object)'
      - description: Occurs when a [run](/docs/api-reference/runs/object) moves to
          a `requires_action` status.
        properties:
          data:
            $ref: '#/components/schemas/RunObject'
          event:
            enum:
            - thread.run.requires_action
            type: string
        required:
        - event
        - data
        type: object
        x-oaiMeta:
          dataDescription: '`data` is a [run](/docs/api-reference/runs/object)'
      - description: Occurs when a [run](/docs/api-reference/runs/object) is completed.
        properties:
          data:
            $ref: '#/components/schemas/RunObject'
          event:
            enum:
            - thread.run.completed
            type: string
        required:
        - event
        - data
        type: object
        x-oaiMeta:
          dataDescription: '`data` is a [run](/docs/api-reference/runs/object)'
      - description: Occurs when a [run](/docs/api-reference/runs/object) ends with
          status `incomplete`.
        properties:
          data:
            $ref: '#/components/schemas/RunObject'
          event:
            enum:
            - thread.run.incomplete
            type: string
        required:
        - event
        - data
        type: object
        x-oaiMeta:
          dataDescription: '`data` is a [run](/docs/api-reference/runs/object)'
      - description: Occurs when a [run](/docs/api-reference/runs/object) fails.
        properties:
          data:
            $ref: '#/components/schemas/RunObject'
          event:
            enum:
            - thread.run.failed
            type: string
        required:
        - event
        - data
        type: object
        x-oaiMeta:
          dataDescription: '`data` is a [run](/docs/api-reference/runs/object)'
      - description: Occurs when a [run](/docs/api-reference/runs/object) moves to
          a `cancelling` status.
        properties:
          data:
            $ref: '#/components/schemas/RunObject'
          event:
            enum:
            - thread.run.cancelling
            type: string
        required:
        - event
        - data
        type: object
        x-oaiMeta:
          dataDescription: '`data` is a [run](/docs/api-reference/runs/object)'
      - description: Occurs when a [run](/docs/api-reference/runs/object) is cancelled.
        properties:
          data:
            $ref: '#/components/schemas/RunObject'
          event:
            enum:
            - thread.run.cancelled
            type: string
        required:
        - event
        - data
        type: object
        x-oaiMeta:
          dataDescription: '`data` is a [run](/docs/api-reference/runs/object)'
      - description: Occurs when a [run](/docs/api-reference/runs/object) expires.
        properties:
          data:
            $ref: '#/components/schemas/RunObject'
          event:
            enum:
            - thread.run.expired
            type: string
        required:
        - event
        - data
        type: object
        x-oaiMeta:
          dataDescription: '`data` is a [run](/docs/api-reference/runs/object)'
    RunToolCallObject:
      description: Tool call objects
      properties:
        function:
          description: The function definition.
          properties:
            arguments:
              description: The arguments that the model expects you to pass to the
                function.
              type: string
            name:
              description: The name of the function.
              type: string
          required:
          - name
          - arguments
          type: object
        id:
          description: The ID of the tool call. This ID must be referenced when you
            submit the tool outputs in using the [Submit tool outputs to run](/docs/api-reference/runs/submitToolOutputs)
            endpoint.
          type: string
        type:
          description: The type of tool call the output is required for. For now,
            this is always `function`.
          enum:
          - function
          type: string
      required:
      - id
      - type
      - function
      type: object
    StaticChunkingStrategy:
      additionalProperties: false
      properties:
        chunk_overlap_tokens:
          description: 'The number of tokens that overlap between chunks. The default
            value is `400`.


            Note that the overlap must not exceed half of `max_chunk_size_tokens`.

            '
          type: integer
        max_chunk_size_tokens:
          description: The maximum number of tokens in each chunk. The default value
            is `800`. The minimum value is `100` and the maximum value is `4096`.
          maximum: 4096
          minimum: 100
          type: integer
      required:
      - max_chunk_size_tokens
      - chunk_overlap_tokens
      type: object
    StaticChunkingStrategyRequestParam:
      additionalProperties: false
      properties:
        static:
          $ref: '#/components/schemas/StaticChunkingStrategy'
        type:
          description: Always `static`.
          enum:
          - static
          type: string
      required:
      - type
      - static
      title: Static Chunking Strategy
      type: object
    StaticChunkingStrategyResponseParam:
      additionalProperties: false
      properties:
        static:
          $ref: '#/components/schemas/StaticChunkingStrategy'
        type:
          description: Always `static`.
          enum:
          - static
          type: string
      required:
      - type
      - static
      title: Static Chunking Strategy
      type: object
    SubmitToolOutputsRunRequest:
      additionalProperties: false
      properties:
        stream:
          description: 'If `true`, returns a stream of events that happen during the
            Run as server-sent events, terminating when the Run enters a terminal
            state with a `data: [DONE]` message.

            '
          type:
          - boolean
          - 'null'
        tool_outputs:
          description: A list of tools for which the outputs are being submitted.
          items:
            properties:
              output:
                description: The output of the tool call to be submitted to continue
                  the run.
                type: string
              tool_call_id:
                description: The ID of the tool call in the `required_action` object
                  within the run object the output is being submitted for.
                type: string
            type: object
          type: array
      required:
      - tool_outputs
      type: object
    ThreadObject:
      description: Represents a thread that contains [messages](/docs/api-reference/messages).
      properties:
        created_at:
          description: The Unix timestamp (in seconds) for when the thread was created.
          type: integer
        id:
          description: The identifier, which can be referenced in API endpoints.
          type: string
        metadata:
          description: 'Set of 16 key-value pairs that can be attached to an object.
            This can be useful for storing additional information about the object
            in a structured format. Keys can be a maximum of 64 characters long and
            values can be a maxium of 512 characters long.

            '
          type:
          - object
          - 'null'
          x-oaiTypeLabel: map
        object:
          description: The object type, which is always `thread`.
          enum:
          - thread
          type: string
        tool_resources:
          description: 'A set of resources that are made available to the assistant''s
            tools in this thread. The resources are specific to the type of tool.
            For example, the `code_interpreter` tool requires a list of file IDs,
            while the `file_search` tool requires a list of vector store IDs.

            '
          properties:
            code_interpreter:
              properties:
                file_ids:
                  default: []
                  description: 'A list of [file](/docs/api-reference/files) IDs made
                    available to the `code_interpreter` tool. There can be a maximum
                    of 20 files associated with the tool.

                    '
                  items:
                    type: string
                  maxItems: 20
                  type: array
              type: object
            file_search:
              properties:
                vector_store_ids:
                  description: 'The [vector store](/docs/api-reference/vector-stores/object)
                    attached to this thread. There can be a maximum of 1 vector store
                    attached to the thread.

                    '
                  items:
                    type: string
                  maxItems: 1
                  type: array
              type: object
          type:
          - object
          - 'null'
      required:
      - id
      - object
      - created_at
      - tool_resources
      - metadata
      title: Thread
      type: object
      x-oaiMeta:
        beta: true
        example: "{\n  \"id\": \"thread_abc123\",\n  \"object\": \"thread\",\n  \"\
          created_at\": 1698107661,\n  \"metadata\": {}\n}\n"
        name: The thread object
    ThreadStreamEvent:
      oneOf:
      - description: Occurs when a new [thread](/docs/api-reference/threads/object)
          is created.
        properties:
          data:
            $ref: '#/components/schemas/ThreadObject'
          event:
            enum:
            - thread.created
            type: string
        required:
        - event
        - data
        type: object
        x-oaiMeta:
          dataDescription: '`data` is a [thread](/docs/api-reference/threads/object)'
    TranscriptionSegment:
      properties:
        avg_logprob:
          description: Average logprob of the segment. If the value is lower than
            -1, consider the logprobs failed.
          format: float
          type: number
        compression_ratio:
          description: Compression ratio of the segment. If the value is greater than
            2.4, consider the compression failed.
          format: float
          type: number
        end:
          description: End time of the segment in seconds.
          format: float
          type: number
        id:
          description: Unique identifier of the segment.
          type: integer
        no_speech_prob:
          description: Probability of no speech in the segment. If the value is higher
            than 1.0 and the `avg_logprob` is below -1, consider this segment silent.
          format: float
          type: number
        seek:
          description: Seek offset of the segment.
          type: integer
        start:
          description: Start time of the segment in seconds.
          format: float
          type: number
        temperature:
          description: Temperature parameter used for generating the segment.
          format: float
          type: number
        text:
          description: Text content of the segment.
          type: string
        tokens:
          description: Array of token IDs for the text content.
          items:
            type: integer
          type: array
      required:
      - id
      - seek
      - start
      - end
      - text
      - tokens
      - temperature
      - avg_logprob
      - compression_ratio
      - no_speech_prob
      type: object
    TranscriptionWord:
      properties:
        end:
          description: End time of the word in seconds.
          format: float
          type: number
        start:
          description: Start time of the word in seconds.
          format: float
          type: number
        word:
          description: The text content of the word.
          type: string
      required:
      - word
      - start
      - end
      type: object
    TruncationObject:
      description: Controls for how a thread will be truncated prior to the run. Use
        this to control the intial context window of the run.
      properties:
        last_messages:
          description: The number of most recent messages from the thread when constructing
            the context for the run.
          minimum: 1
          type:
          - integer
          - 'null'
        type:
          description: The truncation strategy to use for the thread. The default
            is `auto`. If set to `last_messages`, the thread will be truncated to
            the n most recent messages in the thread. When set to `auto`, messages
            in the middle of the thread will be dropped to fit the context length
            of the model, `max_prompt_tokens`.
          enum:
          - auto
          - last_messages
          type: string
      required:
      - type
      title: Thread Truncation Controls
      type: object
    UpdateVectorStoreRequest:
      additionalProperties: false
      properties:
        expires_after:
          $ref: '#/components/schemas/VectorStoreExpirationAfter'
        metadata:
          description: 'Set of 16 key-value pairs that can be attached to an object.
            This can be useful for storing additional information about the object
            in a structured format. Keys can be a maximum of 64 characters long and
            values can be a maxium of 512 characters long.

            '
          type:
          - object
          - 'null'
          x-oaiTypeLabel: map
        name:
          description: The name of the vector store.
          type:
          - string
          - 'null'
      type: object
    VectorStoreExpirationAfter:
      description: The expiration policy for a vector store.
      properties:
        anchor:
          description: 'Anchor timestamp after which the expiration policy applies.
            Supported anchors: `last_active_at`.'
          enum:
          - last_active_at
          type: string
        days:
          description: The number of days after the anchor time that the vector store
            will expire.
          maximum: 365
          minimum: 1
          type: integer
      required:
      - anchor
      - days
      title: Vector store expiration policy
      type: object
    VectorStoreFileBatchObject:
      description: A batch of files attached to a vector store.
      properties:
        created_at:
          description: The Unix timestamp (in seconds) for when the vector store files
            batch was created.
          type: integer
        file_counts:
          properties:
            cancelled:
              description: The number of files that where cancelled.
              type: integer
            completed:
              description: The number of files that have been processed.
              type: integer
            failed:
              description: The number of files that have failed to process.
              type: integer
            in_progress:
              description: The number of files that are currently being processed.
              type: integer
            total:
              description: The total number of files.
              type: integer
          required:
          - in_progress
          - completed
          - cancelled
          - failed
          - total
          type: object
        id:
          description: The identifier, which can be referenced in API endpoints.
          type: string
        object:
          description: The object type, which is always `vector_store.file_batch`.
          enum:
          - vector_store.files_batch
          type: string
        status:
          description: The status of the vector store files batch, which can be either
            `in_progress`, `completed`, `cancelled` or `failed`.
          enum:
          - in_progress
          - completed
          - cancelled
          - failed
          type: string
        vector_store_id:
          description: The ID of the [vector store](/docs/api-reference/vector-stores/object)
            that the [File](/docs/api-reference/files) is attached to.
          type: string
      required:
      - id
      - object
      - created_at
      - vector_store_id
      - status
      - file_counts
      title: Vector store file batch
      type: object
      x-oaiMeta:
        beta: true
        example: "{\n  \"id\": \"vsfb_123\",\n  \"object\": \"vector_store.files_batch\"\
          ,\n  \"created_at\": 1698107661,\n  \"vector_store_id\": \"vs_abc123\",\n\
          \  \"status\": \"completed\",\n  \"file_counts\": {\n    \"in_progress\"\
          : 0,\n    \"completed\": 100,\n    \"failed\": 0,\n    \"cancelled\": 0,\n\
          \    \"total\": 100\n  }\n}\n"
        name: The vector store files batch object
    VectorStoreFileObject:
      description: A list of files attached to a vector store.
      properties:
        chunking_strategy:
          description: The strategy used to chunk the file.
          oneOf:
          - $ref: '#/components/schemas/StaticChunkingStrategyResponseParam'
          - $ref: '#/components/schemas/OtherChunkingStrategyResponseParam'
          type: object
          x-oaiExpandable: true
        created_at:
          description: The Unix timestamp (in seconds) for when the vector store file
            was created.
          type: integer
        id:
          description: The identifier, which can be referenced in API endpoints.
          type: string
        last_error:
          description: The last error associated with this vector store file. Will
            be `null` if there are no errors.
          properties:
            code:
              description: One of `server_error` or `rate_limit_exceeded`.
              enum:
              - internal_error
              - file_not_found
              - parsing_error
              - unhandled_mime_type
              type: string
            message:
              description: A human-readable description of the error.
              type: string
          required:
          - code
          - message
          type:
          - object
          - 'null'
        object:
          description: The object type, which is always `vector_store.file`.
          enum:
          - vector_store.file
          type: string
        status:
          description: The status of the vector store file, which can be either `in_progress`,
            `completed`, `cancelled`, or `failed`. The status `completed` indicates
            that the vector store file is ready for use.
          enum:
          - in_progress
          - completed
          - cancelled
          - failed
          type: string
        usage_bytes:
          description: The total vector store usage in bytes. Note that this may be
            different from the original file size.
          type: integer
        vector_store_id:
          description: The ID of the [vector store](/docs/api-reference/vector-stores/object)
            that the [File](/docs/api-reference/files) is attached to.
          type: string
      required:
      - id
      - object
      - usage_bytes
      - created_at
      - vector_store_id
      - status
      - last_error
      title: Vector store files
      type: object
      x-oaiMeta:
        beta: true
        example: "{\n  \"id\": \"file-abc123\",\n  \"object\": \"vector_store.file\"\
          ,\n  \"usage_bytes\": 1234,\n  \"created_at\": 1698107661,\n  \"vector_store_id\"\
          : \"vs_abc123\",\n  \"status\": \"completed\",\n  \"last_error\": null,\n\
          \  \"chunking_strategy\": {\n    \"type\": \"static\",\n    \"static\":\
          \ {\n      \"max_chunk_size_tokens\": 800,\n      \"chunk_overlap_tokens\"\
          : 400\n    }\n  }\n}\n"
        name: The vector store file object
    VectorStoreObject:
      description: A vector store is a collection of processed files can be used by
        the `file_search` tool.
      properties:
        created_at:
          description: The Unix timestamp (in seconds) for when the vector store was
            created.
          type: integer
        expires_after:
          $ref: '#/components/schemas/VectorStoreExpirationAfter'
        expires_at:
          description: The Unix timestamp (in seconds) for when the vector store will
            expire.
          type:
          - integer
          - 'null'
        file_counts:
          properties:
            cancelled:
              description: The number of files that were cancelled.
              type: integer
            completed:
              description: The number of files that have been successfully processed.
              type: integer
            failed:
              description: The number of files that have failed to process.
              type: integer
            in_progress:
              description: The number of files that are currently being processed.
              type: integer
            total:
              description: The total number of files.
              type: integer
          required:
          - in_progress
          - completed
          - failed
          - cancelled
          - total
          type: object
        id:
          description: The identifier, which can be referenced in API endpoints.
          type: string
        last_active_at:
          description: The Unix timestamp (in seconds) for when the vector store was
            last active.
          type:
          - integer
          - 'null'
        metadata:
          description: 'Set of 16 key-value pairs that can be attached to an object.
            This can be useful for storing additional information about the object
            in a structured format. Keys can be a maximum of 64 characters long and
            values can be a maxium of 512 characters long.

            '
          type:
          - object
          - 'null'
          x-oaiTypeLabel: map
        name:
          description: The name of the vector store.
          type: string
        object:
          description: The object type, which is always `vector_store`.
          enum:
          - vector_store
          type: string
        status:
          description: The status of the vector store, which can be either `expired`,
            `in_progress`, or `completed`. A status of `completed` indicates that
            the vector store is ready for use.
          enum:
          - expired
          - in_progress
          - completed
          type: string
        usage_bytes:
          description: The total number of bytes used by the files in the vector store.
          type: integer
      required:
      - id
      - object
      - usage_bytes
      - created_at
      - status
      - last_active_at
      - name
      - file_counts
      - metadata
      title: Vector store
      type: object
      x-oaiMeta:
        beta: true
        example: "{\n  \"id\": \"vs_123\",\n  \"object\": \"vector_store\",\n  \"\
          created_at\": 1698107661,\n  \"usage_bytes\": 123456,\n  \"last_active_at\"\
          : 1698107661,\n  \"name\": \"my_vector_store\",\n  \"status\": \"completed\"\
          ,\n  \"file_counts\": {\n    \"in_progress\": 0,\n    \"completed\": 100,\n\
          \    \"cancelled\": 0,\n    \"failed\": 0,\n    \"total\": 100\n  },\n \
          \ \"metadata\": {},\n  \"last_used_at\": 1698107661\n}\n"
        name: The vector store object
  securitySchemes:
    ApiKeyAuth:
      scheme: bearer
      type: http
info:
  contact:
    name: OpenAI Support
    url: https://help.openai.com/
  description: The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference
    for more details.
  license:
    name: MIT
    url: https://github.com/openai/openai-openapi/blob/master/LICENSE
  termsOfService: https://openai.com/policies/terms-of-use
  title: OpenAI API
  version: 2.0.0
openapi: 3.1.0
paths:
  /assistants:
    get:
      operationId: listAssistants
      parameters:
      - description: 'A limit on the number of objects to be returned. Limit can range
          between 1 and 100, and the default is 20.

          '
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
      - description: 'Sort order by the `created_at` timestamp of the objects. `asc`
          for ascending order and `desc` for descending order.

          '
        in: query
        name: order
        schema:
          default: desc
          enum:
          - asc
          - desc
          type: string
      - description: 'A cursor for use in pagination. `after` is an object ID that
          defines your place in the list. For instance, if you make a list request
          and receive 100 objects, ending with obj_foo, your subsequent call can include
          after=obj_foo in order to fetch the next page of the list.

          '
        in: query
        name: after
        schema:
          type: string
      - description: 'A cursor for use in pagination. `before` is an object ID that
          defines your place in the list. For instance, if you make a list request
          and receive 100 objects, ending with obj_foo, your subsequent call can include
          before=obj_foo in order to fetch the previous page of the list.

          '
        in: query
        name: before
        schema:
          type: string
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListAssistantsResponse'
          description: OK
      summary: Returns a list of assistants.
      tags:
      - Assistants
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl \"https://api.openai.com/v1/assistants?order=desc&limit=20\"\
              \ \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization:\
              \ Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const myAssistants = await openai.beta.assistants.list({\n\
              \    order: \"desc\",\n    limit: \"20\",\n  });\n\n  console.log(myAssistants.data);\n\
              }\n\nmain();"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nmy_assistants\
              \ = client.beta.assistants.list(\n    order=\"desc\",\n    limit=\"\
              20\",\n)\nprint(my_assistants.data)\n"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\"\
            : \"asst_abc123\",\n      \"object\": \"assistant\",\n      \"created_at\"\
            : 1698982736,\n      \"name\": \"Coding Tutor\",\n      \"description\"\
            : null,\n      \"model\": \"gpt-4-turbo\",\n      \"instructions\": \"\
            You are a helpful assistant designed to make me better at coding!\",\n\
            \      \"tools\": [],\n      \"tool_resources\": {},\n      \"metadata\"\
            : {},\n      \"top_p\": 1.0,\n      \"temperature\": 1.0,\n      \"response_format\"\
            : \"auto\"\n    },\n    {\n      \"id\": \"asst_abc456\",\n      \"object\"\
            : \"assistant\",\n      \"created_at\": 1698982718,\n      \"name\": \"\
            My Assistant\",\n      \"description\": null,\n      \"model\": \"gpt-4-turbo\"\
            ,\n      \"instructions\": \"You are a helpful assistant designed to make\
            \ me better at coding!\",\n      \"tools\": [],\n      \"tool_resources\"\
            : {},\n      \"metadata\": {},\n      \"top_p\": 1.0,\n      \"temperature\"\
            : 1.0,\n      \"response_format\": \"auto\"\n    },\n    {\n      \"id\"\
            : \"asst_abc789\",\n      \"object\": \"assistant\",\n      \"created_at\"\
            : 1698982643,\n      \"name\": null,\n      \"description\": null,\n \
            \     \"model\": \"gpt-4-turbo\",\n      \"instructions\": null,\n   \
            \   \"tools\": [],\n      \"tool_resources\": {},\n      \"metadata\"\
            : {},\n      \"top_p\": 1.0,\n      \"temperature\": 1.0,\n      \"response_format\"\
            : \"auto\"\n    }\n  ],\n  \"first_id\": \"asst_abc123\",\n  \"last_id\"\
            : \"asst_abc789\",\n  \"has_more\": false\n}\n"
        group: assistants
        name: List assistants
        returns: A list of [assistant](/docs/api-reference/assistants/object) objects.
    post:
      operationId: createAssistant
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateAssistantRequest'
        required: true
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AssistantObject'
          description: OK
      summary: Create an assistant with a model and instructions.
      tags:
      - Assistants
      x-oaiMeta:
        beta: true
        examples:
        - request:
            curl: "curl \"https://api.openai.com/v1/assistants\" \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\
              \ \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -d '{\n    \"instructions\"\
              : \"You are a personal math tutor. When asked a question, write and\
              \ run Python code to answer the question.\",\n    \"name\": \"Math Tutor\"\
              ,\n    \"tools\": [{\"type\": \"code_interpreter\"}],\n    \"model\"\
              : \"gpt-4-turbo\"\n  }'\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const myAssistant = await openai.beta.assistants.create({\n\
              \    instructions:\n      \"You are a personal math tutor. When asked\
              \ a question, write and run Python code to answer the question.\",\n\
              \    name: \"Math Tutor\",\n    tools: [{ type: \"code_interpreter\"\
              \ }],\n    model: \"gpt-4-turbo\",\n  });\n\n  console.log(myAssistant);\n\
              }\n\nmain();"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nmy_assistant\
              \ = client.beta.assistants.create(\n    instructions=\"You are a personal\
              \ math tutor. When asked a question, write and run Python code to answer\
              \ the question.\",\n    name=\"Math Tutor\",\n    tools=[{\"type\":\
              \ \"code_interpreter\"}],\n    model=\"gpt-4-turbo\",\n)\nprint(my_assistant)\n"
          response: "{\n  \"id\": \"asst_abc123\",\n  \"object\": \"assistant\",\n\
            \  \"created_at\": 1698984975,\n  \"name\": \"Math Tutor\",\n  \"description\"\
            : null,\n  \"model\": \"gpt-4-turbo\",\n  \"instructions\": \"You are\
            \ a personal math tutor. When asked a question, write and run Python code\
            \ to answer the question.\",\n  \"tools\": [\n    {\n      \"type\": \"\
            code_interpreter\"\n    }\n  ],\n  \"metadata\": {},\n  \"top_p\": 1.0,\n\
            \  \"temperature\": 1.0,\n  \"response_format\": \"auto\"\n}\n"
          title: Code Interpreter
        - request:
            curl: "curl https://api.openai.com/v1/assistants \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\
              \ \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -d '{\n    \"instructions\"\
              : \"You are an HR bot, and you have access to files to answer employee\
              \ questions about company policies.\",\n    \"tools\": [{\"type\": \"\
              file_search\"}],\n    \"tool_resources\": {\"file_search\": {\"vector_store_ids\"\
              : [\"vs_123\"]}},\n    \"model\": \"gpt-4-turbo\"\n  }'\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const myAssistant = await openai.beta.assistants.create({\n\
              \    instructions:\n      \"You are an HR bot, and you have access to\
              \ files to answer employee questions about company policies.\",\n  \
              \  name: \"HR Helper\",\n    tools: [{ type: \"file_search\" }],\n \
              \   tool_resources: {\n      file_search: {\n        vector_store_ids:\
              \ [\"vs_123\"]\n      }\n    },\n    model: \"gpt-4-turbo\"\n  });\n\
              \n  console.log(myAssistant);\n}\n\nmain();"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nmy_assistant\
              \ = client.beta.assistants.create(\n    instructions=\"You are an HR\
              \ bot, and you have access to files to answer employee questions about\
              \ company policies.\",\n    name=\"HR Helper\",\n    tools=[{\"type\"\
              : \"file_search\"}],\n    tool_resources={\"file_search\": {\"vector_store_ids\"\
              : [\"vs_123\"]}},\n    model=\"gpt-4-turbo\"\n)\nprint(my_assistant)\n"
          response: "{\n  \"id\": \"asst_abc123\",\n  \"object\": \"assistant\",\n\
            \  \"created_at\": 1699009403,\n  \"name\": \"HR Helper\",\n  \"description\"\
            : null,\n  \"model\": \"gpt-4-turbo\",\n  \"instructions\": \"You are\
            \ an HR bot, and you have access to files to answer employee questions\
            \ about company policies.\",\n  \"tools\": [\n    {\n      \"type\": \"\
            file_search\"\n    }\n  ],\n  \"tool_resources\": {\n    \"file_search\"\
            : {\n      \"vector_store_ids\": [\"vs_123\"]\n    }\n  },\n  \"metadata\"\
            : {},\n  \"top_p\": 1.0,\n  \"temperature\": 1.0,\n  \"response_format\"\
            : \"auto\"\n}\n"
          title: Files
        group: assistants
        name: Create assistant
        returns: An [assistant](/docs/api-reference/assistants/object) object.
  /assistants/{assistant_id}:
    delete:
      operationId: deleteAssistant
      parameters:
      - description: The ID of the assistant to delete.
        in: path
        name: assistant_id
        required: true
        schema:
          type: string
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteAssistantResponse'
          description: OK
      summary: Delete an assistant.
      tags:
      - Assistants
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/assistants/asst_abc123 \\\n  -H\
              \ \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer\
              \ $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -X\
              \ DELETE\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const response = await openai.beta.assistants.del(\"\
              asst_abc123\");\n\n  console.log(response);\n}\nmain();"
            python: 'from openai import OpenAI

              client = OpenAI()


              response = client.beta.assistants.delete("asst_abc123")

              print(response)

              '
          response: "{\n  \"id\": \"asst_abc123\",\n  \"object\": \"assistant.deleted\"\
            ,\n  \"deleted\": true\n}\n"
        group: assistants
        name: Delete assistant
        returns: Deletion status
    get:
      operationId: getAssistant
      parameters:
      - description: The ID of the assistant to retrieve.
        in: path
        name: assistant_id
        required: true
        schema:
          type: string
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AssistantObject'
          description: OK
      summary: Retrieves an assistant.
      tags:
      - Assistants
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/assistants/asst_abc123 \\\n  -H\
              \ \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer\
              \ $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const myAssistant = await openai.beta.assistants.retrieve(\n\
              \    \"asst_abc123\"\n  );\n\n  console.log(myAssistant);\n}\n\nmain();"
            python: 'from openai import OpenAI

              client = OpenAI()


              my_assistant = client.beta.assistants.retrieve("asst_abc123")

              print(my_assistant)

              '
          response: "{\n  \"id\": \"asst_abc123\",\n  \"object\": \"assistant\",\n\
            \  \"created_at\": 1699009709,\n  \"name\": \"HR Helper\",\n  \"description\"\
            : null,\n  \"model\": \"gpt-4-turbo\",\n  \"instructions\": \"You are\
            \ an HR bot, and you have access to files to answer employee questions\
            \ about company policies.\",\n  \"tools\": [\n    {\n      \"type\": \"\
            file_search\"\n    }\n  ],\n  \"metadata\": {},\n  \"top_p\": 1.0,\n \
            \ \"temperature\": 1.0,\n  \"response_format\": \"auto\"\n}\n"
        group: assistants
        name: Retrieve assistant
        returns: The [assistant](/docs/api-reference/assistants/object) object matching
          the specified ID.
    post:
      operationId: modifyAssistant
      parameters:
      - description: The ID of the assistant to modify.
        in: path
        name: assistant_id
        required: true
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ModifyAssistantRequest'
        required: true
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AssistantObject'
          description: OK
      summary: Modifies an assistant.
      tags:
      - Assistants
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/assistants/asst_abc123 \\\n  -H\
              \ \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer\
              \ $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -d\
              \ '{\n      \"instructions\": \"You are an HR bot, and you have access\
              \ to files to answer employee questions about company policies. Always\
              \ response with info from either of the files.\",\n      \"tools\":\
              \ [{\"type\": \"file_search\"}],\n      \"model\": \"gpt-4-turbo\"\n\
              \    }'\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const myUpdatedAssistant = await openai.beta.assistants.update(\n\
              \    \"asst_abc123\",\n    {\n      instructions:\n        \"You are\
              \ an HR bot, and you have access to files to answer employee questions\
              \ about company policies. Always response with info from either of the\
              \ files.\",\n      name: \"HR Helper\",\n      tools: [{ type: \"file_search\"\
              \ }],\n      model: \"gpt-4-turbo\"\n    }\n  );\n\n  console.log(myUpdatedAssistant);\n\
              }\n\nmain();"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nmy_updated_assistant\
              \ = client.beta.assistants.update(\n  \"asst_abc123\",\n  instructions=\"\
              You are an HR bot, and you have access to files to answer employee questions\
              \ about company policies. Always response with info from either of the\
              \ files.\",\n  name=\"HR Helper\",\n  tools=[{\"type\": \"file_search\"\
              }],\n  model=\"gpt-4-turbo\"\n)\n\nprint(my_updated_assistant)\n"
          response: "{\n  \"id\": \"asst_123\",\n  \"object\": \"assistant\",\n  \"\
            created_at\": 1699009709,\n  \"name\": \"HR Helper\",\n  \"description\"\
            : null,\n  \"model\": \"gpt-4-turbo\",\n  \"instructions\": \"You are\
            \ an HR bot, and you have access to files to answer employee questions\
            \ about company policies. Always response with info from either of the\
            \ files.\",\n  \"tools\": [\n    {\n      \"type\": \"file_search\"\n\
            \    }\n  ],\n  \"tool_resources\": {\n    \"file_search\": {\n      \"\
            vector_store_ids\": []\n    }\n  },\n  \"metadata\": {},\n  \"top_p\"\
            : 1.0,\n  \"temperature\": 1.0,\n  \"response_format\": \"auto\"\n}\n"
        group: assistants
        name: Modify assistant
        returns: The modified [assistant](/docs/api-reference/assistants/object) object.
  /audio/speech:
    post:
      operationId: createSpeech
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateSpeechRequest'
        required: true
      responses:
        '200':
          content:
            application/octet-stream:
              schema:
                format: binary
                type: string
          description: OK
          headers:
            Transfer-Encoding:
              description: chunked
              schema:
                type: string
      summary: Generates audio from the input text.
      tags:
      - Audio
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/audio/speech \\\n  -H \"Authorization:\
              \ Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\"\
              \ \\\n  -d '{\n    \"model\": \"tts-1\",\n    \"input\": \"The quick\
              \ brown fox jumped over the lazy dog.\",\n    \"voice\": \"alloy\"\n\
              \  }' \\\n  --output speech.mp3\n"
            node: "import fs from \"fs\";\nimport path from \"path\";\nimport OpenAI\
              \ from \"openai\";\n\nconst openai = new OpenAI();\n\nconst speechFile\
              \ = path.resolve(\"./speech.mp3\");\n\nasync function main() {\n  const\
              \ mp3 = await openai.audio.speech.create({\n    model: \"tts-1\",\n\
              \    voice: \"alloy\",\n    input: \"Today is a wonderful day to build\
              \ something people love!\",\n  });\n  console.log(speechFile);\n  const\
              \ buffer = Buffer.from(await mp3.arrayBuffer());\n  await fs.promises.writeFile(speechFile,\
              \ buffer);\n}\nmain();\n"
            python: "from pathlib import Path\nimport openai\n\nspeech_file_path =\
              \ Path(__file__).parent / \"speech.mp3\"\nresponse = openai.audio.speech.create(\n\
              \  model=\"tts-1\",\n  voice=\"alloy\",\n  input=\"The quick brown fox\
              \ jumped over the lazy dog.\"\n)\nresponse.stream_to_file(speech_file_path)\n"
        group: audio
        name: Create speech
        returns: The audio file content.
  /audio/transcriptions:
    post:
      operationId: createTranscription
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateTranscriptionRequest'
        required: true
      responses:
        '200':
          content:
            application/json:
              schema:
                oneOf:
                - $ref: '#/components/schemas/CreateTranscriptionResponseJson'
                - $ref: '#/components/schemas/CreateTranscriptionResponseVerboseJson'
          description: OK
      summary: Transcribes audio into the input language.
      tags:
      - Audio
      x-oaiMeta:
        examples:
        - request:
            curl: "curl https://api.openai.com/v1/audio/transcriptions \\\n  -H \"\
              Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: multipart/form-data\"\
              \ \\\n  -F file=\"@/path/to/file/audio.mp3\" \\\n  -F model=\"whisper-1\"\
              \n"
            node: "import fs from \"fs\";\nimport OpenAI from \"openai\";\n\nconst\
              \ openai = new OpenAI();\n\nasync function main() {\n  const transcription\
              \ = await openai.audio.transcriptions.create({\n    file: fs.createReadStream(\"\
              audio.mp3\"),\n    model: \"whisper-1\",\n  });\n\n  console.log(transcription.text);\n\
              }\nmain();\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\naudio_file =\
              \ open(\"speech.mp3\", \"rb\")\ntranscript = client.audio.transcriptions.create(\n\
              \  model=\"whisper-1\",\n  file=audio_file\n)\n"
          response: "{\n  \"text\": \"Imagine the wildest idea that you've ever had,\
            \ and you're curious about how it might scale to something that's a 100,\
            \ a 1,000 times bigger. This is a place where you can get to do that.\"\
            \n}\n"
          title: Default
        - request:
            curl: "curl https://api.openai.com/v1/audio/transcriptions \\\n  -H \"\
              Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: multipart/form-data\"\
              \ \\\n  -F file=\"@/path/to/file/audio.mp3\" \\\n  -F \"timestamp_granularities[]=word\"\
              \ \\\n  -F model=\"whisper-1\" \\\n  -F response_format=\"verbose_json\"\
              \n"
            node: "import fs from \"fs\";\nimport OpenAI from \"openai\";\n\nconst\
              \ openai = new OpenAI();\n\nasync function main() {\n  const transcription\
              \ = await openai.audio.transcriptions.create({\n    file: fs.createReadStream(\"\
              audio.mp3\"),\n    model: \"whisper-1\",\n    response_format: \"verbose_json\"\
              ,\n    timestamp_granularities: [\"word\"]\n  });\n\n  console.log(transcription.text);\n\
              }\nmain();\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\naudio_file =\
              \ open(\"speech.mp3\", \"rb\")\ntranscript = client.audio.transcriptions.create(\n\
              \  file=audio_file,\n  model=\"whisper-1\",\n  response_format=\"verbose_json\"\
              ,\n  timestamp_granularities=[\"word\"]\n)\n\nprint(transcript.words)\n"
          response: "{\n  \"task\": \"transcribe\",\n  \"language\": \"english\",\n\
            \  \"duration\": 8.470000267028809,\n  \"text\": \"The beach was a popular\
            \ spot on a hot summer day. People were swimming in the ocean, building\
            \ sandcastles, and playing beach volleyball.\",\n  \"words\": [\n    {\n\
            \      \"word\": \"The\",\n      \"start\": 0.0,\n      \"end\": 0.23999999463558197\n\
            \    },\n    ...\n    {\n      \"word\": \"volleyball\",\n      \"start\"\
            : 7.400000095367432,\n      \"end\": 7.900000095367432\n    }\n  ]\n}\n"
          title: Word timestamps
        - request:
            curl: "curl https://api.openai.com/v1/audio/transcriptions \\\n  -H \"\
              Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: multipart/form-data\"\
              \ \\\n  -F file=\"@/path/to/file/audio.mp3\" \\\n  -F \"timestamp_granularities[]=segment\"\
              \ \\\n  -F model=\"whisper-1\" \\\n  -F response_format=\"verbose_json\"\
              \n"
            node: "import fs from \"fs\";\nimport OpenAI from \"openai\";\n\nconst\
              \ openai = new OpenAI();\n\nasync function main() {\n  const transcription\
              \ = await openai.audio.transcriptions.create({\n    file: fs.createReadStream(\"\
              audio.mp3\"),\n    model: \"whisper-1\",\n    response_format: \"verbose_json\"\
              ,\n    timestamp_granularities: [\"segment\"]\n  });\n\n  console.log(transcription.text);\n\
              }\nmain();\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\naudio_file =\
              \ open(\"speech.mp3\", \"rb\")\ntranscript = client.audio.transcriptions.create(\n\
              \  file=audio_file,\n  model=\"whisper-1\",\n  response_format=\"verbose_json\"\
              ,\n  timestamp_granularities=[\"segment\"]\n)\n\nprint(transcript.words)\n"
          response: "{\n  \"task\": \"transcribe\",\n  \"language\": \"english\",\n\
            \  \"duration\": 8.470000267028809,\n  \"text\": \"The beach was a popular\
            \ spot on a hot summer day. People were swimming in the ocean, building\
            \ sandcastles, and playing beach volleyball.\",\n  \"segments\": [\n \
            \   {\n      \"id\": 0,\n      \"seek\": 0,\n      \"start\": 0.0,\n \
            \     \"end\": 3.319999933242798,\n      \"text\": \" The beach was a\
            \ popular spot on a hot summer day.\",\n      \"tokens\": [\n        50364,\
            \ 440, 7534, 390, 257, 3743, 4008, 322, 257, 2368, 4266, 786, 13, 50530\n\
            \      ],\n      \"temperature\": 0.0,\n      \"avg_logprob\": -0.2860786020755768,\n\
            \      \"compression_ratio\": 1.2363636493682861,\n      \"no_speech_prob\"\
            : 0.00985979475080967\n    },\n    ...\n  ]\n}\n"
          title: Segment timestamps
        group: audio
        name: Create transcription
        returns: The [transcription object](/docs/api-reference/audio/json-object)
          or a [verbose transcription object](/docs/api-reference/audio/verbose-json-object).
  /audio/translations:
    post:
      operationId: createTranslation
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateTranslationRequest'
        required: true
      responses:
        '200':
          content:
            application/json:
              schema:
                oneOf:
                - $ref: '#/components/schemas/CreateTranslationResponseJson'
                - $ref: '#/components/schemas/CreateTranslationResponseVerboseJson'
          description: OK
      summary: Translates audio into English.
      tags:
      - Audio
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/audio/translations \\\n  -H \"Authorization:\
              \ Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: multipart/form-data\"\
              \ \\\n  -F file=\"@/path/to/file/german.m4a\" \\\n  -F model=\"whisper-1\"\
              \n"
            node: "import fs from \"fs\";\nimport OpenAI from \"openai\";\n\nconst\
              \ openai = new OpenAI();\n\nasync function main() {\n    const translation\
              \ = await openai.audio.translations.create({\n        file: fs.createReadStream(\"\
              speech.mp3\"),\n        model: \"whisper-1\",\n    });\n\n    console.log(translation.text);\n\
              }\nmain();\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\naudio_file =\
              \ open(\"speech.mp3\", \"rb\")\ntranscript = client.audio.translations.create(\n\
              \  model=\"whisper-1\",\n  file=audio_file\n)\n"
          response: "{\n  \"text\": \"Hello, my name is Wolfgang and I come from Germany.\
            \ Where are you heading today?\"\n}\n"
        group: audio
        name: Create translation
        returns: The translated text.
  /batches:
    get:
      operationId: listBatches
      parameters:
      - description: 'A cursor for use in pagination. `after` is an object ID that
          defines your place in the list. For instance, if you make a list request
          and receive 100 objects, ending with obj_foo, your subsequent call can include
          after=obj_foo in order to fetch the next page of the list.

          '
        in: query
        name: after
        required: false
        schema:
          type: string
      - description: 'A limit on the number of objects to be returned. Limit can range
          between 1 and 100, and the default is 20.

          '
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListBatchesResponse'
          description: Batch listed successfully.
      summary: List your organization's batches.
      tags:
      - Batch
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/batches?limit=2 \\\n  -H \"Authorization:\
              \ Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\"\
              \n"
            node: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const list = await openai.batches.list();\n\
              \n  for await (const batch of list) {\n    console.log(batch);\n  }\n\
              }\n\nmain();\n"
            python: 'from openai import OpenAI

              client = OpenAI()


              client.batches.list()

              '
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\"\
            : \"batch_abc123\",\n      \"object\": \"batch\",\n      \"endpoint\"\
            : \"/v1/chat/completions\",\n      \"errors\": null,\n      \"input_file_id\"\
            : \"file-abc123\",\n      \"completion_window\": \"24h\",\n      \"status\"\
            : \"completed\",\n      \"output_file_id\": \"file-cvaTdG\",\n      \"\
            error_file_id\": \"file-HOWS94\",\n      \"created_at\": 1711471533,\n\
            \      \"in_progress_at\": 1711471538,\n      \"expires_at\": 1711557933,\n\
            \      \"finalizing_at\": 1711493133,\n      \"completed_at\": 1711493163,\n\
            \      \"failed_at\": null,\n      \"expired_at\": null,\n      \"cancelling_at\"\
            : null,\n      \"cancelled_at\": null,\n      \"request_counts\": {\n\
            \        \"total\": 100,\n        \"completed\": 95,\n        \"failed\"\
            : 5\n      },\n      \"metadata\": {\n        \"customer_id\": \"user_123456789\"\
            ,\n        \"batch_description\": \"Nightly job\",\n      }\n    },\n\
            \    { ... },\n  ],\n  \"first_id\": \"batch_abc123\",\n  \"last_id\"\
            : \"batch_abc456\",\n  \"has_more\": true\n}\n"
        group: batch
        name: List batch
        returns: A list of paginated [Batch](/docs/api-reference/batch/object) objects.
    post:
      operationId: createBatch
      requestBody:
        content:
          application/json:
            schema:
              properties:
                completion_window:
                  description: The time frame within which the batch should be processed.
                    Currently only `24h` is supported.
                  enum:
                  - 24h
                  type: string
                endpoint:
                  description: The endpoint to be used for all requests in the batch.
                    Currently `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions`
                    are supported. Note that `/v1/embeddings` batches are also restricted
                    to a maximum of 50,000 embedding inputs across all requests in
                    the batch.
                  enum:
                  - /v1/chat/completions
                  - /v1/embeddings
                  - /v1/completions
                  type: string
                input_file_id:
                  description: 'The ID of an uploaded file that contains requests
                    for the new batch.


                    See [upload file](/docs/api-reference/files/create) for how to
                    upload a file.


                    Your input file must be formatted as a [JSONL file](/docs/api-reference/batch/request-input),
                    and must be uploaded with the purpose `batch`. The file can contain
                    up to 50,000 requests, and can be up to 100 MB in size.

                    '
                  type: string
                metadata:
                  additionalProperties:
                    type: string
                  description: Optional custom metadata for the batch.
                  nullable: true
                  type: object
              required:
              - input_file_id
              - endpoint
              - completion_window
              type: object
        required: true
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Batch'
          description: Batch created successfully.
      summary: Creates and executes a batch from an uploaded file of requests
      tags:
      - Batch
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/batches \\\n  -H \"Authorization:\
              \ Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\"\
              \ \\\n  -d '{\n    \"input_file_id\": \"file-abc123\",\n    \"endpoint\"\
              : \"/v1/chat/completions\",\n    \"completion_window\": \"24h\"\n  }'\n"
            node: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const batch = await openai.batches.create({\n\
              \    input_file_id: \"file-abc123\",\n    endpoint: \"/v1/chat/completions\"\
              ,\n    completion_window: \"24h\"\n  });\n\n  console.log(batch);\n\
              }\n\nmain();\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nclient.batches.create(\n\
              \  input_file_id=\"file-abc123\",\n  endpoint=\"/v1/chat/completions\"\
              ,\n  completion_window=\"24h\"\n)\n"
          response: "{\n  \"id\": \"batch_abc123\",\n  \"object\": \"batch\",\n  \"\
            endpoint\": \"/v1/chat/completions\",\n  \"errors\": null,\n  \"input_file_id\"\
            : \"file-abc123\",\n  \"completion_window\": \"24h\",\n  \"status\": \"\
            validating\",\n  \"output_file_id\": null,\n  \"error_file_id\": null,\n\
            \  \"created_at\": 1711471533,\n  \"in_progress_at\": null,\n  \"expires_at\"\
            : null,\n  \"finalizing_at\": null,\n  \"completed_at\": null,\n  \"failed_at\"\
            : null,\n  \"expired_at\": null,\n  \"cancelling_at\": null,\n  \"cancelled_at\"\
            : null,\n  \"request_counts\": {\n    \"total\": 0,\n    \"completed\"\
            : 0,\n    \"failed\": 0\n  },\n  \"metadata\": {\n    \"customer_id\"\
            : \"user_123456789\",\n    \"batch_description\": \"Nightly eval job\"\
            ,\n  }\n}\n"
        group: batch
        name: Create batch
        returns: The created [Batch](/docs/api-reference/batch/object) object.
  /batches/{batch_id}:
    get:
      operationId: retrieveBatch
      parameters:
      - description: The ID of the batch to retrieve.
        in: path
        name: batch_id
        required: true
        schema:
          type: string
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Batch'
          description: Batch retrieved successfully.
      summary: Retrieves a batch.
      tags:
      - Batch
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/batches/batch_abc123 \\\n  -H \"\
              Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\"\
              \ \\\n"
            node: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const batch = await openai.batches.retrieve(\"\
              batch_abc123\");\n\n  console.log(batch);\n}\n\nmain();\n"
            python: 'from openai import OpenAI

              client = OpenAI()


              client.batches.retrieve("batch_abc123")

              '
          response: "{\n  \"id\": \"batch_abc123\",\n  \"object\": \"batch\",\n  \"\
            endpoint\": \"/v1/completions\",\n  \"errors\": null,\n  \"input_file_id\"\
            : \"file-abc123\",\n  \"completion_window\": \"24h\",\n  \"status\": \"\
            completed\",\n  \"output_file_id\": \"file-cvaTdG\",\n  \"error_file_id\"\
            : \"file-HOWS94\",\n  \"created_at\": 1711471533,\n  \"in_progress_at\"\
            : 1711471538,\n  \"expires_at\": 1711557933,\n  \"finalizing_at\": 1711493133,\n\
            \  \"completed_at\": 1711493163,\n  \"failed_at\": null,\n  \"expired_at\"\
            : null,\n  \"cancelling_at\": null,\n  \"cancelled_at\": null,\n  \"request_counts\"\
            : {\n    \"total\": 100,\n    \"completed\": 95,\n    \"failed\": 5\n\
            \  },\n  \"metadata\": {\n    \"customer_id\": \"user_123456789\",\n \
            \   \"batch_description\": \"Nightly eval job\",\n  }\n}\n"
        group: batch
        name: Retrieve batch
        returns: The [Batch](/docs/api-reference/batch/object) object matching the
          specified ID.
  /batches/{batch_id}/cancel:
    post:
      operationId: cancelBatch
      parameters:
      - description: The ID of the batch to cancel.
        in: path
        name: batch_id
        required: true
        schema:
          type: string
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Batch'
          description: Batch is cancelling. Returns the cancelling batch's details.
      summary: Cancels an in-progress batch. The batch will be in status `cancelling`
        for up to 10 minutes, before changing to `cancelled`, where it will have partial
        results (if any) available in the output file.
      tags:
      - Batch
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/batches/batch_abc123/cancel \\\n\
              \  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -X POST\n"
            node: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const batch = await openai.batches.cancel(\"\
              batch_abc123\");\n\n  console.log(batch);\n}\n\nmain();\n"
            python: 'from openai import OpenAI

              client = OpenAI()


              client.batches.cancel("batch_abc123")

              '
          response: "{\n  \"id\": \"batch_abc123\",\n  \"object\": \"batch\",\n  \"\
            endpoint\": \"/v1/chat/completions\",\n  \"errors\": null,\n  \"input_file_id\"\
            : \"file-abc123\",\n  \"completion_window\": \"24h\",\n  \"status\": \"\
            cancelling\",\n  \"output_file_id\": null,\n  \"error_file_id\": null,\n\
            \  \"created_at\": 1711471533,\n  \"in_progress_at\": 1711471538,\n  \"\
            expires_at\": 1711557933,\n  \"finalizing_at\": null,\n  \"completed_at\"\
            : null,\n  \"failed_at\": null,\n  \"expired_at\": null,\n  \"cancelling_at\"\
            : 1711475133,\n  \"cancelled_at\": null,\n  \"request_counts\": {\n  \
            \  \"total\": 100,\n    \"completed\": 23,\n    \"failed\": 1\n  },\n\
            \  \"metadata\": {\n    \"customer_id\": \"user_123456789\",\n    \"batch_description\"\
            : \"Nightly eval job\",\n  }\n}\n"
        group: batch
        name: Cancel batch
        returns: The [Batch](/docs/api-reference/batch/object) object matching the
          specified ID.
  /chat/completions:
    post:
      operationId: createChatCompletion
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateChatCompletionRequest'
        required: true
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateChatCompletionResponse'
          description: OK
      summary: Creates a model response for the given chat conversation.
      tags:
      - Chat
      x-oaiMeta:
        examples:
        - request:
            curl: "curl https://api.openai.com/v1/chat/completions \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\
              \ \\\n  -d '{\n    \"model\": \"VAR_model_id\",\n    \"messages\": [\n\
              \      {\n        \"role\": \"system\",\n        \"content\": \"You\
              \ are a helpful assistant.\"\n      },\n      {\n        \"role\": \"\
              user\",\n        \"content\": \"Hello!\"\n      }\n    ]\n  }'\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const completion = await openai.chat.completions.create({\n\
              \    messages: [{ role: \"system\", content: \"You are a helpful assistant.\"\
              \ }],\n    model: \"VAR_model_id\",\n  });\n\n  console.log(completion.choices[0]);\n\
              }\n\nmain();"
            python: "from openai import OpenAI\nclient = OpenAI()\n\ncompletion =\
              \ client.chat.completions.create(\n  model=\"VAR_model_id\",\n  messages=[\n\
              \    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"\
              },\n    {\"role\": \"user\", \"content\": \"Hello!\"}\n  ]\n)\n\nprint(completion.choices[0].message)\n"
          response: "{\n  \"id\": \"chatcmpl-123\",\n  \"object\": \"chat.completion\"\
            ,\n  \"created\": 1677652288,\n  \"model\": \"gpt-3.5-turbo-0125\",\n\
            \  \"system_fingerprint\": \"fp_44709d6fcb\",\n  \"choices\": [{\n   \
            \ \"index\": 0,\n    \"message\": {\n      \"role\": \"assistant\",\n\
            \      \"content\": \"\\n\\nHello there, how may I assist you today?\"\
            ,\n    },\n    \"logprobs\": null,\n    \"finish_reason\": \"stop\"\n\
            \  }],\n  \"usage\": {\n    \"prompt_tokens\": 9,\n    \"completion_tokens\"\
            : 12,\n    \"total_tokens\": 21\n  }\n}\n"
          title: Default
        - request:
            curl: "curl https://api.openai.com/v1/chat/completions \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\
              \ \\\n  -d '{\n    \"model\": \"gpt-4-turbo\",\n    \"messages\": [\n\
              \      {\n        \"role\": \"user\",\n        \"content\": [\n    \
              \      {\n            \"type\": \"text\",\n            \"text\": \"\
              What'\\''s in this image?\"\n          },\n          {\n           \
              \ \"type\": \"image_url\",\n            \"image_url\": {\n         \
              \     \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"\
              \n            }\n          }\n        ]\n      }\n    ],\n    \"max_tokens\"\
              : 300\n  }'\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const response = await openai.chat.completions.create({\n\
              \    model: \"gpt-4-turbo\",\n    messages: [\n      {\n        role:\
              \ \"user\",\n        content: [\n          { type: \"text\", text: \"\
              What's in this image?\" },\n          {\n            type: \"image_url\"\
              ,\n            image_url:\n              \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"\
              ,\n          },\n        ],\n      },\n    ],\n  });\n  console.log(response.choices[0]);\n\
              }\nmain();"
            python: "from openai import OpenAI\n\nclient = OpenAI()\n\nresponse =\
              \ client.chat.completions.create(\n    model=\"gpt-4-turbo\",\n    messages=[\n\
              \        {\n            \"role\": \"user\",\n            \"content\"\
              : [\n                {\"type\": \"text\", \"text\": \"What's in this\
              \ image?\"},\n                {\n                    \"type\": \"image_url\"\
              ,\n                    \"image_url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"\
              ,\n                },\n            ],\n        }\n    ],\n    max_tokens=300,\n\
              )\n\nprint(response.choices[0])\n"
          response: "{\n  \"id\": \"chatcmpl-123\",\n  \"object\": \"chat.completion\"\
            ,\n  \"created\": 1677652288,\n  \"model\": \"gpt-3.5-turbo-0125\",\n\
            \  \"system_fingerprint\": \"fp_44709d6fcb\",\n  \"choices\": [{\n   \
            \ \"index\": 0,\n    \"message\": {\n      \"role\": \"assistant\",\n\
            \      \"content\": \"\\n\\nThis image shows a wooden boardwalk extending\
            \ through a lush green marshland.\",\n    },\n    \"logprobs\": null,\n\
            \    \"finish_reason\": \"stop\"\n  }],\n  \"usage\": {\n    \"prompt_tokens\"\
            : 9,\n    \"completion_tokens\": 12,\n    \"total_tokens\": 21\n  }\n\
            }\n"
          title: Image input
        - request:
            curl: "curl https://api.openai.com/v1/chat/completions \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\
              \ \\\n  -d '{\n    \"model\": \"VAR_model_id\",\n    \"messages\": [\n\
              \      {\n        \"role\": \"system\",\n        \"content\": \"You\
              \ are a helpful assistant.\"\n      },\n      {\n        \"role\": \"\
              user\",\n        \"content\": \"Hello!\"\n      }\n    ],\n    \"stream\"\
              : true\n  }'\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const completion = await openai.chat.completions.create({\n\
              \    model: \"VAR_model_id\",\n    messages: [\n      {\"role\": \"\
              system\", \"content\": \"You are a helpful assistant.\"},\n      {\"\
              role\": \"user\", \"content\": \"Hello!\"}\n    ],\n    stream: true,\n\
              \  });\n\n  for await (const chunk of completion) {\n    console.log(chunk.choices[0].delta.content);\n\
              \  }\n}\n\nmain();"
            python: "from openai import OpenAI\nclient = OpenAI()\n\ncompletion =\
              \ client.chat.completions.create(\n  model=\"VAR_model_id\",\n  messages=[\n\
              \    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"\
              },\n    {\"role\": \"user\", \"content\": \"Hello!\"}\n  ],\n  stream=True\n\
              )\n\nfor chunk in completion:\n  print(chunk.choices[0].delta)\n"
          response: '{"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-3.5-turbo-0125",
            "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}


            {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-3.5-turbo-0125",
            "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"content":"Hello"},"logprobs":null,"finish_reason":null}]}


            ....


            {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-3.5-turbo-0125",
            "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}

            '
          title: Streaming
        - request:
            curl: "curl https://api.openai.com/v1/chat/completions \\\n-H \"Content-Type:\
              \ application/json\" \\\n-H \"Authorization: Bearer $OPENAI_API_KEY\"\
              \ \\\n-d '{\n  \"model\": \"gpt-4-turbo\",\n  \"messages\": [\n    {\n\
              \      \"role\": \"user\",\n      \"content\": \"What'\\''s the weather\
              \ like in Boston today?\"\n    }\n  ],\n  \"tools\": [\n    {\n    \
              \  \"type\": \"function\",\n      \"function\": {\n        \"name\"\
              : \"get_current_weather\",\n        \"description\": \"Get the current\
              \ weather in a given location\",\n        \"parameters\": {\n      \
              \    \"type\": \"object\",\n          \"properties\": {\n          \
              \  \"location\": {\n              \"type\": \"string\",\n          \
              \    \"description\": \"The city and state, e.g. San Francisco, CA\"\
              \n            },\n            \"unit\": {\n              \"type\": \"\
              string\",\n              \"enum\": [\"celsius\", \"fahrenheit\"]\n \
              \           }\n          },\n          \"required\": [\"location\"]\n\
              \        }\n      }\n    }\n  ],\n  \"tool_choice\": \"auto\"\n}'\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const messages = [{\"role\": \"user\",\
              \ \"content\": \"What's the weather like in Boston today?\"}];\n  const\
              \ tools = [\n      {\n        \"type\": \"function\",\n        \"function\"\
              : {\n          \"name\": \"get_current_weather\",\n          \"description\"\
              : \"Get the current weather in a given location\",\n          \"parameters\"\
              : {\n            \"type\": \"object\",\n            \"properties\":\
              \ {\n              \"location\": {\n                \"type\": \"string\"\
              ,\n                \"description\": \"The city and state, e.g. San Francisco,\
              \ CA\",\n              },\n              \"unit\": {\"type\": \"string\"\
              , \"enum\": [\"celsius\", \"fahrenheit\"]},\n            },\n      \
              \      \"required\": [\"location\"],\n          },\n        }\n    \
              \  }\n  ];\n\n  const response = await openai.chat.completions.create({\n\
              \    model: \"gpt-4-turbo\",\n    messages: messages,\n    tools: tools,\n\
              \    tool_choice: \"auto\",\n  });\n\n  console.log(response);\n}\n\n\
              main();"
            python: "from openai import OpenAI\nclient = OpenAI()\n\ntools = [\n \
              \ {\n    \"type\": \"function\",\n    \"function\": {\n      \"name\"\
              : \"get_current_weather\",\n      \"description\": \"Get the current\
              \ weather in a given location\",\n      \"parameters\": {\n        \"\
              type\": \"object\",\n        \"properties\": {\n          \"location\"\
              : {\n            \"type\": \"string\",\n            \"description\"\
              : \"The city and state, e.g. San Francisco, CA\",\n          },\n  \
              \        \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"\
              fahrenheit\"]},\n        },\n        \"required\": [\"location\"],\n\
              \      },\n    }\n  }\n]\nmessages = [{\"role\": \"user\", \"content\"\
              : \"What's the weather like in Boston today?\"}]\ncompletion = client.chat.completions.create(\n\
              \  model=\"VAR_model_id\",\n  messages=messages,\n  tools=tools,\n \
              \ tool_choice=\"auto\"\n)\n\nprint(completion)\n"
          response: "{\n  \"id\": \"chatcmpl-abc123\",\n  \"object\": \"chat.completion\"\
            ,\n  \"created\": 1699896916,\n  \"model\": \"gpt-3.5-turbo-0125\",\n\
            \  \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n\
            \        \"role\": \"assistant\",\n        \"content\": null,\n      \
            \  \"tool_calls\": [\n          {\n            \"id\": \"call_abc123\"\
            ,\n            \"type\": \"function\",\n            \"function\": {\n\
            \              \"name\": \"get_current_weather\",\n              \"arguments\"\
            : \"{\\n\\\"location\\\": \\\"Boston, MA\\\"\\n}\"\n            }\n  \
            \        }\n        ]\n      },\n      \"logprobs\": null,\n      \"finish_reason\"\
            : \"tool_calls\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\":\
            \ 82,\n    \"completion_tokens\": 17,\n    \"total_tokens\": 99\n  }\n\
            }\n"
          title: Functions
        - request:
            curl: "curl https://api.openai.com/v1/chat/completions \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\
              \ \\\n  -d '{\n    \"model\": \"VAR_model_id\",\n    \"messages\": [\n\
              \      {\n        \"role\": \"user\",\n        \"content\": \"Hello!\"\
              \n      }\n    ],\n    \"logprobs\": true,\n    \"top_logprobs\": 2\n\
              \  }'\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const completion = await openai.chat.completions.create({\n\
              \    messages: [{ role: \"user\", content: \"Hello!\" }],\n    model:\
              \ \"VAR_model_id\",\n    logprobs: true,\n    top_logprobs: 2,\n  });\n\
              \n  console.log(completion.choices[0]);\n}\n\nmain();"
            python: "from openai import OpenAI\nclient = OpenAI()\n\ncompletion =\
              \ client.chat.completions.create(\n  model=\"VAR_model_id\",\n  messages=[\n\
              \    {\"role\": \"user\", \"content\": \"Hello!\"}\n  ],\n  logprobs=True,\n\
              \  top_logprobs=2\n)\n\nprint(completion.choices[0].message)\nprint(completion.choices[0].logprobs)\n"
          response: "{\n  \"id\": \"chatcmpl-123\",\n  \"object\": \"chat.completion\"\
            ,\n  \"created\": 1702685778,\n  \"model\": \"gpt-3.5-turbo-0125\",\n\
            \  \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n\
            \        \"role\": \"assistant\",\n        \"content\": \"Hello! How can\
            \ I assist you today?\"\n      },\n      \"logprobs\": {\n        \"content\"\
            : [\n          {\n            \"token\": \"Hello\",\n            \"logprob\"\
            : -0.31725305,\n            \"bytes\": [72, 101, 108, 108, 111],\n   \
            \         \"top_logprobs\": [\n              {\n                \"token\"\
            : \"Hello\",\n                \"logprob\": -0.31725305,\n            \
            \    \"bytes\": [72, 101, 108, 108, 111]\n              },\n         \
            \     {\n                \"token\": \"Hi\",\n                \"logprob\"\
            : -1.3190403,\n                \"bytes\": [72, 105]\n              }\n\
            \            ]\n          },\n          {\n            \"token\": \"!\"\
            ,\n            \"logprob\": -0.02380986,\n            \"bytes\": [\n \
            \             33\n            ],\n            \"top_logprobs\": [\n  \
            \            {\n                \"token\": \"!\",\n                \"\
            logprob\": -0.02380986,\n                \"bytes\": [33]\n           \
            \   },\n              {\n                \"token\": \" there\",\n    \
            \            \"logprob\": -3.787621,\n                \"bytes\": [32,\
            \ 116, 104, 101, 114, 101]\n              }\n            ]\n         \
            \ },\n          {\n            \"token\": \" How\",\n            \"logprob\"\
            : -0.000054669687,\n            \"bytes\": [32, 72, 111, 119],\n     \
            \       \"top_logprobs\": [\n              {\n                \"token\"\
            : \" How\",\n                \"logprob\": -0.000054669687,\n         \
            \       \"bytes\": [32, 72, 111, 119]\n              },\n            \
            \  {\n                \"token\": \"<|end|>\",\n                \"logprob\"\
            : -10.953937,\n                \"bytes\": null\n              }\n    \
            \        ]\n          },\n          {\n            \"token\": \" can\"\
            ,\n            \"logprob\": -0.015801601,\n            \"bytes\": [32,\
            \ 99, 97, 110],\n            \"top_logprobs\": [\n              {\n  \
            \              \"token\": \" can\",\n                \"logprob\": -0.015801601,\n\
            \                \"bytes\": [32, 99, 97, 110]\n              },\n    \
            \          {\n                \"token\": \" may\",\n                \"\
            logprob\": -4.161023,\n                \"bytes\": [32, 109, 97, 121]\n\
            \              }\n            ]\n          },\n          {\n         \
            \   \"token\": \" I\",\n            \"logprob\": -3.7697225e-6,\n    \
            \        \"bytes\": [\n              32,\n              73\n         \
            \   ],\n            \"top_logprobs\": [\n              {\n           \
            \     \"token\": \" I\",\n                \"logprob\": -3.7697225e-6,\n\
            \                \"bytes\": [32, 73]\n              },\n             \
            \ {\n                \"token\": \" assist\",\n                \"logprob\"\
            : -13.596657,\n                \"bytes\": [32, 97, 115, 115, 105, 115,\
            \ 116]\n              }\n            ]\n          },\n          {\n  \
            \          \"token\": \" assist\",\n            \"logprob\": -0.04571125,\n\
            \            \"bytes\": [32, 97, 115, 115, 105, 115, 116],\n         \
            \   \"top_logprobs\": [\n              {\n                \"token\": \"\
            \ assist\",\n                \"logprob\": -0.04571125,\n             \
            \   \"bytes\": [32, 97, 115, 115, 105, 115, 116]\n              },\n \
            \             {\n                \"token\": \" help\",\n             \
            \   \"logprob\": -3.1089056,\n                \"bytes\": [32, 104, 101,\
            \ 108, 112]\n              }\n            ]\n          },\n          {\n\
            \            \"token\": \" you\",\n            \"logprob\": -5.4385737e-6,\n\
            \            \"bytes\": [32, 121, 111, 117],\n            \"top_logprobs\"\
            : [\n              {\n                \"token\": \" you\",\n         \
            \       \"logprob\": -5.4385737e-6,\n                \"bytes\": [32, 121,\
            \ 111, 117]\n              },\n              {\n                \"token\"\
            : \" today\",\n                \"logprob\": -12.807695,\n            \
            \    \"bytes\": [32, 116, 111, 100, 97, 121]\n              }\n      \
            \      ]\n          },\n          {\n            \"token\": \" today\"\
            ,\n            \"logprob\": -0.0040071653,\n            \"bytes\": [32,\
            \ 116, 111, 100, 97, 121],\n            \"top_logprobs\": [\n        \
            \      {\n                \"token\": \" today\",\n                \"logprob\"\
            : -0.0040071653,\n                \"bytes\": [32, 116, 111, 100, 97, 121]\n\
            \              },\n              {\n                \"token\": \"?\",\n\
            \                \"logprob\": -5.5247097,\n                \"bytes\":\
            \ [63]\n              }\n            ]\n          },\n          {\n  \
            \          \"token\": \"?\",\n            \"logprob\": -0.0008108172,\n\
            \            \"bytes\": [63],\n            \"top_logprobs\": [\n     \
            \         {\n                \"token\": \"?\",\n                \"logprob\"\
            : -0.0008108172,\n                \"bytes\": [63]\n              },\n\
            \              {\n                \"token\": \"?\\n\",\n             \
            \   \"logprob\": -7.184561,\n                \"bytes\": [63, 10]\n   \
            \           }\n            ]\n          }\n        ]\n      },\n     \
            \ \"finish_reason\": \"stop\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\"\
            : 9,\n    \"completion_tokens\": 9,\n    \"total_tokens\": 18\n  },\n\
            \  \"system_fingerprint\": null\n}\n"
          title: Logprobs
        group: chat
        name: Create chat completion
        path: create
        returns: 'Returns a [chat completion](/docs/api-reference/chat/object) object,
          or a streamed sequence of [chat completion chunk](/docs/api-reference/chat/streaming)
          objects if the request is streamed.

          '
  /completions:
    post:
      operationId: createCompletion
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateCompletionRequest'
        required: true
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateCompletionResponse'
          description: OK
      summary: Creates a completion for the provided prompt and parameters.
      tags:
      - Completions
      x-oaiMeta:
        examples:
        - request:
            curl: "curl https://api.openai.com/v1/completions \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\
              \ \\\n  -d '{\n    \"model\": \"VAR_model_id\",\n    \"prompt\": \"\
              Say this is a test\",\n    \"max_tokens\": 7,\n    \"temperature\":\
              \ 0\n  }'\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const completion = await openai.completions.create({\n\
              \    model: \"VAR_model_id\",\n    prompt: \"Say this is a test.\",\n\
              \    max_tokens: 7,\n    temperature: 0,\n  });\n\n  console.log(completion);\n\
              }\nmain();"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nclient.completions.create(\n\
              \  model=\"VAR_model_id\",\n  prompt=\"Say this is a test\",\n  max_tokens=7,\n\
              \  temperature=0\n)\n"
          response: "{\n  \"id\": \"cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7\",\n  \"object\"\
            : \"text_completion\",\n  \"created\": 1589478378,\n  \"model\": \"VAR_model_id\"\
            ,\n  \"system_fingerprint\": \"fp_44709d6fcb\",\n  \"choices\": [\n  \
            \  {\n      \"text\": \"\\n\\nThis is indeed a test\",\n      \"index\"\
            : 0,\n      \"logprobs\": null,\n      \"finish_reason\": \"length\"\n\
            \    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 5,\n    \"completion_tokens\"\
            : 7,\n    \"total_tokens\": 12\n  }\n}\n"
          title: No streaming
        - request:
            curl: "curl https://api.openai.com/v1/completions \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\
              \ \\\n  -d '{\n    \"model\": \"VAR_model_id\",\n    \"prompt\": \"\
              Say this is a test\",\n    \"max_tokens\": 7,\n    \"temperature\":\
              \ 0,\n    \"stream\": true\n  }'\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const stream = await openai.completions.create({\n\
              \    model: \"VAR_model_id\",\n    prompt: \"Say this is a test.\",\n\
              \    stream: true,\n  });\n\n  for await (const chunk of stream) {\n\
              \    console.log(chunk.choices[0].text)\n  }\n}\nmain();"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nfor chunk in\
              \ client.completions.create(\n  model=\"VAR_model_id\",\n  prompt=\"\
              Say this is a test\",\n  max_tokens=7,\n  temperature=0,\n  stream=True\n\
              ):\n  print(chunk.choices[0].text)\n"
          response: "{\n  \"id\": \"cmpl-7iA7iJjj8V2zOkCGvWF2hAkDWBQZe\",\n  \"object\"\
            : \"text_completion\",\n  \"created\": 1690759702,\n  \"choices\": [\n\
            \    {\n      \"text\": \"This\",\n      \"index\": 0,\n      \"logprobs\"\
            : null,\n      \"finish_reason\": null\n    }\n  ],\n  \"model\": \"gpt-3.5-turbo-instruct\"\
            \n  \"system_fingerprint\": \"fp_44709d6fcb\",\n}\n"
          title: Streaming
        group: completions
        legacy: true
        name: Create completion
        returns: 'Returns a [completion](/docs/api-reference/completions/object) object,
          or a sequence of completion objects if the request is streamed.

          '
  /embeddings:
    post:
      operationId: createEmbedding
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateEmbeddingRequest'
        required: true
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateEmbeddingResponse'
          description: OK
      summary: Creates an embedding vector representing the input text.
      tags:
      - Embeddings
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/embeddings \\\n  -H \"Authorization:\
              \ Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\"\
              \ \\\n  -d '{\n    \"input\": \"The food was delicious and the waiter...\"\
              ,\n    \"model\": \"text-embedding-ada-002\",\n    \"encoding_format\"\
              : \"float\"\n  }'\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const embedding = await openai.embeddings.create({\n\
              \    model: \"text-embedding-ada-002\",\n    input: \"The quick brown\
              \ fox jumped over the lazy dog\",\n    encoding_format: \"float\",\n\
              \  });\n\n  console.log(embedding);\n}\n\nmain();"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nclient.embeddings.create(\n\
              \  model=\"text-embedding-ada-002\",\n  input=\"The food was delicious\
              \ and the waiter...\",\n  encoding_format=\"float\"\n)\n"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\"\
            : \"embedding\",\n      \"embedding\": [\n        0.0023064255,\n    \
            \    -0.009327292,\n        .... (1536 floats total for ada-002)\n   \
            \     -0.0028842222,\n      ],\n      \"index\": 0\n    }\n  ],\n  \"\
            model\": \"text-embedding-ada-002\",\n  \"usage\": {\n    \"prompt_tokens\"\
            : 8,\n    \"total_tokens\": 8\n  }\n}\n"
        group: embeddings
        name: Create embeddings
        returns: A list of [embedding](/docs/api-reference/embeddings/object) objects.
  /files:
    get:
      operationId: listFiles
      parameters:
      - description: Only return files with the given purpose.
        in: query
        name: purpose
        required: false
        schema:
          type: string
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListFilesResponse'
          description: OK
      summary: Returns a list of files that belong to the user's organization.
      tags:
      - Files
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/files \\\n  -H \"Authorization:\
              \ Bearer $OPENAI_API_KEY\"\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const list = await openai.files.list();\n\
              \n  for await (const file of list) {\n    console.log(file);\n  }\n\
              }\n\nmain();"
            python: 'from openai import OpenAI

              client = OpenAI()


              client.files.list()

              '
          response: "{\n  \"data\": [\n    {\n      \"id\": \"file-abc123\",\n   \
            \   \"object\": \"file\",\n      \"bytes\": 175,\n      \"created_at\"\
            : 1613677385,\n      \"filename\": \"salesOverview.pdf\",\n      \"purpose\"\
            : \"assistants\",\n    },\n    {\n      \"id\": \"file-abc123\",\n   \
            \   \"object\": \"file\",\n      \"bytes\": 140,\n      \"created_at\"\
            : 1613779121,\n      \"filename\": \"puppy.jsonl\",\n      \"purpose\"\
            : \"fine-tune\",\n    }\n  ],\n  \"object\": \"list\"\n}\n"
        group: files
        name: List files
        returns: A list of [File](/docs/api-reference/files/object) objects.
    post:
      operationId: createFile
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateFileRequest'
        required: true
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/OpenAIFile'
          description: OK
      summary: 'Upload a file that can be used across various endpoints. Individual
        files can be up to 512 MB, and the size of all files uploaded by one organization
        can be up to 100 GB.


        The Assistants API supports files up to 2 million tokens and of specific file
        types. See the [Assistants Tools guide](/docs/assistants/tools) for details.


        The Fine-tuning API only supports `.jsonl` files. The input also has certain
        required formats for fine-tuning [chat](/docs/api-reference/fine-tuning/chat-input)
        or [completions](/docs/api-reference/fine-tuning/completions-input) models.


        The Batch API only supports `.jsonl` files up to 100 MB in size. The input
        also has a specific required [format](/docs/api-reference/batch/request-input).


        Please [contact us](https://help.openai.com/) if you need to increase these
        storage limits.

        '
      tags:
      - Files
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/files \\\n  -H \"Authorization:\
              \ Bearer $OPENAI_API_KEY\" \\\n  -F purpose=\"fine-tune\" \\\n  -F file=\"\
              @mydata.jsonl\"\n"
            node.js: "import fs from \"fs\";\nimport OpenAI from \"openai\";\n\nconst\
              \ openai = new OpenAI();\n\nasync function main() {\n  const file =\
              \ await openai.files.create({\n    file: fs.createReadStream(\"mydata.jsonl\"\
              ),\n    purpose: \"fine-tune\",\n  });\n\n  console.log(file);\n}\n\n\
              main();"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nclient.files.create(\n\
              \  file=open(\"mydata.jsonl\", \"rb\"),\n  purpose=\"fine-tune\"\n)\n"
          response: "{\n  \"id\": \"file-abc123\",\n  \"object\": \"file\",\n  \"\
            bytes\": 120000,\n  \"created_at\": 1677610602,\n  \"filename\": \"mydata.jsonl\"\
            ,\n  \"purpose\": \"fine-tune\",\n}\n"
        group: files
        name: Upload file
        returns: The uploaded [File](/docs/api-reference/files/object) object.
  /files/{file_id}:
    delete:
      operationId: deleteFile
      parameters:
      - description: The ID of the file to use for this request.
        in: path
        name: file_id
        required: true
        schema:
          type: string
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteFileResponse'
          description: OK
      summary: Delete a file.
      tags:
      - Files
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/files/file-abc123 \\\n  -X DELETE\
              \ \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const file = await openai.files.del(\"\
              file-abc123\");\n\n  console.log(file);\n}\n\nmain();"
            python: 'from openai import OpenAI

              client = OpenAI()


              client.files.delete("file-abc123")

              '
          response: "{\n  \"id\": \"file-abc123\",\n  \"object\": \"file\",\n  \"\
            deleted\": true\n}\n"
        group: files
        name: Delete file
        returns: Deletion status.
    get:
      operationId: retrieveFile
      parameters:
      - description: The ID of the file to use for this request.
        in: path
        name: file_id
        required: true
        schema:
          type: string
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/OpenAIFile'
          description: OK
      summary: Returns information about a specific file.
      tags:
      - Files
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/files/file-abc123 \\\n  -H \"Authorization:\
              \ Bearer $OPENAI_API_KEY\"\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const file = await openai.files.retrieve(\"\
              file-abc123\");\n\n  console.log(file);\n}\n\nmain();"
            python: 'from openai import OpenAI

              client = OpenAI()


              client.files.retrieve("file-abc123")

              '
          response: "{\n  \"id\": \"file-abc123\",\n  \"object\": \"file\",\n  \"\
            bytes\": 120000,\n  \"created_at\": 1677610602,\n  \"filename\": \"mydata.jsonl\"\
            ,\n  \"purpose\": \"fine-tune\",\n}\n"
        group: files
        name: Retrieve file
        returns: The [File](/docs/api-reference/files/object) object matching the
          specified ID.
  /files/{file_id}/content:
    get:
      operationId: downloadFile
      parameters:
      - description: The ID of the file to use for this request.
        in: path
        name: file_id
        required: true
        schema:
          type: string
      responses:
        '200':
          content:
            application/json:
              schema:
                type: string
          description: OK
      summary: Returns the contents of the specified file.
      tags:
      - Files
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/files/file-abc123/content \\\n \
              \ -H \"Authorization: Bearer $OPENAI_API_KEY\" > file.jsonl\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const file = await openai.files.content(\"\
              file-abc123\");\n\n  console.log(file);\n}\n\nmain();\n"
            python: 'from openai import OpenAI

              client = OpenAI()


              content = client.files.content("file-abc123")

              '
        group: files
        name: Retrieve file content
        returns: The file content.
  /fine_tuning/jobs:
    get:
      operationId: listPaginatedFineTuningJobs
      parameters:
      - description: Identifier for the last job from the previous pagination request.
        in: query
        name: after
        required: false
        schema:
          type: string
      - description: Number of fine-tuning jobs to retrieve.
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListPaginatedFineTuningJobsResponse'
          description: OK
      summary: 'List your organization''s fine-tuning jobs

        '
      tags:
      - Fine-tuning
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/fine_tuning/jobs?limit=2 \\\n  -H\
              \ \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const list = await openai.fineTuning.jobs.list();\n\
              \n  for await (const fineTune of list) {\n    console.log(fineTune);\n\
              \  }\n}\n\nmain();"
            python: 'from openai import OpenAI

              client = OpenAI()


              client.fine_tuning.jobs.list()

              '
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\"\
            : \"fine_tuning.job.event\",\n      \"id\": \"ft-event-TjX0lMfOniCZX64t9PUQT5hn\"\
            ,\n      \"created_at\": 1689813489,\n      \"level\": \"warn\",\n   \
            \   \"message\": \"Fine tuning process stopping due to job cancellation\"\
            ,\n      \"data\": null,\n      \"type\": \"message\"\n    },\n    { ...\
            \ },\n    { ... }\n  ], \"has_more\": true\n}\n"
        group: fine-tuning
        name: List fine-tuning jobs
        returns: A list of paginated [fine-tuning job](/docs/api-reference/fine-tuning/object)
          objects.
    post:
      operationId: createFineTuningJob
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateFineTuningJobRequest'
        required: true
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FineTuningJob'
          description: OK
      summary: 'Creates a fine-tuning job which begins the process of creating a new
        model from a given dataset.


        Response includes details of the enqueued job including job status and the
        name of the fine-tuned models once complete.


        [Learn more about fine-tuning](/docs/guides/fine-tuning)

        '
      tags:
      - Fine-tuning
      x-oaiMeta:
        examples:
        - request:
            curl: "curl https://api.openai.com/v1/fine_tuning/jobs \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\
              \ \\\n  -d '{\n    \"training_file\": \"file-BK7bzQj3FfZFXr7DbL6xJwfo\"\
              ,\n    \"model\": \"gpt-3.5-turbo\"\n  }'\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const fineTune = await openai.fineTuning.jobs.create({\n\
              \    training_file: \"file-abc123\"\n  });\n\n  console.log(fineTune);\n\
              }\n\nmain();\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nclient.fine_tuning.jobs.create(\n\
              \  training_file=\"file-abc123\",\n  model=\"gpt-3.5-turbo\"\n)\n"
          response: "{\n  \"object\": \"fine_tuning.job\",\n  \"id\": \"ftjob-abc123\"\
            ,\n  \"model\": \"gpt-3.5-turbo-0125\",\n  \"created_at\": 1614807352,\n\
            \  \"fine_tuned_model\": null,\n  \"organization_id\": \"org-123\",\n\
            \  \"result_files\": [],\n  \"status\": \"queued\",\n  \"validation_file\"\
            : null,\n  \"training_file\": \"file-abc123\",\n}\n"
          title: Default
        - request:
            curl: "curl https://api.openai.com/v1/fine_tuning/jobs \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\
              \ \\\n  -d '{\n    \"training_file\": \"file-abc123\",\n    \"model\"\
              : \"gpt-3.5-turbo\",\n    \"hyperparameters\": {\n      \"n_epochs\"\
              : 2\n    }\n  }'\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const fineTune = await openai.fineTuning.jobs.create({\n\
              \    training_file: \"file-abc123\",\n    model: \"gpt-3.5-turbo\",\n\
              \    hyperparameters: { n_epochs: 2 }\n  });\n\n  console.log(fineTune);\n\
              }\n\nmain();\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nclient.fine_tuning.jobs.create(\n\
              \  training_file=\"file-abc123\",\n  model=\"gpt-3.5-turbo\",\n  hyperparameters={\n\
              \    \"n_epochs\":2\n  }\n)\n"
          response: "{\n  \"object\": \"fine_tuning.job\",\n  \"id\": \"ftjob-abc123\"\
            ,\n  \"model\": \"gpt-3.5-turbo-0125\",\n  \"created_at\": 1614807352,\n\
            \  \"fine_tuned_model\": null,\n  \"organization_id\": \"org-123\",\n\
            \  \"result_files\": [],\n  \"status\": \"queued\",\n  \"validation_file\"\
            : null,\n  \"training_file\": \"file-abc123\",\n  \"hyperparameters\"\
            : {\"n_epochs\": 2},\n}\n"
          title: Epochs
        - request:
            curl: "curl https://api.openai.com/v1/fine_tuning/jobs \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\
              \ \\\n  -d '{\n    \"training_file\": \"file-abc123\",\n    \"validation_file\"\
              : \"file-abc123\",\n    \"model\": \"gpt-3.5-turbo\"\n  }'\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const fineTune = await openai.fineTuning.jobs.create({\n\
              \    training_file: \"file-abc123\",\n    validation_file: \"file-abc123\"\
              \n  });\n\n  console.log(fineTune);\n}\n\nmain();\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nclient.fine_tuning.jobs.create(\n\
              \  training_file=\"file-abc123\",\n  validation_file=\"file-def456\"\
              ,\n  model=\"gpt-3.5-turbo\"\n)\n"
          response: "{\n  \"object\": \"fine_tuning.job\",\n  \"id\": \"ftjob-abc123\"\
            ,\n  \"model\": \"gpt-3.5-turbo-0125\",\n  \"created_at\": 1614807352,\n\
            \  \"fine_tuned_model\": null,\n  \"organization_id\": \"org-123\",\n\
            \  \"result_files\": [],\n  \"status\": \"queued\",\n  \"validation_file\"\
            : \"file-abc123\",\n  \"training_file\": \"file-abc123\",\n}\n"
          title: Validation file
        - request:
            curl: "curl https://api.openai.com/v1/fine_tuning/jobs \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\
              \ \\\n  -d '{\n    \"training_file\": \"file-abc123\",\n    \"validation_file\"\
              : \"file-abc123\",\n    \"model\": \"gpt-3.5-turbo\",\n    \"integrations\"\
              : [\n      {\n        \"type\": \"wandb\",\n        \"wandb\": {\n \
              \         \"project\": \"my-wandb-project\",\n          \"name\": \"\
              ft-run-display-name\"\n          \"tags\": [\n            \"first-experiment\"\
              , \"v2\"\n          ]\n        }\n      }\n    ]\n  }'\n"
          response: "{\n  \"object\": \"fine_tuning.job\",\n  \"id\": \"ftjob-abc123\"\
            ,\n  \"model\": \"gpt-3.5-turbo-0125\",\n  \"created_at\": 1614807352,\n\
            \  \"fine_tuned_model\": null,\n  \"organization_id\": \"org-123\",\n\
            \  \"result_files\": [],\n  \"status\": \"queued\",\n  \"validation_file\"\
            : \"file-abc123\",\n  \"training_file\": \"file-abc123\",\n  \"integrations\"\
            : [\n    {\n      \"type\": \"wandb\",\n      \"wandb\": {\n        \"\
            project\": \"my-wandb-project\",\n        \"entity\": None,\n        \"\
            run_id\": \"ftjob-abc123\"\n      }\n    }\n  ]\n}\n"
          title: W&B Integration
        group: fine-tuning
        name: Create fine-tuning job
        returns: A [fine-tuning.job](/docs/api-reference/fine-tuning/object) object.
  /fine_tuning/jobs/{fine_tuning_job_id}:
    get:
      operationId: retrieveFineTuningJob
      parameters:
      - description: 'The ID of the fine-tuning job.

          '
        in: path
        name: fine_tuning_job_id
        required: true
        schema:
          example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
          type: string
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FineTuningJob'
          description: OK
      summary: 'Get info about a fine-tuning job.


        [Learn more about fine-tuning](/docs/guides/fine-tuning)

        '
      tags:
      - Fine-tuning
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/fine_tuning/jobs/ft-AF1WoRqd3aJAHsqc9NY7iL8F\
              \ \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const fineTune = await openai.fineTuning.jobs.retrieve(\"\
              ftjob-abc123\");\n\n  console.log(fineTune);\n}\n\nmain();\n"
            python: 'from openai import OpenAI

              client = OpenAI()


              client.fine_tuning.jobs.retrieve("ftjob-abc123")

              '
          response: "{\n  \"object\": \"fine_tuning.job\",\n  \"id\": \"ftjob-abc123\"\
            ,\n  \"model\": \"davinci-002\",\n  \"created_at\": 1692661014,\n  \"\
            finished_at\": 1692661190,\n  \"fine_tuned_model\": \"ft:davinci-002:my-org:custom_suffix:7q8mpxmy\"\
            ,\n  \"organization_id\": \"org-123\",\n  \"result_files\": [\n      \"\
            file-abc123\"\n  ],\n  \"status\": \"succeeded\",\n  \"validation_file\"\
            : null,\n  \"training_file\": \"file-abc123\",\n  \"hyperparameters\"\
            : {\n      \"n_epochs\": 4,\n      \"batch_size\": 1,\n      \"learning_rate_multiplier\"\
            : 1.0\n  },\n  \"trained_tokens\": 5768,\n  \"integrations\": [],\n  \"\
            seed\": 0,\n  \"estimated_finish\": 0\n}\n"
        group: fine-tuning
        name: Retrieve fine-tuning job
        returns: The [fine-tuning](/docs/api-reference/fine-tuning/object) object
          with the given ID.
  /fine_tuning/jobs/{fine_tuning_job_id}/cancel:
    post:
      operationId: cancelFineTuningJob
      parameters:
      - description: 'The ID of the fine-tuning job to cancel.

          '
        in: path
        name: fine_tuning_job_id
        required: true
        schema:
          example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
          type: string
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FineTuningJob'
          description: OK
      summary: 'Immediately cancel a fine-tune job.

        '
      tags:
      - Fine-tuning
      x-oaiMeta:
        examples:
          request:
            curl: "curl -X POST https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/cancel\
              \ \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const fineTune = await openai.fineTuning.jobs.cancel(\"\
              ftjob-abc123\");\n\n  console.log(fineTune);\n}\nmain();"
            python: 'from openai import OpenAI

              client = OpenAI()


              client.fine_tuning.jobs.cancel("ftjob-abc123")

              '
          response: "{\n  \"object\": \"fine_tuning.job\",\n  \"id\": \"ftjob-abc123\"\
            ,\n  \"model\": \"gpt-3.5-turbo-0125\",\n  \"created_at\": 1689376978,\n\
            \  \"fine_tuned_model\": null,\n  \"organization_id\": \"org-123\",\n\
            \  \"result_files\": [],\n  \"hyperparameters\": {\n    \"n_epochs\":\
            \  \"auto\"\n  },\n  \"status\": \"cancelled\",\n  \"validation_file\"\
            : \"file-abc123\",\n  \"training_file\": \"file-abc123\"\n}\n"
        group: fine-tuning
        name: Cancel fine-tuning
        returns: The cancelled [fine-tuning](/docs/api-reference/fine-tuning/object)
          object.
  /fine_tuning/jobs/{fine_tuning_job_id}/checkpoints:
    get:
      operationId: listFineTuningJobCheckpoints
      parameters:
      - description: 'The ID of the fine-tuning job to get checkpoints for.

          '
        in: path
        name: fine_tuning_job_id
        required: true
        schema:
          example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
          type: string
      - description: Identifier for the last checkpoint ID from the previous pagination
          request.
        in: query
        name: after
        required: false
        schema:
          type: string
      - description: Number of checkpoints to retrieve.
        in: query
        name: limit
        required: false
        schema:
          default: 10
          type: integer
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListFineTuningJobCheckpointsResponse'
          description: OK
      summary: 'List checkpoints for a fine-tuning job.

        '
      tags:
      - Fine-tuning
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/checkpoints\
              \ \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
          response: "{\n  \"object\": \"list\"\n  \"data\": [\n    {\n      \"object\"\
            : \"fine_tuning.job.checkpoint\",\n      \"id\": \"ftckpt_zc4Q7MP6XxulcVzj4MZdwsAB\"\
            ,\n      \"created_at\": 1519129973,\n      \"fine_tuned_model_checkpoint\"\
            : \"ft:gpt-3.5-turbo-0125:my-org:custom-suffix:96olL566:ckpt-step-2000\"\
            ,\n      \"metrics\": {\n        \"full_valid_loss\": 0.134,\n       \
            \ \"full_valid_mean_token_accuracy\": 0.874\n      },\n      \"fine_tuning_job_id\"\
            : \"ftjob-abc123\",\n      \"step_number\": 2000,\n    },\n    {\n   \
            \   \"object\": \"fine_tuning.job.checkpoint\",\n      \"id\": \"ftckpt_enQCFmOTGj3syEpYVhBRLTSy\"\
            ,\n      \"created_at\": 1519129833,\n      \"fine_tuned_model_checkpoint\"\
            : \"ft:gpt-3.5-turbo-0125:my-org:custom-suffix:7q8mpxmy:ckpt-step-1000\"\
            ,\n      \"metrics\": {\n        \"full_valid_loss\": 0.167,\n       \
            \ \"full_valid_mean_token_accuracy\": 0.781\n      },\n      \"fine_tuning_job_id\"\
            : \"ftjob-abc123\",\n      \"step_number\": 1000,\n    },\n  ],\n  \"\
            first_id\": \"ftckpt_zc4Q7MP6XxulcVzj4MZdwsAB\",\n  \"last_id\": \"ftckpt_enQCFmOTGj3syEpYVhBRLTSy\"\
            ,\n  \"has_more\": true\n}\n"
        group: fine-tuning
        name: List fine-tuning checkpoints
        returns: A list of fine-tuning [checkpoint objects](/docs/api-reference/fine-tuning/checkpoint-object)
          for a fine-tuning job.
  /fine_tuning/jobs/{fine_tuning_job_id}/events:
    get:
      operationId: listFineTuningEvents
      parameters:
      - description: 'The ID of the fine-tuning job to get events for.

          '
        in: path
        name: fine_tuning_job_id
        required: true
        schema:
          example: ft-AF1WoRqd3aJAHsqc9NY7iL8F
          type: string
      - description: Identifier for the last event from the previous pagination request.
        in: query
        name: after
        required: false
        schema:
          type: string
      - description: Number of events to retrieve.
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListFineTuningJobEventsResponse'
          description: OK
      summary: 'Get status updates for a fine-tuning job.

        '
      tags:
      - Fine-tuning
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/events\
              \ \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const list = await openai.fineTuning.list_events(id=\"\
              ftjob-abc123\", limit=2);\n\n  for await (const fineTune of list) {\n\
              \    console.log(fineTune);\n  }\n}\n\nmain();"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nclient.fine_tuning.jobs.list_events(\n\
              \  fine_tuning_job_id=\"ftjob-abc123\",\n  limit=2\n)\n"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\"\
            : \"fine_tuning.job.event\",\n      \"id\": \"ft-event-ddTJfwuMVpfLXseO0Am0Gqjm\"\
            ,\n      \"created_at\": 1692407401,\n      \"level\": \"info\",\n   \
            \   \"message\": \"Fine tuning job successfully completed\",\n      \"\
            data\": null,\n      \"type\": \"message\"\n    },\n    {\n      \"object\"\
            : \"fine_tuning.job.event\",\n      \"id\": \"ft-event-tyiGuB72evQncpH87xe505Sv\"\
            ,\n      \"created_at\": 1692407400,\n      \"level\": \"info\",\n   \
            \   \"message\": \"New fine-tuned model created: ft:gpt-3.5-turbo:openai::7p4lURel\"\
            ,\n      \"data\": null,\n      \"type\": \"message\"\n    }\n  ],\n \
            \ \"has_more\": true\n}\n"
        group: fine-tuning
        name: List fine-tuning events
        returns: A list of fine-tuning event objects.
  /images/edits:
    post:
      operationId: createImageEdit
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateImageEditRequest'
        required: true
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ImagesResponse'
          description: OK
      summary: Creates an edited or extended image given an original image and a prompt.
      tags:
      - Images
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/images/edits \\\n  -H \"Authorization:\
              \ Bearer $OPENAI_API_KEY\" \\\n  -F image=\"@otter.png\" \\\n  -F mask=\"\
              @mask.png\" \\\n  -F prompt=\"A cute baby sea otter wearing a beret\"\
              \ \\\n  -F n=2 \\\n  -F size=\"1024x1024\"\n"
            node.js: "import fs from \"fs\";\nimport OpenAI from \"openai\";\n\nconst\
              \ openai = new OpenAI();\n\nasync function main() {\n  const image =\
              \ await openai.images.edit({\n    image: fs.createReadStream(\"otter.png\"\
              ),\n    mask: fs.createReadStream(\"mask.png\"),\n    prompt: \"A cute\
              \ baby sea otter wearing a beret\",\n  });\n\n  console.log(image.data);\n\
              }\nmain();"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nclient.images.edit(\n\
              \  image=open(\"otter.png\", \"rb\"),\n  mask=open(\"mask.png\", \"\
              rb\"),\n  prompt=\"A cute baby sea otter wearing a beret\",\n  n=2,\n\
              \  size=\"1024x1024\"\n)\n"
          response: "{\n  \"created\": 1589478378,\n  \"data\": [\n    {\n      \"\
            url\": \"https://...\"\n    },\n    {\n      \"url\": \"https://...\"\n\
            \    }\n  ]\n}\n"
        group: images
        name: Create image edit
        returns: Returns a list of [image](/docs/api-reference/images/object) objects.
  /images/generations:
    post:
      operationId: createImage
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateImageRequest'
        required: true
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ImagesResponse'
          description: OK
      summary: Creates an image given a prompt.
      tags:
      - Images
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/images/generations \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\
              \ \\\n  -d '{\n    \"model\": \"dall-e-3\",\n    \"prompt\": \"A cute\
              \ baby sea otter\",\n    \"n\": 1,\n    \"size\": \"1024x1024\"\n  }'\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const image = await openai.images.generate({\
              \ model: \"dall-e-3\", prompt: \"A cute baby sea otter\" });\n\n  console.log(image.data);\n\
              }\nmain();"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nclient.images.generate(\n\
              \  model=\"dall-e-3\",\n  prompt=\"A cute baby sea otter\",\n  n=1,\n\
              \  size=\"1024x1024\"\n)\n"
          response: "{\n  \"created\": 1589478378,\n  \"data\": [\n    {\n      \"\
            url\": \"https://...\"\n    },\n    {\n      \"url\": \"https://...\"\n\
            \    }\n  ]\n}\n"
        group: images
        name: Create image
        returns: Returns a list of [image](/docs/api-reference/images/object) objects.
  /images/variations:
    post:
      operationId: createImageVariation
      requestBody:
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/CreateImageVariationRequest'
        required: true
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ImagesResponse'
          description: OK
      summary: Creates a variation of a given image.
      tags:
      - Images
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/images/variations \\\n  -H \"Authorization:\
              \ Bearer $OPENAI_API_KEY\" \\\n  -F image=\"@otter.png\" \\\n  -F n=2\
              \ \\\n  -F size=\"1024x1024\"\n"
            node.js: "import fs from \"fs\";\nimport OpenAI from \"openai\";\n\nconst\
              \ openai = new OpenAI();\n\nasync function main() {\n  const image =\
              \ await openai.images.createVariation({\n    image: fs.createReadStream(\"\
              otter.png\"),\n  });\n\n  console.log(image.data);\n}\nmain();"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nresponse = client.images.create_variation(\n\
              \  image=open(\"image_edit_original.png\", \"rb\"),\n  n=2,\n  size=\"\
              1024x1024\"\n)\n"
          response: "{\n  \"created\": 1589478378,\n  \"data\": [\n    {\n      \"\
            url\": \"https://...\"\n    },\n    {\n      \"url\": \"https://...\"\n\
            \    }\n  ]\n}\n"
        group: images
        name: Create image variation
        returns: Returns a list of [image](/docs/api-reference/images/object) objects.
  /models:
    get:
      operationId: listModels
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListModelsResponse'
          description: OK
      summary: Lists the currently available models, and provides basic information
        about each one such as the owner and availability.
      tags:
      - Models
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/models \\\n  -H \"Authorization:\
              \ Bearer $OPENAI_API_KEY\"\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const list = await openai.models.list();\n\
              \n  for await (const model of list) {\n    console.log(model);\n  }\n\
              }\nmain();"
            python: 'from openai import OpenAI

              client = OpenAI()


              client.models.list()

              '
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\"\
            : \"model-id-0\",\n      \"object\": \"model\",\n      \"created\": 1686935002,\n\
            \      \"owned_by\": \"organization-owner\"\n    },\n    {\n      \"id\"\
            : \"model-id-1\",\n      \"object\": \"model\",\n      \"created\": 1686935002,\n\
            \      \"owned_by\": \"organization-owner\",\n    },\n    {\n      \"\
            id\": \"model-id-2\",\n      \"object\": \"model\",\n      \"created\"\
            : 1686935002,\n      \"owned_by\": \"openai\"\n    },\n  ],\n  \"object\"\
            : \"list\"\n}\n"
        group: models
        name: List models
        returns: A list of [model](/docs/api-reference/models/object) objects.
  /models/{model}:
    delete:
      operationId: deleteModel
      parameters:
      - description: The model to delete
        in: path
        name: model
        required: true
        schema:
          example: ft:gpt-3.5-turbo:acemeco:suffix:abc123
          type: string
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteModelResponse'
          description: OK
      summary: Delete a fine-tuned model. You must have the Owner role in your organization
        to delete a model.
      tags:
      - Models
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/models/ft:gpt-3.5-turbo:acemeco:suffix:abc123\
              \ \\\n  -X DELETE \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\
              \n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const model = await openai.models.del(\"\
              ft:gpt-3.5-turbo:acemeco:suffix:abc123\");\n\n  console.log(model);\n\
              }\nmain();"
            python: 'from openai import OpenAI

              client = OpenAI()


              client.models.delete("ft:gpt-3.5-turbo:acemeco:suffix:abc123")

              '
          response: "{\n  \"id\": \"ft:gpt-3.5-turbo:acemeco:suffix:abc123\",\n  \"\
            object\": \"model\",\n  \"deleted\": true\n}\n"
        group: models
        name: Delete a fine-tuned model
        returns: Deletion status.
    get:
      operationId: retrieveModel
      parameters:
      - description: The ID of the model to use for this request
        in: path
        name: model
        required: true
        schema:
          example: gpt-3.5-turbo
          type: string
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Model'
          description: OK
      summary: Retrieves a model instance, providing basic information about the model
        such as the owner and permissioning.
      tags:
      - Models
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/models/VAR_model_id \\\n  -H \"\
              Authorization: Bearer $OPENAI_API_KEY\"\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const model = await openai.models.retrieve(\"\
              VAR_model_id\");\n\n  console.log(model);\n}\n\nmain();"
            python: 'from openai import OpenAI

              client = OpenAI()


              client.models.retrieve("VAR_model_id")

              '
          response: "{\n  \"id\": \"VAR_model_id\",\n  \"object\": \"model\",\n  \"\
            created\": 1686935002,\n  \"owned_by\": \"openai\"\n}\n"
        group: models
        name: Retrieve model
        returns: The [model](/docs/api-reference/models/object) object matching the
          specified ID.
  /moderations:
    post:
      operationId: createModeration
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateModerationRequest'
        required: true
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateModerationResponse'
          description: OK
      summary: Classifies if text is potentially harmful.
      tags:
      - Moderations
      x-oaiMeta:
        examples:
          request:
            curl: "curl https://api.openai.com/v1/moderations \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\
              \ \\\n  -d '{\n    \"input\": \"I want to kill them.\"\n  }'\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const moderation = await openai.moderations.create({\
              \ input: \"I want to kill them.\" });\n\n  console.log(moderation);\n\
              }\nmain();\n"
            python: 'from openai import OpenAI

              client = OpenAI()


              moderation = client.moderations.create(input="I want to kill them.")

              print(moderation)

              '
          response: "{\n  \"id\": \"modr-XXXXX\",\n  \"model\": \"text-moderation-005\"\
            ,\n  \"results\": [\n    {\n      \"flagged\": true,\n      \"categories\"\
            : {\n        \"sexual\": false,\n        \"hate\": false,\n        \"\
            harassment\": false,\n        \"self-harm\": false,\n        \"sexual/minors\"\
            : false,\n        \"hate/threatening\": false,\n        \"violence/graphic\"\
            : false,\n        \"self-harm/intent\": false,\n        \"self-harm/instructions\"\
            : false,\n        \"harassment/threatening\": true,\n        \"violence\"\
            : true,\n      },\n      \"category_scores\": {\n        \"sexual\": 1.2282071e-06,\n\
            \        \"hate\": 0.010696256,\n        \"harassment\": 0.29842457,\n\
            \        \"self-harm\": 1.5236925e-08,\n        \"sexual/minors\": 5.7246268e-08,\n\
            \        \"hate/threatening\": 0.0060676364,\n        \"violence/graphic\"\
            : 4.435014e-06,\n        \"self-harm/intent\": 8.098441e-10,\n       \
            \ \"self-harm/instructions\": 2.8498655e-11,\n        \"harassment/threatening\"\
            : 0.63055265,\n        \"violence\": 0.99011886,\n      }\n    }\n  ]\n\
            }\n"
        group: moderations
        name: Create moderation
        returns: A [moderation](/docs/api-reference/moderations/object) object.
  /threads:
    post:
      operationId: createThread
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateThreadRequest'
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ThreadObject'
          description: OK
      summary: Create a thread.
      tags:
      - Assistants
      x-oaiMeta:
        beta: true
        examples:
        - request:
            curl: "curl https://api.openai.com/v1/threads \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\
              \ \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -d ''\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const emptyThread = await openai.beta.threads.create();\n\
              \n  console.log(emptyThread);\n}\n\nmain();"
            python: 'from openai import OpenAI

              client = OpenAI()


              empty_thread = client.beta.threads.create()

              print(empty_thread)

              '
          response: "{\n  \"id\": \"thread_abc123\",\n  \"object\": \"thread\",\n\
            \  \"created_at\": 1699012949,\n  \"metadata\": {},\n  \"tool_resources\"\
            : {}\n}\n"
          title: Empty
        - request:
            curl: "curl https://api.openai.com/v1/threads \\\n-H \"Content-Type: application/json\"\
              \ \\\n-H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n-H \"OpenAI-Beta:\
              \ assistants=v2\" \\\n-d '{\n    \"messages\": [{\n      \"role\": \"\
              user\",\n      \"content\": \"Hello, what is AI?\"\n    }, {\n     \
              \ \"role\": \"user\",\n      \"content\": \"How does AI work? Explain\
              \ it in simple terms.\"\n    }]\n  }'\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const messageThread = await openai.beta.threads.create({\n\
              \    messages: [\n      {\n        role: \"user\",\n        content:\
              \ \"Hello, what is AI?\"\n      },\n      {\n        role: \"user\"\
              ,\n        content: \"How does AI work? Explain it in simple terms.\"\
              ,\n      },\n    ],\n  });\n\n  console.log(messageThread);\n}\n\nmain();"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nmessage_thread\
              \ = client.beta.threads.create(\n  messages=[\n    {\n      \"role\"\
              : \"user\",\n      \"content\": \"Hello, what is AI?\"\n    },\n   \
              \ {\n      \"role\": \"user\",\n      \"content\": \"How does AI work?\
              \ Explain it in simple terms.\"\n    },\n  ]\n)\n\nprint(message_thread)\n"
          response: "{\n  \"id\": \"thread_abc123\",\n  \"object\": \"thread\",\n\
            \  \"created_at\": 1699014083,\n  \"metadata\": {},\n  \"tool_resources\"\
            : {}\n}\n"
          title: Messages
        group: threads
        name: Create thread
        returns: A [thread](/docs/api-reference/threads) object.
  /threads/runs:
    post:
      operationId: createThreadAndRun
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateThreadAndRunRequest'
        required: true
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
          description: OK
      summary: Create a thread and run it in one request.
      tags:
      - Assistants
      x-oaiMeta:
        beta: true
        examples:
        - request:
            curl: "curl https://api.openai.com/v1/threads/runs \\\n  -H \"Authorization:\
              \ Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\"\
              \ \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -d '{\n      \"assistant_id\"\
              : \"asst_abc123\",\n      \"thread\": {\n        \"messages\": [\n \
              \         {\"role\": \"user\", \"content\": \"Explain deep learning\
              \ to a 5 year old.\"}\n        ]\n      }\n    }'\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const run = await openai.beta.threads.createAndRun({\n\
              \    assistant_id: \"asst_abc123\",\n    thread: {\n      messages:\
              \ [\n        { role: \"user\", content: \"Explain deep learning to a\
              \ 5 year old.\" },\n      ],\n    },\n  });\n\n  console.log(run);\n\
              }\n\nmain();\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nrun = client.beta.threads.create_and_run(\n\
              \  assistant_id=\"asst_abc123\",\n  thread={\n    \"messages\": [\n\
              \      {\"role\": \"user\", \"content\": \"Explain deep learning to\
              \ a 5 year old.\"}\n    ]\n  }\n)\n\nprint(run)\n"
          response: "{\n  \"id\": \"run_abc123\",\n  \"object\": \"thread.run\",\n\
            \  \"created_at\": 1699076792,\n  \"assistant_id\": \"asst_abc123\",\n\
            \  \"thread_id\": \"thread_abc123\",\n  \"status\": \"queued\",\n  \"\
            started_at\": null,\n  \"expires_at\": 1699077392,\n  \"cancelled_at\"\
            : null,\n  \"failed_at\": null,\n  \"completed_at\": null,\n  \"required_action\"\
            : null,\n  \"last_error\": null,\n  \"model\": \"gpt-4-turbo\",\n  \"\
            instructions\": \"You are a helpful assistant.\",\n  \"tools\": [],\n\
            \  \"tool_resources\": {},\n  \"metadata\": {},\n  \"temperature\": 1.0,\n\
            \  \"top_p\": 1.0,\n  \"max_completion_tokens\": null,\n  \"max_prompt_tokens\"\
            : null,\n  \"truncation_strategy\": {\n    \"type\": \"auto\",\n    \"\
            last_messages\": null\n  },\n  \"incomplete_details\": null,\n  \"usage\"\
            : null,\n  \"response_format\": \"auto\",\n  \"tool_choice\": \"auto\"\
            ,\n  \"parallel_tool_calls\": true\n}\n"
          title: Default
        - request:
            curl: "curl https://api.openai.com/v1/threads/runs \\\n  -H \"Authorization:\
              \ Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\"\
              \ \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -d '{\n    \"assistant_id\"\
              : \"asst_123\",\n    \"thread\": {\n      \"messages\": [\n        {\"\
              role\": \"user\", \"content\": \"Hello\"}\n      ]\n    },\n    \"stream\"\
              : true\n  }'\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const stream = await openai.beta.threads.createAndRun({\n\
              \      assistant_id: \"asst_123\",\n      thread: {\n        messages:\
              \ [\n          { role: \"user\", content: \"Hello\" },\n        ],\n\
              \      },\n      stream: true\n  });\n\n  for await (const event of\
              \ stream) {\n    console.log(event);\n  }\n}\n\nmain();\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nstream = client.beta.threads.create_and_run(\n\
              \  assistant_id=\"asst_123\",\n  thread={\n    \"messages\": [\n   \
              \   {\"role\": \"user\", \"content\": \"Hello\"}\n    ]\n  },\n  stream=True\n\
              )\n\nfor event in stream:\n  print(event)\n"
          response: 'event: thread.created

            data: {"id":"thread_123","object":"thread","created_at":1710348075,"metadata":{}}


            event: thread.run.created

            data: {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[],"tool_resources":{},"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}


            event: thread.run.queued

            data: {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[],"tool_resources":{},"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}


            event: thread.run.in_progress

            data: {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"in_progress","started_at":null,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[],"tool_resources":{},"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}


            event: thread.run.step.created

            data: {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}


            event: thread.run.step.in_progress

            data: {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}


            event: thread.message.created

            data: {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],
            "metadata":{}}


            event: thread.message.in_progress

            data: {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],
            "metadata":{}}


            event: thread.message.delta

            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"Hello","annotations":[]}}]}}


            ...


            event: thread.message.delta

            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"
            today"}}]}}


            event: thread.message.delta

            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"?"}}]}}


            event: thread.message.completed

            data: {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"completed","incomplete_details":null,"incomplete_at":null,"completed_at":1710348077,"role":"assistant","content":[{"type":"text","text":{"value":"Hello!
            How can I assist you today?","annotations":[]}}], "metadata":{}}


            event: thread.run.step.completed

            data: {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"completed","cancelled_at":null,"completed_at":1710348077,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31}}


            event: thread.run.completed

            {"id":"run_123","object":"thread.run","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","status":"completed","started_at":1713226836,"expires_at":null,"cancelled_at":null,"failed_at":null,"completed_at":1713226837,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":{"prompt_tokens":345,"completion_tokens":11,"total_tokens":356},"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}


            event: done

            data: [DONE]

            '
          title: Streaming
        - request:
            curl: "curl https://api.openai.com/v1/threads/runs \\\n  -H \"Authorization:\
              \ Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\"\
              \ \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -d '{\n    \"assistant_id\"\
              : \"asst_abc123\",\n    \"thread\": {\n      \"messages\": [\n     \
              \   {\"role\": \"user\", \"content\": \"What is the weather like in\
              \ San Francisco?\"}\n      ]\n    },\n    \"tools\": [\n      {\n  \
              \      \"type\": \"function\",\n        \"function\": {\n          \"\
              name\": \"get_current_weather\",\n          \"description\": \"Get the\
              \ current weather in a given location\",\n          \"parameters\":\
              \ {\n            \"type\": \"object\",\n            \"properties\":\
              \ {\n              \"location\": {\n                \"type\": \"string\"\
              ,\n                \"description\": \"The city and state, e.g. San Francisco,\
              \ CA\"\n              },\n              \"unit\": {\n              \
              \  \"type\": \"string\",\n                \"enum\": [\"celsius\", \"\
              fahrenheit\"]\n              }\n            },\n            \"required\"\
              : [\"location\"]\n          }\n        }\n      }\n    ],\n    \"stream\"\
              : true\n  }'\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nconst tools = [\n    {\n      \"type\": \"function\",\n      \"function\"\
              : {\n        \"name\": \"get_current_weather\",\n        \"description\"\
              : \"Get the current weather in a given location\",\n        \"parameters\"\
              : {\n          \"type\": \"object\",\n          \"properties\": {\n\
              \            \"location\": {\n              \"type\": \"string\",\n\
              \              \"description\": \"The city and state, e.g. San Francisco,\
              \ CA\",\n            },\n            \"unit\": {\"type\": \"string\"\
              , \"enum\": [\"celsius\", \"fahrenheit\"]},\n          },\n        \
              \  \"required\": [\"location\"],\n        },\n      }\n    }\n];\n\n\
              async function main() {\n  const stream = await openai.beta.threads.createAndRun({\n\
              \    assistant_id: \"asst_123\",\n    thread: {\n      messages: [\n\
              \        { role: \"user\", content: \"What is the weather like in San\
              \ Francisco?\" },\n      ],\n    },\n    tools: tools,\n    stream:\
              \ true\n  });\n\n  for await (const event of stream) {\n    console.log(event);\n\
              \  }\n}\n\nmain();\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\ntools = [\n \
              \ {\n    \"type\": \"function\",\n    \"function\": {\n      \"name\"\
              : \"get_current_weather\",\n      \"description\": \"Get the current\
              \ weather in a given location\",\n      \"parameters\": {\n        \"\
              type\": \"object\",\n        \"properties\": {\n          \"location\"\
              : {\n            \"type\": \"string\",\n            \"description\"\
              : \"The city and state, e.g. San Francisco, CA\",\n          },\n  \
              \        \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"\
              fahrenheit\"]},\n        },\n        \"required\": [\"location\"],\n\
              \      },\n    }\n  }\n]\n\nstream = client.beta.threads.create_and_run(\n\
              \  thread={\n      \"messages\": [\n        {\"role\": \"user\", \"\
              content\": \"What is the weather like in San Francisco?\"}\n      ]\n\
              \  },\n  assistant_id=\"asst_abc123\",\n  tools=tools,\n  stream=True\n\
              )\n\nfor event in stream:\n  print(event)\n"
          response: 'event: thread.created

            data: {"id":"thread_123","object":"thread","created_at":1710351818,"metadata":{}}


            event: thread.run.created

            data: {"id":"run_123","object":"thread.run","created_at":1710351818,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710352418,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get
            the current weather in a given location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The
            city and state, e.g. San Francisco, CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}


            event: thread.run.queued

            data: {"id":"run_123","object":"thread.run","created_at":1710351818,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710352418,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get
            the current weather in a given location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The
            city and state, e.g. San Francisco, CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}


            event: thread.run.in_progress

            data: {"id":"run_123","object":"thread.run","created_at":1710351818,"assistant_id":"asst_123","thread_id":"thread_123","status":"in_progress","started_at":1710351818,"expires_at":1710352418,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get
            the current weather in a given location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The
            city and state, e.g. San Francisco, CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}


            event: thread.run.step.created

            data: {"id":"step_001","object":"thread.run.step","created_at":1710351819,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"tool_calls","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710352418,"failed_at":null,"last_error":null,"step_details":{"type":"tool_calls","tool_calls":[]},"usage":null}


            event: thread.run.step.in_progress

            data: {"id":"step_001","object":"thread.run.step","created_at":1710351819,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"tool_calls","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710352418,"failed_at":null,"last_error":null,"step_details":{"type":"tool_calls","tool_calls":[]},"usage":null}


            event: thread.run.step.delta

            data: {"id":"step_001","object":"thread.run.step.delta","delta":{"step_details":{"type":"tool_calls","tool_calls":[{"index":0,"id":"call_XXNp8YGaFrjrSjgqxtC8JJ1B","type":"function","function":{"name":"get_current_weather","arguments":"","output":null}}]}}}


            event: thread.run.step.delta

            data: {"id":"step_001","object":"thread.run.step.delta","delta":{"step_details":{"type":"tool_calls","tool_calls":[{"index":0,"type":"function","function":{"arguments":"{\""}}]}}}


            event: thread.run.step.delta

            data: {"id":"step_001","object":"thread.run.step.delta","delta":{"step_details":{"type":"tool_calls","tool_calls":[{"index":0,"type":"function","function":{"arguments":"location"}}]}}}


            ...


            event: thread.run.step.delta

            data: {"id":"step_001","object":"thread.run.step.delta","delta":{"step_details":{"type":"tool_calls","tool_calls":[{"index":0,"type":"function","function":{"arguments":"ahrenheit"}}]}}}


            event: thread.run.step.delta

            data: {"id":"step_001","object":"thread.run.step.delta","delta":{"step_details":{"type":"tool_calls","tool_calls":[{"index":0,"type":"function","function":{"arguments":"\"}"}}]}}}


            event: thread.run.requires_action

            data: {"id":"run_123","object":"thread.run","created_at":1710351818,"assistant_id":"asst_123","thread_id":"thread_123","status":"requires_action","started_at":1710351818,"expires_at":1710352418,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":{"type":"submit_tool_outputs","submit_tool_outputs":{"tool_calls":[{"id":"call_XXNp8YGaFrjrSjgqxtC8JJ1B","type":"function","function":{"name":"get_current_weather","arguments":"{\"location\":\"San
            Francisco, CA\",\"unit\":\"fahrenheit\"}"}}]}},"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get
            the current weather in a given location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The
            city and state, e.g. San Francisco, CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":{"prompt_tokens":345,"completion_tokens":11,"total_tokens":356},"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}


            event: done

            data: [DONE]

            '
          title: Streaming with Functions
        group: threads
        name: Create thread and run
        returns: A [run](/docs/api-reference/runs/object) object.
  /threads/{thread_id}:
    delete:
      operationId: deleteThread
      parameters:
      - description: The ID of the thread to delete.
        in: path
        name: thread_id
        required: true
        schema:
          type: string
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteThreadResponse'
          description: OK
      summary: Delete a thread.
      tags:
      - Assistants
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123 \\\n  -H \"\
              Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\
              \ \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -X DELETE\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const response = await openai.beta.threads.del(\"\
              thread_abc123\");\n\n  console.log(response);\n}\nmain();"
            python: 'from openai import OpenAI

              client = OpenAI()


              response = client.beta.threads.delete("thread_abc123")

              print(response)

              '
          response: "{\n  \"id\": \"thread_abc123\",\n  \"object\": \"thread.deleted\"\
            ,\n  \"deleted\": true\n}\n"
        group: threads
        name: Delete thread
        returns: Deletion status
    get:
      operationId: getThread
      parameters:
      - description: The ID of the thread to retrieve.
        in: path
        name: thread_id
        required: true
        schema:
          type: string
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ThreadObject'
          description: OK
      summary: Retrieves a thread.
      tags:
      - Assistants
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123 \\\n  -H \"\
              Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\
              \ \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const myThread = await openai.beta.threads.retrieve(\n\
              \    \"thread_abc123\"\n  );\n\n  console.log(myThread);\n}\n\nmain();"
            python: 'from openai import OpenAI

              client = OpenAI()


              my_thread = client.beta.threads.retrieve("thread_abc123")

              print(my_thread)

              '
          response: "{\n  \"id\": \"thread_abc123\",\n  \"object\": \"thread\",\n\
            \  \"created_at\": 1699014083,\n  \"metadata\": {},\n  \"tool_resources\"\
            : {\n    \"code_interpreter\": {\n      \"file_ids\": []\n    }\n  }\n\
            }\n"
        group: threads
        name: Retrieve thread
        returns: The [thread](/docs/api-reference/threads/object) object matching
          the specified ID.
    post:
      operationId: modifyThread
      parameters:
      - description: The ID of the thread to modify. Only the `metadata` can be modified.
        in: path
        name: thread_id
        required: true
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ModifyThreadRequest'
        required: true
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ThreadObject'
          description: OK
      summary: Modifies a thread.
      tags:
      - Assistants
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123 \\\n  -H \"\
              Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\
              \ \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -d '{\n      \"metadata\"\
              : {\n        \"modified\": \"true\",\n        \"user\": \"abc123\"\n\
              \      }\n    }'\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const updatedThread = await openai.beta.threads.update(\n\
              \    \"thread_abc123\",\n    {\n      metadata: { modified: \"true\"\
              , user: \"abc123\" },\n    }\n  );\n\n  console.log(updatedThread);\n\
              }\n\nmain();"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nmy_updated_thread\
              \ = client.beta.threads.update(\n  \"thread_abc123\",\n  metadata={\n\
              \    \"modified\": \"true\",\n    \"user\": \"abc123\"\n  }\n)\nprint(my_updated_thread)\n"
          response: "{\n  \"id\": \"thread_abc123\",\n  \"object\": \"thread\",\n\
            \  \"created_at\": 1699014083,\n  \"metadata\": {\n    \"modified\": \"\
            true\",\n    \"user\": \"abc123\"\n  },\n  \"tool_resources\": {}\n}\n"
        group: threads
        name: Modify thread
        returns: The modified [thread](/docs/api-reference/threads/object) object
          matching the specified ID.
  /threads/{thread_id}/messages:
    get:
      operationId: listMessages
      parameters:
      - description: The ID of the [thread](/docs/api-reference/threads) the messages
          belong to.
        in: path
        name: thread_id
        required: true
        schema:
          type: string
      - description: 'A limit on the number of objects to be returned. Limit can range
          between 1 and 100, and the default is 20.

          '
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
      - description: 'Sort order by the `created_at` timestamp of the objects. `asc`
          for ascending order and `desc` for descending order.

          '
        in: query
        name: order
        schema:
          default: desc
          enum:
          - asc
          - desc
          type: string
      - description: 'A cursor for use in pagination. `after` is an object ID that
          defines your place in the list. For instance, if you make a list request
          and receive 100 objects, ending with obj_foo, your subsequent call can include
          after=obj_foo in order to fetch the next page of the list.

          '
        in: query
        name: after
        schema:
          type: string
      - description: 'A cursor for use in pagination. `before` is an object ID that
          defines your place in the list. For instance, if you make a list request
          and receive 100 objects, ending with obj_foo, your subsequent call can include
          before=obj_foo in order to fetch the previous page of the list.

          '
        in: query
        name: before
        schema:
          type: string
      - description: 'Filter messages by the run ID that generated them.

          '
        in: query
        name: run_id
        schema:
          type: string
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListMessagesResponse'
          description: OK
      summary: Returns a list of messages for a given thread.
      tags:
      - Assistants
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123/messages \\\
              \n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization:\
              \ Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const threadMessages = await openai.beta.threads.messages.list(\n\
              \    \"thread_abc123\"\n  );\n\n  console.log(threadMessages.data);\n\
              }\n\nmain();"
            python: 'from openai import OpenAI

              client = OpenAI()


              thread_messages = client.beta.threads.messages.list("thread_abc123")

              print(thread_messages.data)

              '
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\"\
            : \"msg_abc123\",\n      \"object\": \"thread.message\",\n      \"created_at\"\
            : 1699016383,\n      \"assistant_id\": null,\n      \"thread_id\": \"\
            thread_abc123\",\n      \"run_id\": null,\n      \"role\": \"user\",\n\
            \      \"content\": [\n        {\n          \"type\": \"text\",\n    \
            \      \"text\": {\n            \"value\": \"How does AI work? Explain\
            \ it in simple terms.\",\n            \"annotations\": []\n          }\n\
            \        }\n      ],\n      \"attachments\": [],\n      \"metadata\":\
            \ {}\n    },\n    {\n      \"id\": \"msg_abc456\",\n      \"object\":\
            \ \"thread.message\",\n      \"created_at\": 1699016383,\n      \"assistant_id\"\
            : null,\n      \"thread_id\": \"thread_abc123\",\n      \"run_id\": null,\n\
            \      \"role\": \"user\",\n      \"content\": [\n        {\n        \
            \  \"type\": \"text\",\n          \"text\": {\n            \"value\":\
            \ \"Hello, what is AI?\",\n            \"annotations\": []\n         \
            \ }\n        }\n      ],\n      \"attachments\": [],\n      \"metadata\"\
            : {}\n    }\n  ],\n  \"first_id\": \"msg_abc123\",\n  \"last_id\": \"\
            msg_abc456\",\n  \"has_more\": false\n}\n"
        group: threads
        name: List messages
        returns: A list of [message](/docs/api-reference/messages) objects.
    post:
      operationId: createMessage
      parameters:
      - description: The ID of the [thread](/docs/api-reference/threads) to create
          a message for.
        in: path
        name: thread_id
        required: true
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateMessageRequest'
        required: true
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/MessageObject'
          description: OK
      summary: Create a message.
      tags:
      - Assistants
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123/messages \\\
              \n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization:\
              \ Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\
              \n  -d '{\n      \"role\": \"user\",\n      \"content\": \"How does\
              \ AI work? Explain it in simple terms.\"\n    }'\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const threadMessages = await openai.beta.threads.messages.create(\n\
              \    \"thread_abc123\",\n    { role: \"user\", content: \"How does AI\
              \ work? Explain it in simple terms.\" }\n  );\n\n  console.log(threadMessages);\n\
              }\n\nmain();"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nthread_message\
              \ = client.beta.threads.messages.create(\n  \"thread_abc123\",\n  role=\"\
              user\",\n  content=\"How does AI work? Explain it in simple terms.\"\
              ,\n)\nprint(thread_message)\n"
          response: "{\n  \"id\": \"msg_abc123\",\n  \"object\": \"thread.message\"\
            ,\n  \"created_at\": 1713226573,\n  \"assistant_id\": null,\n  \"thread_id\"\
            : \"thread_abc123\",\n  \"run_id\": null,\n  \"role\": \"user\",\n  \"\
            content\": [\n    {\n      \"type\": \"text\",\n      \"text\": {\n  \
            \      \"value\": \"How does AI work? Explain it in simple terms.\",\n\
            \        \"annotations\": []\n      }\n    }\n  ],\n  \"attachments\"\
            : [],\n  \"metadata\": {}\n}\n"
        group: threads
        name: Create message
        returns: A [message](/docs/api-reference/messages/object) object.
  /threads/{thread_id}/messages/{message_id}:
    delete:
      operationId: deleteMessage
      parameters:
      - description: The ID of the thread to which this message belongs.
        in: path
        name: thread_id
        required: true
        schema:
          type: string
      - description: The ID of the message to delete.
        in: path
        name: message_id
        required: true
        schema:
          type: string
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteMessageResponse'
          description: OK
      summary: Deletes a message.
      tags:
      - Assistants
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl -X DELETE https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123\
              \ \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization:\
              \ Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const deletedMessage = await openai.beta.threads.messages.del(\n\
              \    \"thread_abc123\",\n    \"msg_abc123\"\n  );\n\n  console.log(deletedMessage);\n\
              }"
            python: "from openai import OpenAI\nclient = OpenAI()\n\ndeleted_message\
              \ = client.beta.threads.messages.delete(\n  message_id=\"msg_abc12\"\
              ,\n  thread_id=\"thread_abc123\",\n)\nprint(deleted_message)\n"
          response: "{\n  \"id\": \"msg_abc123\",\n  \"object\": \"thread.message.deleted\"\
            ,\n  \"deleted\": true\n}\n"
        group: threads
        name: Delete message
        returns: Deletion status
    get:
      operationId: getMessage
      parameters:
      - description: The ID of the [thread](/docs/api-reference/threads) to which
          this message belongs.
        in: path
        name: thread_id
        required: true
        schema:
          type: string
      - description: The ID of the message to retrieve.
        in: path
        name: message_id
        required: true
        schema:
          type: string
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/MessageObject'
          description: OK
      summary: Retrieve a message.
      tags:
      - Assistants
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123\
              \ \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization:\
              \ Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const message = await openai.beta.threads.messages.retrieve(\n\
              \    \"thread_abc123\",\n    \"msg_abc123\"\n  );\n\n  console.log(message);\n\
              }\n\nmain();"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nmessage = client.beta.threads.messages.retrieve(\n\
              \  message_id=\"msg_abc123\",\n  thread_id=\"thread_abc123\",\n)\nprint(message)\n"
          response: "{\n  \"id\": \"msg_abc123\",\n  \"object\": \"thread.message\"\
            ,\n  \"created_at\": 1699017614,\n  \"assistant_id\": null,\n  \"thread_id\"\
            : \"thread_abc123\",\n  \"run_id\": null,\n  \"role\": \"user\",\n  \"\
            content\": [\n    {\n      \"type\": \"text\",\n      \"text\": {\n  \
            \      \"value\": \"How does AI work? Explain it in simple terms.\",\n\
            \        \"annotations\": []\n      }\n    }\n  ],\n  \"attachments\"\
            : [],\n  \"metadata\": {}\n}\n"
        group: threads
        name: Retrieve message
        returns: The [message](/docs/api-reference/threads/messages/object) object
          matching the specified ID.
    post:
      operationId: modifyMessage
      parameters:
      - description: The ID of the thread to which this message belongs.
        in: path
        name: thread_id
        required: true
        schema:
          type: string
      - description: The ID of the message to modify.
        in: path
        name: message_id
        required: true
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ModifyMessageRequest'
        required: true
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/MessageObject'
          description: OK
      summary: Modifies a message.
      tags:
      - Assistants
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123\
              \ \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization:\
              \ Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\
              \n  -d '{\n      \"metadata\": {\n        \"modified\": \"true\",\n\
              \        \"user\": \"abc123\"\n      }\n    }'\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const message = await openai.beta.threads.messages.update(\n\
              \    \"thread_abc123\",\n    \"msg_abc123\",\n    {\n      metadata:\
              \ {\n        modified: \"true\",\n        user: \"abc123\",\n      },\n\
              \    }\n  }'"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nmessage = client.beta.threads.messages.update(\n\
              \  message_id=\"msg_abc12\",\n  thread_id=\"thread_abc123\",\n  metadata={\n\
              \    \"modified\": \"true\",\n    \"user\": \"abc123\",\n  },\n)\nprint(message)\n"
          response: "{\n  \"id\": \"msg_abc123\",\n  \"object\": \"thread.message\"\
            ,\n  \"created_at\": 1699017614,\n  \"assistant_id\": null,\n  \"thread_id\"\
            : \"thread_abc123\",\n  \"run_id\": null,\n  \"role\": \"user\",\n  \"\
            content\": [\n    {\n      \"type\": \"text\",\n      \"text\": {\n  \
            \      \"value\": \"How does AI work? Explain it in simple terms.\",\n\
            \        \"annotations\": []\n      }\n    }\n  ],\n  \"file_ids\": [],\n\
            \  \"metadata\": {\n    \"modified\": \"true\",\n    \"user\": \"abc123\"\
            \n  }\n}\n"
        group: threads
        name: Modify message
        returns: The modified [message](/docs/api-reference/threads/messages/object)
          object.
  /threads/{thread_id}/runs:
    get:
      operationId: listRuns
      parameters:
      - description: The ID of the thread the run belongs to.
        in: path
        name: thread_id
        required: true
        schema:
          type: string
      - description: 'A limit on the number of objects to be returned. Limit can range
          between 1 and 100, and the default is 20.

          '
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
      - description: 'Sort order by the `created_at` timestamp of the objects. `asc`
          for ascending order and `desc` for descending order.

          '
        in: query
        name: order
        schema:
          default: desc
          enum:
          - asc
          - desc
          type: string
      - description: 'A cursor for use in pagination. `after` is an object ID that
          defines your place in the list. For instance, if you make a list request
          and receive 100 objects, ending with obj_foo, your subsequent call can include
          after=obj_foo in order to fetch the next page of the list.

          '
        in: query
        name: after
        schema:
          type: string
      - description: 'A cursor for use in pagination. `before` is an object ID that
          defines your place in the list. For instance, if you make a list request
          and receive 100 objects, ending with obj_foo, your subsequent call can include
          before=obj_foo in order to fetch the previous page of the list.

          '
        in: query
        name: before
        schema:
          type: string
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListRunsResponse'
          description: OK
      summary: Returns a list of runs belonging to a thread.
      tags:
      - Assistants
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123/runs \\\n\
              \  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const runs = await openai.beta.threads.runs.list(\n\
              \    \"thread_abc123\"\n  );\n\n  console.log(runs);\n}\n\nmain();\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nruns = client.beta.threads.runs.list(\n\
              \  \"thread_abc123\"\n)\n\nprint(runs)\n"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\"\
            : \"run_abc123\",\n      \"object\": \"thread.run\",\n      \"created_at\"\
            : 1699075072,\n      \"assistant_id\": \"asst_abc123\",\n      \"thread_id\"\
            : \"thread_abc123\",\n      \"status\": \"completed\",\n      \"started_at\"\
            : 1699075072,\n      \"expires_at\": null,\n      \"cancelled_at\": null,\n\
            \      \"failed_at\": null,\n      \"completed_at\": 1699075073,\n   \
            \   \"last_error\": null,\n      \"model\": \"gpt-4-turbo\",\n      \"\
            instructions\": null,\n      \"incomplete_details\": null,\n      \"tools\"\
            : [\n        {\n          \"type\": \"code_interpreter\"\n        }\n\
            \      ],\n      \"tool_resources\": {\n        \"code_interpreter\":\
            \ {\n          \"file_ids\": [\n            \"file-abc123\",\n       \
            \     \"file-abc456\"\n          ]\n        }\n      },\n      \"metadata\"\
            : {},\n      \"usage\": {\n        \"prompt_tokens\": 123,\n        \"\
            completion_tokens\": 456,\n        \"total_tokens\": 579\n      },\n \
            \     \"temperature\": 1.0,\n      \"top_p\": 1.0,\n      \"max_prompt_tokens\"\
            : 1000,\n      \"max_completion_tokens\": 1000,\n      \"truncation_strategy\"\
            : {\n        \"type\": \"auto\",\n        \"last_messages\": null\n  \
            \    },\n      \"response_format\": \"auto\",\n      \"tool_choice\":\
            \ \"auto\",\n      \"parallel_tool_calls\": true\n    },\n    {\n    \
            \  \"id\": \"run_abc456\",\n      \"object\": \"thread.run\",\n      \"\
            created_at\": 1699063290,\n      \"assistant_id\": \"asst_abc123\",\n\
            \      \"thread_id\": \"thread_abc123\",\n      \"status\": \"completed\"\
            ,\n      \"started_at\": 1699063290,\n      \"expires_at\": null,\n  \
            \    \"cancelled_at\": null,\n      \"failed_at\": null,\n      \"completed_at\"\
            : 1699063291,\n      \"last_error\": null,\n      \"model\": \"gpt-4-turbo\"\
            ,\n      \"instructions\": null,\n      \"incomplete_details\": null,\n\
            \      \"tools\": [\n        {\n          \"type\": \"code_interpreter\"\
            \n        }\n      ],\n      \"tool_resources\": {\n        \"code_interpreter\"\
            : {\n          \"file_ids\": [\n            \"file-abc123\",\n       \
            \     \"file-abc456\"\n          ]\n        }\n      },\n      \"metadata\"\
            : {},\n      \"usage\": {\n        \"prompt_tokens\": 123,\n        \"\
            completion_tokens\": 456,\n        \"total_tokens\": 579\n      },\n \
            \     \"temperature\": 1.0,\n      \"top_p\": 1.0,\n      \"max_prompt_tokens\"\
            : 1000,\n      \"max_completion_tokens\": 1000,\n      \"truncation_strategy\"\
            : {\n        \"type\": \"auto\",\n        \"last_messages\": null\n  \
            \    },\n      \"response_format\": \"auto\",\n      \"tool_choice\":\
            \ \"auto\",\n      \"parallel_tool_calls\": true\n    }\n  ],\n  \"first_id\"\
            : \"run_abc123\",\n  \"last_id\": \"run_abc456\",\n  \"has_more\": false\n\
            }\n"
        group: threads
        name: List runs
        returns: A list of [run](/docs/api-reference/runs/object) objects.
    post:
      operationId: createRun
      parameters:
      - description: The ID of the thread to run.
        in: path
        name: thread_id
        required: true
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateRunRequest'
        required: true
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
          description: OK
      summary: Create a run.
      tags:
      - Assistants
      x-oaiMeta:
        beta: true
        examples:
        - request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123/runs \\\n\
              \  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -d\
              \ '{\n    \"assistant_id\": \"asst_abc123\"\n  }'\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const run = await openai.beta.threads.runs.create(\n\
              \    \"thread_abc123\",\n    { assistant_id: \"asst_abc123\" }\n  );\n\
              \n  console.log(run);\n}\n\nmain();\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nrun = client.beta.threads.runs.create(\n\
              \  thread_id=\"thread_abc123\",\n  assistant_id=\"asst_abc123\"\n)\n\
              \nprint(run)\n"
          response: "{\n  \"id\": \"run_abc123\",\n  \"object\": \"thread.run\",\n\
            \  \"created_at\": 1699063290,\n  \"assistant_id\": \"asst_abc123\",\n\
            \  \"thread_id\": \"thread_abc123\",\n  \"status\": \"queued\",\n  \"\
            started_at\": 1699063290,\n  \"expires_at\": null,\n  \"cancelled_at\"\
            : null,\n  \"failed_at\": null,\n  \"completed_at\": 1699063291,\n  \"\
            last_error\": null,\n  \"model\": \"gpt-4-turbo\",\n  \"instructions\"\
            : null,\n  \"incomplete_details\": null,\n  \"tools\": [\n    {\n    \
            \  \"type\": \"code_interpreter\"\n    }\n  ],\n  \"metadata\": {},\n\
            \  \"usage\": null,\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"\
            max_prompt_tokens\": 1000,\n  \"max_completion_tokens\": 1000,\n  \"truncation_strategy\"\
            : {\n    \"type\": \"auto\",\n    \"last_messages\": null\n  },\n  \"\
            response_format\": \"auto\",\n  \"tool_choice\": \"auto\",\n  \"parallel_tool_calls\"\
            : true\n}\n"
          title: Default
        - request:
            curl: "curl https://api.openai.com/v1/threads/thread_123/runs \\\n  -H\
              \ \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -d\
              \ '{\n    \"assistant_id\": \"asst_123\",\n    \"stream\": true\n  }'\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const stream = await openai.beta.threads.runs.create(\n\
              \    \"thread_123\",\n    { assistant_id: \"asst_123\", stream: true\
              \ }\n  );\n\n  for await (const event of stream) {\n    console.log(event);\n\
              \  }\n}\n\nmain();\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nstream = client.beta.threads.runs.create(\n\
              \  thread_id=\"thread_123\",\n  assistant_id=\"asst_123\",\n  stream=True\n\
              )\n\nfor event in stream:\n  print(event)\n"
          response: 'event: thread.run.created

            data: {"id":"run_123","object":"thread.run","created_at":1710330640,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710331240,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}


            event: thread.run.queued

            data: {"id":"run_123","object":"thread.run","created_at":1710330640,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710331240,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}


            event: thread.run.in_progress

            data: {"id":"run_123","object":"thread.run","created_at":1710330640,"assistant_id":"asst_123","thread_id":"thread_123","status":"in_progress","started_at":1710330641,"expires_at":1710331240,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}


            event: thread.run.step.created

            data: {"id":"step_001","object":"thread.run.step","created_at":1710330641,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710331240,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}


            event: thread.run.step.in_progress

            data: {"id":"step_001","object":"thread.run.step","created_at":1710330641,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710331240,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}


            event: thread.message.created

            data: {"id":"msg_001","object":"thread.message","created_at":1710330641,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}


            event: thread.message.in_progress

            data: {"id":"msg_001","object":"thread.message","created_at":1710330641,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}


            event: thread.message.delta

            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"Hello","annotations":[]}}]}}


            ...


            event: thread.message.delta

            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"
            today"}}]}}


            event: thread.message.delta

            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"?"}}]}}


            event: thread.message.completed

            data: {"id":"msg_001","object":"thread.message","created_at":1710330641,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"completed","incomplete_details":null,"incomplete_at":null,"completed_at":1710330642,"role":"assistant","content":[{"type":"text","text":{"value":"Hello!
            How can I assist you today?","annotations":[]}}],"metadata":{}}


            event: thread.run.step.completed

            data: {"id":"step_001","object":"thread.run.step","created_at":1710330641,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"completed","cancelled_at":null,"completed_at":1710330642,"expires_at":1710331240,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31}}


            event: thread.run.completed

            data: {"id":"run_123","object":"thread.run","created_at":1710330640,"assistant_id":"asst_123","thread_id":"thread_123","status":"completed","started_at":1710330641,"expires_at":null,"cancelled_at":null,"failed_at":null,"completed_at":1710330642,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31},"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}


            event: done

            data: [DONE]

            '
          title: Streaming
        - request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123/runs \\\n\
              \  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -d\
              \ '{\n    \"assistant_id\": \"asst_abc123\",\n    \"tools\": [\n   \
              \   {\n        \"type\": \"function\",\n        \"function\": {\n  \
              \        \"name\": \"get_current_weather\",\n          \"description\"\
              : \"Get the current weather in a given location\",\n          \"parameters\"\
              : {\n            \"type\": \"object\",\n            \"properties\":\
              \ {\n              \"location\": {\n                \"type\": \"string\"\
              ,\n                \"description\": \"The city and state, e.g. San Francisco,\
              \ CA\"\n              },\n              \"unit\": {\n              \
              \  \"type\": \"string\",\n                \"enum\": [\"celsius\", \"\
              fahrenheit\"]\n              }\n            },\n            \"required\"\
              : [\"location\"]\n          }\n        }\n      }\n    ],\n    \"stream\"\
              : true\n  }'\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nconst tools = [\n    {\n      \"type\": \"function\",\n      \"function\"\
              : {\n        \"name\": \"get_current_weather\",\n        \"description\"\
              : \"Get the current weather in a given location\",\n        \"parameters\"\
              : {\n          \"type\": \"object\",\n          \"properties\": {\n\
              \            \"location\": {\n              \"type\": \"string\",\n\
              \              \"description\": \"The city and state, e.g. San Francisco,\
              \ CA\",\n            },\n            \"unit\": {\"type\": \"string\"\
              , \"enum\": [\"celsius\", \"fahrenheit\"]},\n          },\n        \
              \  \"required\": [\"location\"],\n        },\n      }\n    }\n];\n\n\
              async function main() {\n  const stream = await openai.beta.threads.runs.create(\n\
              \    \"thread_abc123\",\n    {\n      assistant_id: \"asst_abc123\"\
              ,\n      tools: tools,\n      stream: true\n    }\n  );\n\n  for await\
              \ (const event of stream) {\n    console.log(event);\n  }\n}\n\nmain();\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\ntools = [\n \
              \ {\n    \"type\": \"function\",\n    \"function\": {\n      \"name\"\
              : \"get_current_weather\",\n      \"description\": \"Get the current\
              \ weather in a given location\",\n      \"parameters\": {\n        \"\
              type\": \"object\",\n        \"properties\": {\n          \"location\"\
              : {\n            \"type\": \"string\",\n            \"description\"\
              : \"The city and state, e.g. San Francisco, CA\",\n          },\n  \
              \        \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"\
              fahrenheit\"]},\n        },\n        \"required\": [\"location\"],\n\
              \      },\n    }\n  }\n]\n\nstream = client.beta.threads.runs.create(\n\
              \  thread_id=\"thread_abc123\",\n  assistant_id=\"asst_abc123\",\n \
              \ tools=tools,\n  stream=True\n)\n\nfor event in stream:\n  print(event)\n"
          response: 'event: thread.run.created

            data: {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}


            event: thread.run.queued

            data: {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}


            event: thread.run.in_progress

            data: {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"in_progress","started_at":1710348075,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}


            event: thread.run.step.created

            data: {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}


            event: thread.run.step.in_progress

            data: {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}


            event: thread.message.created

            data: {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}


            event: thread.message.in_progress

            data: {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}


            event: thread.message.delta

            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"Hello","annotations":[]}}]}}


            ...


            event: thread.message.delta

            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"
            today"}}]}}


            event: thread.message.delta

            data: {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"?"}}]}}


            event: thread.message.completed

            data: {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"completed","incomplete_details":null,"incomplete_at":null,"completed_at":1710348077,"role":"assistant","content":[{"type":"text","text":{"value":"Hello!
            How can I assist you today?","annotations":[]}}],"metadata":{}}


            event: thread.run.step.completed

            data: {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"completed","cancelled_at":null,"completed_at":1710348077,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31}}


            event: thread.run.completed

            data: {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"completed","started_at":1710348075,"expires_at":null,"cancelled_at":null,"failed_at":null,"completed_at":1710348077,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31},"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}


            event: done

            data: [DONE]

            '
          title: Streaming with Functions
        group: threads
        name: Create run
        returns: A [run](/docs/api-reference/runs/object) object.
  /threads/{thread_id}/runs/{run_id}:
    get:
      operationId: getRun
      parameters:
      - description: The ID of the [thread](/docs/api-reference/threads) that was
          run.
        in: path
        name: thread_id
        required: true
        schema:
          type: string
      - description: The ID of the run to retrieve.
        in: path
        name: run_id
        required: true
        schema:
          type: string
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
          description: OK
      summary: Retrieves a run.
      tags:
      - Assistants
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123\
              \ \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta:\
              \ assistants=v2\"\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const run = await openai.beta.threads.runs.retrieve(\n\
              \    \"thread_abc123\",\n    \"run_abc123\"\n  );\n\n  console.log(run);\n\
              }\n\nmain();\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nrun = client.beta.threads.runs.retrieve(\n\
              \  thread_id=\"thread_abc123\",\n  run_id=\"run_abc123\"\n)\n\nprint(run)\n"
          response: "{\n  \"id\": \"run_abc123\",\n  \"object\": \"thread.run\",\n\
            \  \"created_at\": 1699075072,\n  \"assistant_id\": \"asst_abc123\",\n\
            \  \"thread_id\": \"thread_abc123\",\n  \"status\": \"completed\",\n \
            \ \"started_at\": 1699075072,\n  \"expires_at\": null,\n  \"cancelled_at\"\
            : null,\n  \"failed_at\": null,\n  \"completed_at\": 1699075073,\n  \"\
            last_error\": null,\n  \"model\": \"gpt-4-turbo\",\n  \"instructions\"\
            : null,\n  \"incomplete_details\": null,\n  \"tools\": [\n    {\n    \
            \  \"type\": \"code_interpreter\"\n    }\n  ],\n  \"metadata\": {},\n\
            \  \"usage\": {\n    \"prompt_tokens\": 123,\n    \"completion_tokens\"\
            : 456,\n    \"total_tokens\": 579\n  },\n  \"temperature\": 1.0,\n  \"\
            top_p\": 1.0,\n  \"max_prompt_tokens\": 1000,\n  \"max_completion_tokens\"\
            : 1000,\n  \"truncation_strategy\": {\n    \"type\": \"auto\",\n    \"\
            last_messages\": null\n  },\n  \"response_format\": \"auto\",\n  \"tool_choice\"\
            : \"auto\",\n  \"parallel_tool_calls\": true\n}\n"
        group: threads
        name: Retrieve run
        returns: The [run](/docs/api-reference/runs/object) object matching the specified
          ID.
    post:
      operationId: modifyRun
      parameters:
      - description: The ID of the [thread](/docs/api-reference/threads) that was
          run.
        in: path
        name: thread_id
        required: true
        schema:
          type: string
      - description: The ID of the run to modify.
        in: path
        name: run_id
        required: true
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ModifyRunRequest'
        required: true
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
          description: OK
      summary: Modifies a run.
      tags:
      - Assistants
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123\
              \ \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -d\
              \ '{\n    \"metadata\": {\n      \"user_id\": \"user_abc123\"\n    }\n\
              \  }'\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const run = await openai.beta.threads.runs.update(\n\
              \    \"thread_abc123\",\n    \"run_abc123\",\n    {\n      metadata:\
              \ {\n        user_id: \"user_abc123\",\n      },\n    }\n  );\n\n  console.log(run);\n\
              }\n\nmain();\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nrun = client.beta.threads.runs.update(\n\
              \  thread_id=\"thread_abc123\",\n  run_id=\"run_abc123\",\n  metadata={\"\
              user_id\": \"user_abc123\"},\n)\n\nprint(run)\n"
          response: "{\n  \"id\": \"run_abc123\",\n  \"object\": \"thread.run\",\n\
            \  \"created_at\": 1699075072,\n  \"assistant_id\": \"asst_abc123\",\n\
            \  \"thread_id\": \"thread_abc123\",\n  \"status\": \"completed\",\n \
            \ \"started_at\": 1699075072,\n  \"expires_at\": null,\n  \"cancelled_at\"\
            : null,\n  \"failed_at\": null,\n  \"completed_at\": 1699075073,\n  \"\
            last_error\": null,\n  \"model\": \"gpt-4-turbo\",\n  \"instructions\"\
            : null,\n  \"incomplete_details\": null,\n  \"tools\": [\n    {\n    \
            \  \"type\": \"code_interpreter\"\n    }\n  ],\n  \"tool_resources\":\
            \ {\n    \"code_interpreter\": {\n      \"file_ids\": [\n        \"file-abc123\"\
            ,\n        \"file-abc456\"\n      ]\n    }\n  },\n  \"metadata\": {\n\
            \    \"user_id\": \"user_abc123\"\n  },\n  \"usage\": {\n    \"prompt_tokens\"\
            : 123,\n    \"completion_tokens\": 456,\n    \"total_tokens\": 579\n \
            \ },\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"max_prompt_tokens\"\
            : 1000,\n  \"max_completion_tokens\": 1000,\n  \"truncation_strategy\"\
            : {\n    \"type\": \"auto\",\n    \"last_messages\": null\n  },\n  \"\
            response_format\": \"auto\",\n  \"tool_choice\": \"auto\",\n  \"parallel_tool_calls\"\
            : true\n}\n"
        group: threads
        name: Modify run
        returns: The modified [run](/docs/api-reference/runs/object) object matching
          the specified ID.
  /threads/{thread_id}/runs/{run_id}/cancel:
    post:
      operationId: cancelRun
      parameters:
      - description: The ID of the thread to which this run belongs.
        in: path
        name: thread_id
        required: true
        schema:
          type: string
      - description: The ID of the run to cancel.
        in: path
        name: run_id
        required: true
        schema:
          type: string
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
          description: OK
      summary: Cancels a run that is `in_progress`.
      tags:
      - Assistants
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/cancel\
              \ \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"OpenAI-Beta:\
              \ assistants=v2\" \\\n  -X POST\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const run = await openai.beta.threads.runs.cancel(\n\
              \    \"thread_abc123\",\n    \"run_abc123\"\n  );\n\n  console.log(run);\n\
              }\n\nmain();\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nrun = client.beta.threads.runs.cancel(\n\
              \  thread_id=\"thread_abc123\",\n  run_id=\"run_abc123\"\n)\n\nprint(run)\n"
          response: "{\n  \"id\": \"run_abc123\",\n  \"object\": \"thread.run\",\n\
            \  \"created_at\": 1699076126,\n  \"assistant_id\": \"asst_abc123\",\n\
            \  \"thread_id\": \"thread_abc123\",\n  \"status\": \"cancelling\",\n\
            \  \"started_at\": 1699076126,\n  \"expires_at\": 1699076726,\n  \"cancelled_at\"\
            : null,\n  \"failed_at\": null,\n  \"completed_at\": null,\n  \"last_error\"\
            : null,\n  \"model\": \"gpt-4-turbo\",\n  \"instructions\": \"You summarize\
            \ books.\",\n  \"tools\": [\n    {\n      \"type\": \"file_search\"\n\
            \    }\n  ],\n  \"tool_resources\": {\n    \"file_search\": {\n      \"\
            vector_store_ids\": [\"vs_123\"]\n    }\n  },\n  \"metadata\": {},\n \
            \ \"usage\": null,\n  \"temperature\": 1.0,\n  \"top_p\": 1.0,\n  \"response_format\"\
            : \"auto\",\n  \"tool_choice\": \"auto\",\n  \"parallel_tool_calls\":\
            \ true\n}\n"
        group: threads
        name: Cancel a run
        returns: The modified [run](/docs/api-reference/runs/object) object matching
          the specified ID.
  /threads/{thread_id}/runs/{run_id}/steps:
    get:
      operationId: listRunSteps
      parameters:
      - description: The ID of the thread the run and run steps belong to.
        in: path
        name: thread_id
        required: true
        schema:
          type: string
      - description: The ID of the run the run steps belong to.
        in: path
        name: run_id
        required: true
        schema:
          type: string
      - description: 'A limit on the number of objects to be returned. Limit can range
          between 1 and 100, and the default is 20.

          '
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
      - description: 'Sort order by the `created_at` timestamp of the objects. `asc`
          for ascending order and `desc` for descending order.

          '
        in: query
        name: order
        schema:
          default: desc
          enum:
          - asc
          - desc
          type: string
      - description: 'A cursor for use in pagination. `after` is an object ID that
          defines your place in the list. For instance, if you make a list request
          and receive 100 objects, ending with obj_foo, your subsequent call can include
          after=obj_foo in order to fetch the next page of the list.

          '
        in: query
        name: after
        schema:
          type: string
      - description: 'A cursor for use in pagination. `before` is an object ID that
          defines your place in the list. For instance, if you make a list request
          and receive 100 objects, ending with obj_foo, your subsequent call can include
          before=obj_foo in order to fetch the previous page of the list.

          '
        in: query
        name: before
        schema:
          type: string
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListRunStepsResponse'
          description: OK
      summary: Returns a list of run steps belonging to a run.
      tags:
      - Assistants
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps\
              \ \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            node.js: "import OpenAI from \"openai\";\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const runStep = await openai.beta.threads.runs.steps.list(\n\
              \    \"thread_abc123\",\n    \"run_abc123\"\n  );\n  console.log(runStep);\n\
              }\n\nmain();\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nrun_steps = client.beta.threads.runs.steps.list(\n\
              \    thread_id=\"thread_abc123\",\n    run_id=\"run_abc123\"\n)\n\n\
              print(run_steps)\n"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\"\
            : \"step_abc123\",\n      \"object\": \"thread.run.step\",\n      \"created_at\"\
            : 1699063291,\n      \"run_id\": \"run_abc123\",\n      \"assistant_id\"\
            : \"asst_abc123\",\n      \"thread_id\": \"thread_abc123\",\n      \"\
            type\": \"message_creation\",\n      \"status\": \"completed\",\n    \
            \  \"cancelled_at\": null,\n      \"completed_at\": 1699063291,\n    \
            \  \"expired_at\": null,\n      \"failed_at\": null,\n      \"last_error\"\
            : null,\n      \"step_details\": {\n        \"type\": \"message_creation\"\
            ,\n        \"message_creation\": {\n          \"message_id\": \"msg_abc123\"\
            \n        }\n      },\n      \"usage\": {\n        \"prompt_tokens\":\
            \ 123,\n        \"completion_tokens\": 456,\n        \"total_tokens\"\
            : 579\n      }\n    }\n  ],\n  \"first_id\": \"step_abc123\",\n  \"last_id\"\
            : \"step_abc456\",\n  \"has_more\": false\n}\n"
        group: threads
        name: List run steps
        returns: A list of [run step](/docs/api-reference/runs/step-object) objects.
  /threads/{thread_id}/runs/{run_id}/steps/{step_id}:
    get:
      operationId: getRunStep
      parameters:
      - description: The ID of the thread to which the run and run step belongs.
        in: path
        name: thread_id
        required: true
        schema:
          type: string
      - description: The ID of the run to which the run step belongs.
        in: path
        name: run_id
        required: true
        schema:
          type: string
      - description: The ID of the run step to retrieve.
        in: path
        name: step_id
        required: true
        schema:
          type: string
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunStepObject'
          description: OK
      summary: Retrieves a run step.
      tags:
      - Assistants
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps/step_abc123\
              \ \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            node.js: "import OpenAI from \"openai\";\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const runStep = await openai.beta.threads.runs.steps.retrieve(\n\
              \    \"thread_abc123\",\n    \"run_abc123\",\n    \"step_abc123\"\n\
              \  );\n  console.log(runStep);\n}\n\nmain();\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nrun_step = client.beta.threads.runs.steps.retrieve(\n\
              \    thread_id=\"thread_abc123\",\n    run_id=\"run_abc123\",\n    step_id=\"\
              step_abc123\"\n)\n\nprint(run_step)\n"
          response: "{\n  \"id\": \"step_abc123\",\n  \"object\": \"thread.run.step\"\
            ,\n  \"created_at\": 1699063291,\n  \"run_id\": \"run_abc123\",\n  \"\
            assistant_id\": \"asst_abc123\",\n  \"thread_id\": \"thread_abc123\",\n\
            \  \"type\": \"message_creation\",\n  \"status\": \"completed\",\n  \"\
            cancelled_at\": null,\n  \"completed_at\": 1699063291,\n  \"expired_at\"\
            : null,\n  \"failed_at\": null,\n  \"last_error\": null,\n  \"step_details\"\
            : {\n    \"type\": \"message_creation\",\n    \"message_creation\": {\n\
            \      \"message_id\": \"msg_abc123\"\n    }\n  },\n  \"usage\": {\n \
            \   \"prompt_tokens\": 123,\n    \"completion_tokens\": 456,\n    \"total_tokens\"\
            : 579\n  }\n}\n"
        group: threads
        name: Retrieve run step
        returns: The [run step](/docs/api-reference/runs/step-object) object matching
          the specified ID.
  /threads/{thread_id}/runs/{run_id}/submit_tool_outputs:
    post:
      operationId: submitToolOuputsToRun
      parameters:
      - description: The ID of the [thread](/docs/api-reference/threads) to which
          this run belongs.
        in: path
        name: thread_id
        required: true
        schema:
          type: string
      - description: The ID of the run that requires the tool output submission.
        in: path
        name: run_id
        required: true
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/SubmitToolOutputsRunRequest'
        required: true
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RunObject'
          description: OK
      summary: 'When a run has the `status: "requires_action"` and `required_action.type`
        is `submit_tool_outputs`, this endpoint can be used to submit the outputs
        from the tool calls once they''re all completed. All outputs must be submitted
        in a single request.

        '
      tags:
      - Assistants
      x-oaiMeta:
        beta: true
        examples:
        - request:
            curl: "curl https://api.openai.com/v1/threads/thread_123/runs/run_123/submit_tool_outputs\
              \ \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -d\
              \ '{\n    \"tool_outputs\": [\n      {\n        \"tool_call_id\": \"\
              call_001\",\n        \"output\": \"70 degrees and sunny.\"\n      }\n\
              \    ]\n  }'\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const run = await openai.beta.threads.runs.submitToolOutputs(\n\
              \    \"thread_123\",\n    \"run_123\",\n    {\n      tool_outputs: [\n\
              \        {\n          tool_call_id: \"call_001\",\n          output:\
              \ \"70 degrees and sunny.\",\n        },\n      ],\n    }\n  );\n\n\
              \  console.log(run);\n}\n\nmain();\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nrun = client.beta.threads.runs.submit_tool_outputs(\n\
              \  thread_id=\"thread_123\",\n  run_id=\"run_123\",\n  tool_outputs=[\n\
              \    {\n      \"tool_call_id\": \"call_001\",\n      \"output\": \"\
              70 degrees and sunny.\"\n    }\n  ]\n)\n\nprint(run)\n"
          response: "{\n  \"id\": \"run_123\",\n  \"object\": \"thread.run\",\n  \"\
            created_at\": 1699075592,\n  \"assistant_id\": \"asst_123\",\n  \"thread_id\"\
            : \"thread_123\",\n  \"status\": \"queued\",\n  \"started_at\": 1699075592,\n\
            \  \"expires_at\": 1699076192,\n  \"cancelled_at\": null,\n  \"failed_at\"\
            : null,\n  \"completed_at\": null,\n  \"last_error\": null,\n  \"model\"\
            : \"gpt-4-turbo\",\n  \"instructions\": null,\n  \"tools\": [\n    {\n\
            \      \"type\": \"function\",\n      \"function\": {\n        \"name\"\
            : \"get_current_weather\",\n        \"description\": \"Get the current\
            \ weather in a given location\",\n        \"parameters\": {\n        \
            \  \"type\": \"object\",\n          \"properties\": {\n            \"\
            location\": {\n              \"type\": \"string\",\n              \"description\"\
            : \"The city and state, e.g. San Francisco, CA\"\n            },\n   \
            \         \"unit\": {\n              \"type\": \"string\",\n         \
            \     \"enum\": [\"celsius\", \"fahrenheit\"]\n            }\n       \
            \   },\n          \"required\": [\"location\"]\n        }\n      }\n \
            \   }\n  ],\n  \"metadata\": {},\n  \"usage\": null,\n  \"temperature\"\
            : 1.0,\n  \"top_p\": 1.0,\n  \"max_prompt_tokens\": 1000,\n  \"max_completion_tokens\"\
            : 1000,\n  \"truncation_strategy\": {\n    \"type\": \"auto\",\n    \"\
            last_messages\": null\n  },\n  \"response_format\": \"auto\",\n  \"tool_choice\"\
            : \"auto\",\n  \"parallel_tool_calls\": true\n}\n"
          title: Default
        - request:
            curl: "curl https://api.openai.com/v1/threads/thread_123/runs/run_123/submit_tool_outputs\
              \ \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -d\
              \ '{\n    \"tool_outputs\": [\n      {\n        \"tool_call_id\": \"\
              call_001\",\n        \"output\": \"70 degrees and sunny.\"\n      }\n\
              \    ],\n    \"stream\": true\n  }'\n"
            node.js: "import OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const stream = await openai.beta.threads.runs.submitToolOutputs(\n\
              \    \"thread_123\",\n    \"run_123\",\n    {\n      tool_outputs: [\n\
              \        {\n          tool_call_id: \"call_001\",\n          output:\
              \ \"70 degrees and sunny.\",\n        },\n      ],\n    }\n  );\n\n\
              \  for await (const event of stream) {\n    console.log(event);\n  }\n\
              }\n\nmain();\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nstream = client.beta.threads.runs.submit_tool_outputs(\n\
              \  thread_id=\"thread_123\",\n  run_id=\"run_123\",\n  tool_outputs=[\n\
              \    {\n      \"tool_call_id\": \"call_001\",\n      \"output\": \"\
              70 degrees and sunny.\"\n    }\n  ],\n  stream=True\n)\n\nfor event\
              \ in stream:\n  print(event)\n"
          response: 'event: thread.run.step.completed

            data: {"id":"step_001","object":"thread.run.step","created_at":1710352449,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"tool_calls","status":"completed","cancelled_at":null,"completed_at":1710352475,"expires_at":1710353047,"failed_at":null,"last_error":null,"step_details":{"type":"tool_calls","tool_calls":[{"id":"call_iWr0kQ2EaYMaxNdl0v3KYkx7","type":"function","function":{"name":"get_current_weather","arguments":"{\"location\":\"San
            Francisco, CA\",\"unit\":\"fahrenheit\"}","output":"70 degrees and sunny."}}]},"usage":{"prompt_tokens":291,"completion_tokens":24,"total_tokens":315}}


            event: thread.run.queued

            data: {"id":"run_123","object":"thread.run","created_at":1710352447,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":1710352448,"expires_at":1710353047,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get
            the current weather in a given location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The
            city and state, e.g. San Francisco, CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}


            event: thread.run.in_progress

            data: {"id":"run_123","object":"thread.run","created_at":1710352447,"assistant_id":"asst_123","thread_id":"thread_123","status":"in_progress","started_at":1710352475,"expires_at":1710353047,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get
            the current weather in a given location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The
            city and state, e.g. San Francisco, CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}


            event: thread.run.step.created

            data: {"id":"step_002","object":"thread.run.step","created_at":1710352476,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710353047,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_002"}},"usage":null}


            event: thread.run.step.in_progress

            data: {"id":"step_002","object":"thread.run.step","created_at":1710352476,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710353047,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_002"}},"usage":null}


            event: thread.message.created

            data: {"id":"msg_002","object":"thread.message","created_at":1710352476,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}


            event: thread.message.in_progress

            data: {"id":"msg_002","object":"thread.message","created_at":1710352476,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}


            event: thread.message.delta

            data: {"id":"msg_002","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"The","annotations":[]}}]}}


            event: thread.message.delta

            data: {"id":"msg_002","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"
            current"}}]}}


            event: thread.message.delta

            data: {"id":"msg_002","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"
            weather"}}]}}


            ...


            event: thread.message.delta

            data: {"id":"msg_002","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"
            sunny"}}]}}


            event: thread.message.delta

            data: {"id":"msg_002","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"."}}]}}


            event: thread.message.completed

            data: {"id":"msg_002","object":"thread.message","created_at":1710352476,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"completed","incomplete_details":null,"incomplete_at":null,"completed_at":1710352477,"role":"assistant","content":[{"type":"text","text":{"value":"The
            current weather in San Francisco, CA is 70 degrees Fahrenheit and sunny.","annotations":[]}}],"metadata":{}}


            event: thread.run.step.completed

            data: {"id":"step_002","object":"thread.run.step","created_at":1710352476,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"completed","cancelled_at":null,"completed_at":1710352477,"expires_at":1710353047,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_002"}},"usage":{"prompt_tokens":329,"completion_tokens":18,"total_tokens":347}}


            event: thread.run.completed

            data: {"id":"run_123","object":"thread.run","created_at":1710352447,"assistant_id":"asst_123","thread_id":"thread_123","status":"completed","started_at":1710352475,"expires_at":null,"cancelled_at":null,"failed_at":null,"completed_at":1710352477,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get
            the current weather in a given location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The
            city and state, e.g. San Francisco, CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31},"response_format":"auto","tool_choice":"auto","parallel_tool_calls":true}}


            event: done

            data: [DONE]

            '
          title: Streaming
        group: threads
        name: Submit tool outputs to run
        returns: The modified [run](/docs/api-reference/runs/object) object matching
          the specified ID.
  /vector_stores:
    get:
      operationId: listVectorStores
      parameters:
      - description: 'A limit on the number of objects to be returned. Limit can range
          between 1 and 100, and the default is 20.

          '
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
      - description: 'Sort order by the `created_at` timestamp of the objects. `asc`
          for ascending order and `desc` for descending order.

          '
        in: query
        name: order
        schema:
          default: desc
          enum:
          - asc
          - desc
          type: string
      - description: 'A cursor for use in pagination. `after` is an object ID that
          defines your place in the list. For instance, if you make a list request
          and receive 100 objects, ending with obj_foo, your subsequent call can include
          after=obj_foo in order to fetch the next page of the list.

          '
        in: query
        name: after
        schema:
          type: string
      - description: 'A cursor for use in pagination. `before` is an object ID that
          defines your place in the list. For instance, if you make a list request
          and receive 100 objects, ending with obj_foo, your subsequent call can include
          before=obj_foo in order to fetch the previous page of the list.

          '
        in: query
        name: before
        schema:
          type: string
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListVectorStoresResponse'
          description: OK
      summary: Returns a list of vector stores.
      tags:
      - Vector Stores
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/vector_stores \\\n  -H \"Authorization:\
              \ Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\"\
              \ \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            node.js: "import OpenAI from \"openai\";\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const vectorStores = await openai.beta.vectorStores.list();\n\
              \  console.log(vectorStores);\n}\n\nmain();\n"
            python: 'from openai import OpenAI

              client = OpenAI()


              vector_stores = client.beta.vector_stores.list()

              print(vector_stores)

              '
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\"\
            : \"vs_abc123\",\n      \"object\": \"vector_store\",\n      \"created_at\"\
            : 1699061776,\n      \"name\": \"Support FAQ\",\n      \"bytes\": 139920,\n\
            \      \"file_counts\": {\n        \"in_progress\": 0,\n        \"completed\"\
            : 3,\n        \"failed\": 0,\n        \"cancelled\": 0,\n        \"total\"\
            : 3\n      }\n    },\n    {\n      \"id\": \"vs_abc456\",\n      \"object\"\
            : \"vector_store\",\n      \"created_at\": 1699061776,\n      \"name\"\
            : \"Support FAQ v2\",\n      \"bytes\": 139920,\n      \"file_counts\"\
            : {\n        \"in_progress\": 0,\n        \"completed\": 3,\n        \"\
            failed\": 0,\n        \"cancelled\": 0,\n        \"total\": 3\n      }\n\
            \    }\n  ],\n  \"first_id\": \"vs_abc123\",\n  \"last_id\": \"vs_abc456\"\
            ,\n  \"has_more\": false\n}\n"
        group: vector_stores
        name: List vector stores
        returns: A list of [vector store](/docs/api-reference/vector-stores/object)
          objects.
    post:
      operationId: createVectorStore
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateVectorStoreRequest'
        required: true
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreObject'
          description: OK
      summary: Create a vector store.
      tags:
      - Vector Stores
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/vector_stores \\\n  -H \"Authorization:\
              \ Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type: application/json\"\
              \ \\\n  -H \"OpenAI-Beta: assistants=v2\"\n  -d '{\n    \"name\": \"\
              Support FAQ\"\n  }'\n"
            node.js: "import OpenAI from \"openai\";\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const vectorStore = await openai.beta.vectorStores.create({\n\
              \    name: \"Support FAQ\"\n  });\n  console.log(vectorStore);\n}\n\n\
              main();\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nvector_store\
              \ = client.beta.vector_stores.create(\n  name=\"Support FAQ\"\n)\nprint(vector_store)\n"
          response: "{\n  \"id\": \"vs_abc123\",\n  \"object\": \"vector_store\",\n\
            \  \"created_at\": 1699061776,\n  \"name\": \"Support FAQ\",\n  \"bytes\"\
            : 139920,\n  \"file_counts\": {\n    \"in_progress\": 0,\n    \"completed\"\
            : 3,\n    \"failed\": 0,\n    \"cancelled\": 0,\n    \"total\": 3\n  }\n\
            }\n"
        group: vector_stores
        name: Create vector store
        returns: A [vector store](/docs/api-reference/vector-stores/object) object.
  /vector_stores/{vector_store_id}:
    delete:
      operationId: deleteVectorStore
      parameters:
      - description: The ID of the vector store to delete.
        in: path
        name: vector_store_id
        required: true
        schema:
          type: string
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteVectorStoreResponse'
          description: OK
      summary: Delete a vector store.
      tags:
      - Vector Stores
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/vector_stores/vs_abc123 \\\n  -H\
              \ \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -X\
              \ DELETE\n"
            node.js: "import OpenAI from \"openai\";\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const deletedVectorStore = await openai.beta.vectorStores.del(\n\
              \    \"vs_abc123\"\n  );\n  console.log(deletedVectorStore);\n}\n\n\
              main();\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\ndeleted_vector_store\
              \ = client.beta.vector_stores.delete(\n  vector_store_id=\"vs_abc123\"\
              \n)\nprint(deleted_vector_store)\n"
          response: "{\n  id: \"vs_abc123\",\n  object: \"vector_store.deleted\",\n\
            \  deleted: true\n}\n"
        group: vector_stores
        name: Delete vector store
        returns: Deletion status
    get:
      operationId: getVectorStore
      parameters:
      - description: The ID of the vector store to retrieve.
        in: path
        name: vector_store_id
        required: true
        schema:
          type: string
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreObject'
          description: OK
      summary: Retrieves a vector store.
      tags:
      - Vector Stores
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/vector_stores/vs_abc123 \\\n  -H\
              \ \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            node.js: "import OpenAI from \"openai\";\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const vectorStore = await openai.beta.vectorStores.retrieve(\n\
              \    \"vs_abc123\"\n  );\n  console.log(vectorStore);\n}\n\nmain();\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nvector_store\
              \ = client.beta.vector_stores.retrieve(\n  vector_store_id=\"vs_abc123\"\
              \n)\nprint(vector_store)\n"
          response: "{\n  \"id\": \"vs_abc123\",\n  \"object\": \"vector_store\",\n\
            \  \"created_at\": 1699061776\n}\n"
        group: vector_stores
        name: Retrieve vector store
        returns: The [vector store](/docs/api-reference/vector-stores/object) object
          matching the specified ID.
    post:
      operationId: modifyVectorStore
      parameters:
      - description: The ID of the vector store to modify.
        in: path
        name: vector_store_id
        required: true
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/UpdateVectorStoreRequest'
        required: true
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreObject'
          description: OK
      summary: Modifies a vector store.
      tags:
      - Vector Stores
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/vector_stores/vs_abc123 \\\n  -H\
              \ \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n  -d '{\n\
              \    \"name\": \"Support FAQ\"\n  }'\n"
            node.js: "import OpenAI from \"openai\";\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const vectorStore = await openai.beta.vectorStores.update(\n\
              \    \"vs_abc123\",\n    {\n      name: \"Support FAQ\"\n    }\n  );\n\
              \  console.log(vectorStore);\n}\n\nmain();\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nvector_store\
              \ = client.beta.vector_stores.update(\n  vector_store_id=\"vs_abc123\"\
              ,\n  name=\"Support FAQ\"\n)\nprint(vector_store)\n"
          response: "{\n  \"id\": \"vs_abc123\",\n  \"object\": \"vector_store\",\n\
            \  \"created_at\": 1699061776,\n  \"name\": \"Support FAQ\",\n  \"bytes\"\
            : 139920,\n  \"file_counts\": {\n    \"in_progress\": 0,\n    \"completed\"\
            : 3,\n    \"failed\": 0,\n    \"cancelled\": 0,\n    \"total\": 3\n  }\n\
            }\n"
        group: vector_stores
        name: Modify vector store
        returns: The modified [vector store](/docs/api-reference/vector-stores/object)
          object.
  /vector_stores/{vector_store_id}/file_batches:
    post:
      operationId: createVectorStoreFileBatch
      parameters:
      - description: 'The ID of the vector store for which to create a File Batch.

          '
        in: path
        name: vector_store_id
        required: true
        schema:
          example: vs_abc123
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateVectorStoreFileBatchRequest'
        required: true
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreFileBatchObject'
          description: OK
      summary: Create a vector store file batch.
      tags:
      - Vector Stores
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/vector_stores/vs_abc123/file_batches\
              \ \\\n    -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n    -H \"\
              Content-Type: application/json \\\n    -H \"OpenAI-Beta: assistants=v2\"\
              \ \\\n    -d '{\n      \"file_ids\": [\"file-abc123\", \"file-abc456\"\
              ]\n    }'\n"
            node.js: "import OpenAI from \"openai\";\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const myVectorStoreFileBatch = await openai.beta.vectorStores.fileBatches.create(\n\
              \    \"vs_abc123\",\n    {\n      file_ids: [\"file-abc123\", \"file-abc456\"\
              ]\n    }\n  );\n  console.log(myVectorStoreFileBatch);\n}\n\nmain();\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nvector_store_file_batch\
              \ = client.beta.vector_stores.file_batches.create(\n  vector_store_id=\"\
              vs_abc123\",\n  file_ids=[\"file-abc123\", \"file-abc456\"]\n)\nprint(vector_store_file_batch)\n"
          response: "{\n  \"id\": \"vsfb_abc123\",\n  \"object\": \"vector_store.file_batch\"\
            ,\n  \"created_at\": 1699061776,\n  \"vector_store_id\": \"vs_abc123\"\
            ,\n  \"status\": \"in_progress\",\n  \"file_counts\": {\n    \"in_progress\"\
            : 1,\n    \"completed\": 1,\n    \"failed\": 0,\n    \"cancelled\": 0,\n\
            \    \"total\": 0,\n  }\n}\n"
        group: vector_stores
        name: Create vector store file batch
        returns: A [vector store file batch](/docs/api-reference/vector-stores-file-batches/batch-object)
          object.
  /vector_stores/{vector_store_id}/file_batches/{batch_id}:
    get:
      operationId: getVectorStoreFileBatch
      parameters:
      - description: The ID of the vector store that the file batch belongs to.
        in: path
        name: vector_store_id
        required: true
        schema:
          example: vs_abc123
          type: string
      - description: The ID of the file batch being retrieved.
        in: path
        name: batch_id
        required: true
        schema:
          example: vsfb_abc123
          type: string
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreFileBatchObject'
          description: OK
      summary: Retrieves a vector store file batch.
      tags:
      - Vector Stores
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123\
              \ \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            node.js: "import OpenAI from \"openai\";\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const vectorStoreFileBatch = await openai.beta.vectorStores.fileBatches.retrieve(\n\
              \    \"vs_abc123\",\n    \"vsfb_abc123\"\n  );\n  console.log(vectorStoreFileBatch);\n\
              }\n\nmain();\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nvector_store_file_batch\
              \ = client.beta.vector_stores.file_batches.retrieve(\n  vector_store_id=\"\
              vs_abc123\",\n  batch_id=\"vsfb_abc123\"\n)\nprint(vector_store_file_batch)\n"
          response: "{\n  \"id\": \"vsfb_abc123\",\n  \"object\": \"vector_store.file_batch\"\
            ,\n  \"created_at\": 1699061776,\n  \"vector_store_id\": \"vs_abc123\"\
            ,\n  \"status\": \"in_progress\",\n  \"file_counts\": {\n    \"in_progress\"\
            : 1,\n    \"completed\": 1,\n    \"failed\": 0,\n    \"cancelled\": 0,\n\
            \    \"total\": 0,\n  }\n}\n"
        group: vector_stores
        name: Retrieve vector store file batch
        returns: The [vector store file batch](/docs/api-reference/vector-stores-file-batches/batch-object)
          object.
  /vector_stores/{vector_store_id}/file_batches/{batch_id}/cancel:
    post:
      operationId: cancelVectorStoreFileBatch
      parameters:
      - description: The ID of the vector store that the file batch belongs to.
        in: path
        name: vector_store_id
        required: true
        schema:
          type: string
      - description: The ID of the file batch to cancel.
        in: path
        name: batch_id
        required: true
        schema:
          type: string
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreFileBatchObject'
          description: OK
      summary: Cancel a vector store file batch. This attempts to cancel the processing
        of files in this batch as soon as possible.
      tags:
      - Vector Stores
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123/cancel\
              \ \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -X\
              \ POST\n"
            node.js: "import OpenAI from \"openai\";\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const deletedVectorStoreFileBatch = await\
              \ openai.vector_stores.fileBatches.cancel(\n    \"vs_abc123\",\n   \
              \ \"vsfb_abc123\"\n  );\n  console.log(deletedVectorStoreFileBatch);\n\
              }\n\nmain();\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\ndeleted_vector_store_file_batch\
              \ = client.beta.vector_stores.file_batches.cancel(\n    vector_store_id=\"\
              vs_abc123\",\n    file_batch_id=\"vsfb_abc123\"\n)\nprint(deleted_vector_store_file_batch)\n"
          response: "{\n  \"id\": \"vsfb_abc123\",\n  \"object\": \"vector_store.file_batch\"\
            ,\n  \"created_at\": 1699061776,\n  \"vector_store_id\": \"vs_abc123\"\
            ,\n  \"status\": \"cancelling\",\n  \"file_counts\": {\n    \"in_progress\"\
            : 12,\n    \"completed\": 3,\n    \"failed\": 0,\n    \"cancelled\": 0,\n\
            \    \"total\": 15,\n  }\n}\n"
        group: vector_stores
        name: Cancel vector store file batch
        returns: The modified vector store file batch object.
  /vector_stores/{vector_store_id}/file_batches/{batch_id}/files:
    get:
      operationId: listFilesInVectorStoreBatch
      parameters:
      - description: The ID of the vector store that the files belong to.
        in: path
        name: vector_store_id
        required: true
        schema:
          type: string
      - description: The ID of the file batch that the files belong to.
        in: path
        name: batch_id
        required: true
        schema:
          type: string
      - description: 'A limit on the number of objects to be returned. Limit can range
          between 1 and 100, and the default is 20.

          '
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
      - description: 'Sort order by the `created_at` timestamp of the objects. `asc`
          for ascending order and `desc` for descending order.

          '
        in: query
        name: order
        schema:
          default: desc
          enum:
          - asc
          - desc
          type: string
      - description: 'A cursor for use in pagination. `after` is an object ID that
          defines your place in the list. For instance, if you make a list request
          and receive 100 objects, ending with obj_foo, your subsequent call can include
          after=obj_foo in order to fetch the next page of the list.

          '
        in: query
        name: after
        schema:
          type: string
      - description: 'A cursor for use in pagination. `before` is an object ID that
          defines your place in the list. For instance, if you make a list request
          and receive 100 objects, ending with obj_foo, your subsequent call can include
          before=obj_foo in order to fetch the previous page of the list.

          '
        in: query
        name: before
        schema:
          type: string
      - description: Filter by file status. One of `in_progress`, `completed`, `failed`,
          `cancelled`.
        in: query
        name: filter
        schema:
          enum:
          - in_progress
          - completed
          - failed
          - cancelled
          type: string
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListVectorStoreFilesResponse'
          description: OK
      summary: Returns a list of vector store files in a batch.
      tags:
      - Vector Stores
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123/files\
              \ \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            node.js: "import OpenAI from \"openai\";\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const vectorStoreFiles = await openai.beta.vectorStores.fileBatches.listFiles(\n\
              \    \"vs_abc123\",\n    \"vsfb_abc123\"\n  );\n  console.log(vectorStoreFiles);\n\
              }\n\nmain();\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nvector_store_files\
              \ = client.beta.vector_stores.file_batches.list_files(\n  vector_store_id=\"\
              vs_abc123\",\n  batch_id=\"vsfb_abc123\"\n)\nprint(vector_store_files)\n"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\"\
            : \"file-abc123\",\n      \"object\": \"vector_store.file\",\n      \"\
            created_at\": 1699061776,\n      \"vector_store_id\": \"vs_abc123\"\n\
            \    },\n    {\n      \"id\": \"file-abc456\",\n      \"object\": \"vector_store.file\"\
            ,\n      \"created_at\": 1699061776,\n      \"vector_store_id\": \"vs_abc123\"\
            \n    }\n  ],\n  \"first_id\": \"file-abc123\",\n  \"last_id\": \"file-abc456\"\
            ,\n  \"has_more\": false\n}\n"
        group: vector_stores
        name: List vector store files in a batch
        returns: A list of [vector store file](/docs/api-reference/vector-stores-files/file-object)
          objects.
  /vector_stores/{vector_store_id}/files:
    get:
      operationId: listVectorStoreFiles
      parameters:
      - description: The ID of the vector store that the files belong to.
        in: path
        name: vector_store_id
        required: true
        schema:
          type: string
      - description: 'A limit on the number of objects to be returned. Limit can range
          between 1 and 100, and the default is 20.

          '
        in: query
        name: limit
        required: false
        schema:
          default: 20
          type: integer
      - description: 'Sort order by the `created_at` timestamp of the objects. `asc`
          for ascending order and `desc` for descending order.

          '
        in: query
        name: order
        schema:
          default: desc
          enum:
          - asc
          - desc
          type: string
      - description: 'A cursor for use in pagination. `after` is an object ID that
          defines your place in the list. For instance, if you make a list request
          and receive 100 objects, ending with obj_foo, your subsequent call can include
          after=obj_foo in order to fetch the next page of the list.

          '
        in: query
        name: after
        schema:
          type: string
      - description: 'A cursor for use in pagination. `before` is an object ID that
          defines your place in the list. For instance, if you make a list request
          and receive 100 objects, ending with obj_foo, your subsequent call can include
          before=obj_foo in order to fetch the previous page of the list.

          '
        in: query
        name: before
        schema:
          type: string
      - description: Filter by file status. One of `in_progress`, `completed`, `failed`,
          `cancelled`.
        in: query
        name: filter
        schema:
          enum:
          - in_progress
          - completed
          - failed
          - cancelled
          type: string
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ListVectorStoreFilesResponse'
          description: OK
      summary: Returns a list of vector store files.
      tags:
      - Vector Stores
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/vector_stores/vs_abc123/files \\\
              \n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            node.js: "import OpenAI from \"openai\";\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const vectorStoreFiles = await openai.beta.vectorStores.files.list(\n\
              \    \"vs_abc123\"\n  );\n  console.log(vectorStoreFiles);\n}\n\nmain();\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nvector_store_files\
              \ = client.beta.vector_stores.files.list(\n  vector_store_id=\"vs_abc123\"\
              \n)\nprint(vector_store_files)\n"
          response: "{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\"\
            : \"file-abc123\",\n      \"object\": \"vector_store.file\",\n      \"\
            created_at\": 1699061776,\n      \"vector_store_id\": \"vs_abc123\"\n\
            \    },\n    {\n      \"id\": \"file-abc456\",\n      \"object\": \"vector_store.file\"\
            ,\n      \"created_at\": 1699061776,\n      \"vector_store_id\": \"vs_abc123\"\
            \n    }\n  ],\n  \"first_id\": \"file-abc123\",\n  \"last_id\": \"file-abc456\"\
            ,\n  \"has_more\": false\n}\n"
        group: vector_stores
        name: List vector store files
        returns: A list of [vector store file](/docs/api-reference/vector-stores-files/file-object)
          objects.
    post:
      operationId: createVectorStoreFile
      parameters:
      - description: 'The ID of the vector store for which to create a File.

          '
        in: path
        name: vector_store_id
        required: true
        schema:
          example: vs_abc123
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateVectorStoreFileRequest'
        required: true
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreFileObject'
          description: OK
      summary: Create a vector store file by attaching a [File](/docs/api-reference/files)
        to a [vector store](/docs/api-reference/vector-stores/object).
      tags:
      - Vector Stores
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/vector_stores/vs_abc123/files \\\
              \n    -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n    -H \"Content-Type:\
              \ application/json\" \\\n    -H \"OpenAI-Beta: assistants=v2\" \\\n\
              \    -d '{\n      \"file_id\": \"file-abc123\"\n    }'\n"
            node.js: "import OpenAI from \"openai\";\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const myVectorStoreFile = await openai.beta.vectorStores.files.create(\n\
              \    \"vs_abc123\",\n    {\n      file_id: \"file-abc123\"\n    }\n\
              \  );\n  console.log(myVectorStoreFile);\n}\n\nmain();\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nvector_store_file\
              \ = client.beta.vector_stores.files.create(\n  vector_store_id=\"vs_abc123\"\
              ,\n  file_id=\"file-abc123\"\n)\nprint(vector_store_file)\n"
          response: "{\n  \"id\": \"file-abc123\",\n  \"object\": \"vector_store.file\"\
            ,\n  \"created_at\": 1699061776,\n  \"usage_bytes\": 1234,\n  \"vector_store_id\"\
            : \"vs_abcd\",\n  \"status\": \"completed\",\n  \"last_error\": null\n\
            }\n"
        group: vector_stores
        name: Create vector store file
        returns: A [vector store file](/docs/api-reference/vector-stores-files/file-object)
          object.
  /vector_stores/{vector_store_id}/files/{file_id}:
    delete:
      operationId: deleteVectorStoreFile
      parameters:
      - description: The ID of the vector store that the file belongs to.
        in: path
        name: vector_store_id
        required: true
        schema:
          type: string
      - description: The ID of the file to delete.
        in: path
        name: file_id
        required: true
        schema:
          type: string
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DeleteVectorStoreFileResponse'
          description: OK
      summary: Delete a vector store file. This will remove the file from the vector
        store but the file itself will not be deleted. To delete the file, use the
        [delete file](/docs/api-reference/files/delete) endpoint.
      tags:
      - Vector Stores
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123\
              \ \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\" \\\n  -X\
              \ DELETE\n"
            node.js: "import OpenAI from \"openai\";\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const deletedVectorStoreFile = await openai.beta.vectorStores.files.del(\n\
              \    \"vs_abc123\",\n    \"file-abc123\"\n  );\n  console.log(deletedVectorStoreFile);\n\
              }\n\nmain();\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\ndeleted_vector_store_file\
              \ = client.beta.vector_stores.files.delete(\n    vector_store_id=\"\
              vs_abc123\",\n    file_id=\"file-abc123\"\n)\nprint(deleted_vector_store_file)\n"
          response: "{\n  id: \"file-abc123\",\n  object: \"vector_store.file.deleted\"\
            ,\n  deleted: true\n}\n"
        group: vector_stores
        name: Delete vector store file
        returns: Deletion status
    get:
      operationId: getVectorStoreFile
      parameters:
      - description: The ID of the vector store that the file belongs to.
        in: path
        name: vector_store_id
        required: true
        schema:
          example: vs_abc123
          type: string
      - description: The ID of the file being retrieved.
        in: path
        name: file_id
        required: true
        schema:
          example: file-abc123
          type: string
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/VectorStoreFileObject'
          description: OK
      summary: Retrieves a vector store file.
      tags:
      - Vector Stores
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: "curl https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123\
              \ \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -H \"Content-Type:\
              \ application/json\" \\\n  -H \"OpenAI-Beta: assistants=v2\"\n"
            node.js: "import OpenAI from \"openai\";\nconst openai = new OpenAI();\n\
              \nasync function main() {\n  const vectorStoreFile = await openai.beta.vectorStores.files.retrieve(\n\
              \    \"vs_abc123\",\n    \"file-abc123\"\n  );\n  console.log(vectorStoreFile);\n\
              }\n\nmain();\n"
            python: "from openai import OpenAI\nclient = OpenAI()\n\nvector_store_file\
              \ = client.beta.vector_stores.files.retrieve(\n  vector_store_id=\"\
              vs_abc123\",\n  file_id=\"file-abc123\"\n)\nprint(vector_store_file)\n"
          response: "{\n  \"id\": \"file-abc123\",\n  \"object\": \"vector_store.file\"\
            ,\n  \"created_at\": 1699061776,\n  \"vector_store_id\": \"vs_abcd\",\n\
            \  \"status\": \"completed\",\n  \"last_error\": null\n}\n"
        group: vector_stores
        name: Retrieve vector store file
        returns: The [vector store file](/docs/api-reference/vector-stores-files/file-object)
          object.
security:
- ApiKeyAuth: []
servers:
- url: https://api.openai.com/v1
tags:
- description: Build Assistants that can call models and use tools.
  name: Assistants
- description: Turn audio into text or text into audio.
  name: Audio
- description: Given a list of messages comprising a conversation, the model will
    return a response.
  name: Chat
- description: Given a prompt, the model will return one or more predicted completions,
    and can also return the probabilities of alternative tokens at each position.
  name: Completions
- description: Get a vector representation of a given input that can be easily consumed
    by machine learning models and algorithms.
  name: Embeddings
- description: Manage fine-tuning jobs to tailor a model to your specific training
    data.
  name: Fine-tuning
- description: Create large batches of API requests to run asynchronously.
  name: Batch
- description: Files are used to upload documents that can be used with features like
    Assistants and Fine-tuning.
  name: Files
- description: Given a prompt and/or an input image, the model will generate a new
    image.
  name: Images
- description: List and describe the various models available in the API.
  name: Models
- description: Given a input text, outputs if the model classifies it as potentially
    harmful.
  name: Moderations
x-oaiMeta:
  groups:
  - description: 'Learn how to turn audio into text or text into audio.


      Related guide: [Speech to text](/docs/guides/speech-to-text)

      '
    id: audio
    navigationGroup: endpoints
    sections:
    - key: createSpeech
      path: createSpeech
      type: endpoint
    - key: createTranscription
      path: createTranscription
      type: endpoint
    - key: createTranslation
      path: createTranslation
      type: endpoint
    - key: CreateTranscriptionResponseJson
      path: json-object
      type: object
    - key: CreateTranscriptionResponseVerboseJson
      path: verbose-json-object
      type: object
    title: Audio
  - description: 'Given a list of messages comprising a conversation, the model will
      return a response.


      Related guide: [Chat Completions](/docs/guides/text-generation)

      '
    id: chat
    navigationGroup: endpoints
    sections:
    - key: createChatCompletion
      path: create
      type: endpoint
    - key: CreateChatCompletionResponse
      path: object
      type: object
    - key: CreateChatCompletionStreamResponse
      path: streaming
      type: object
    title: Chat
  - description: 'Get a vector representation of a given input that can be easily
      consumed by machine learning models and algorithms.


      Related guide: [Embeddings](/docs/guides/embeddings)

      '
    id: embeddings
    navigationGroup: endpoints
    sections:
    - key: createEmbedding
      path: create
      type: endpoint
    - key: Embedding
      path: object
      type: object
    title: Embeddings
  - description: 'Manage fine-tuning jobs to tailor a model to your specific training
      data.


      Related guide: [Fine-tune models](/docs/guides/fine-tuning)

      '
    id: fine-tuning
    navigationGroup: endpoints
    sections:
    - key: createFineTuningJob
      path: create
      type: endpoint
    - key: listPaginatedFineTuningJobs
      path: list
      type: endpoint
    - key: listFineTuningEvents
      path: list-events
      type: endpoint
    - key: listFineTuningJobCheckpoints
      path: list-checkpoints
      type: endpoint
    - key: retrieveFineTuningJob
      path: retrieve
      type: endpoint
    - key: cancelFineTuningJob
      path: cancel
      type: endpoint
    - key: FinetuneChatRequestInput
      path: chat-input
      type: object
    - key: FinetuneCompletionRequestInput
      path: completions-input
      type: object
    - key: FineTuningJob
      path: object
      type: object
    - key: FineTuningJobEvent
      path: event-object
      type: object
    - key: FineTuningJobCheckpoint
      path: checkpoint-object
      type: object
    title: Fine-tuning
  - description: 'Create large batches of API requests for asynchronous processing.
      The Batch API returns completions within 24 hours for a 50% discount.


      Related guide: [Batch](/docs/guides/batch)

      '
    id: batch
    navigationGroup: endpoints
    sections:
    - key: createBatch
      path: create
      type: endpoint
    - key: retrieveBatch
      path: retrieve
      type: endpoint
    - key: cancelBatch
      path: cancel
      type: endpoint
    - key: listBatches
      path: list
      type: endpoint
    - key: Batch
      path: object
      type: object
    - key: BatchRequestInput
      path: request-input
      type: object
    - key: BatchRequestOutput
      path: request-output
      type: object
    title: Batch
  - description: 'Files are used to upload documents that can be used with features
      like [Assistants](/docs/api-reference/assistants), [Fine-tuning](/docs/api-reference/fine-tuning),
      and [Batch API](/docs/guides/batch).

      '
    id: files
    navigationGroup: endpoints
    sections:
    - key: createFile
      path: create
      type: endpoint
    - key: listFiles
      path: list
      type: endpoint
    - key: retrieveFile
      path: retrieve
      type: endpoint
    - key: deleteFile
      path: delete
      type: endpoint
    - key: downloadFile
      path: retrieve-contents
      type: endpoint
    - key: OpenAIFile
      path: object
      type: object
    title: Files
  - description: 'Given a prompt and/or an input image, the model will generate a
      new image.


      Related guide: [Image generation](/docs/guides/images)

      '
    id: images
    navigationGroup: endpoints
    sections:
    - key: createImage
      path: create
      type: endpoint
    - key: createImageEdit
      path: createEdit
      type: endpoint
    - key: createImageVariation
      path: createVariation
      type: endpoint
    - key: Image
      path: object
      type: object
    title: Images
  - description: 'List and describe the various models available in the API. You can
      refer to the [Models](/docs/models) documentation to understand what models
      are available and the differences between them.

      '
    id: models
    navigationGroup: endpoints
    sections:
    - key: listModels
      path: list
      type: endpoint
    - key: retrieveModel
      path: retrieve
      type: endpoint
    - key: deleteModel
      path: delete
      type: endpoint
    - key: Model
      path: object
      type: object
    title: Models
  - description: 'Given some input text, outputs if the model classifies it as potentially
      harmful across several categories.


      Related guide: [Moderations](/docs/guides/moderation)

      '
    id: moderations
    navigationGroup: endpoints
    sections:
    - key: createModeration
      path: create
      type: endpoint
    - key: CreateModerationResponse
      path: object
      type: object
    title: Moderations
  - beta: true
    description: 'Build assistants that can call models and use tools to perform tasks.


      [Get started with the Assistants API](/docs/assistants)

      '
    id: assistants
    navigationGroup: assistants
    sections:
    - key: createAssistant
      path: createAssistant
      type: endpoint
    - key: listAssistants
      path: listAssistants
      type: endpoint
    - key: getAssistant
      path: getAssistant
      type: endpoint
    - key: modifyAssistant
      path: modifyAssistant
      type: endpoint
    - key: deleteAssistant
      path: deleteAssistant
      type: endpoint
    - key: AssistantObject
      path: object
      type: object
    title: Assistants
  - beta: true
    description: 'Create threads that assistants can interact with.


      Related guide: [Assistants](/docs/assistants/overview)

      '
    id: threads
    navigationGroup: assistants
    sections:
    - key: createThread
      path: createThread
      type: endpoint
    - key: getThread
      path: getThread
      type: endpoint
    - key: modifyThread
      path: modifyThread
      type: endpoint
    - key: deleteThread
      path: deleteThread
      type: endpoint
    - key: ThreadObject
      path: object
      type: object
    title: Threads
  - beta: true
    description: 'Create messages within threads


      Related guide: [Assistants](/docs/assistants/overview)

      '
    id: messages
    navigationGroup: assistants
    sections:
    - key: createMessage
      path: createMessage
      type: endpoint
    - key: listMessages
      path: listMessages
      type: endpoint
    - key: getMessage
      path: getMessage
      type: endpoint
    - key: modifyMessage
      path: modifyMessage
      type: endpoint
    - key: deleteMessage
      path: deleteMessage
      type: endpoint
    - key: MessageObject
      path: object
      type: object
    title: Messages
  - beta: true
    description: 'Represents an execution run on a thread.


      Related guide: [Assistants](/docs/assistants/overview)

      '
    id: runs
    navigationGroup: assistants
    sections:
    - key: createRun
      path: createRun
      type: endpoint
    - key: createThreadAndRun
      path: createThreadAndRun
      type: endpoint
    - key: listRuns
      path: listRuns
      type: endpoint
    - key: getRun
      path: getRun
      type: endpoint
    - key: modifyRun
      path: modifyRun
      type: endpoint
    - key: submitToolOuputsToRun
      path: submitToolOutputs
      type: endpoint
    - key: cancelRun
      path: cancelRun
      type: endpoint
    - key: RunObject
      path: object
      type: object
    title: Runs
  - beta: true
    description: 'Represents the steps (model and tool calls) taken during the run.


      Related guide: [Assistants](/docs/assistants/overview)

      '
    id: run-steps
    navigationGroup: assistants
    sections:
    - key: listRunSteps
      path: listRunSteps
      type: endpoint
    - key: getRunStep
      path: getRunStep
      type: endpoint
    - key: RunStepObject
      path: step-object
      type: object
    title: Run Steps
  - beta: true
    description: 'Vector stores are used to store files for use by the `file_search`
      tool.


      Related guide: [File Search](/docs/assistants/tools/file-search)

      '
    id: vector-stores
    navigationGroup: assistants
    sections:
    - key: createVectorStore
      path: create
      type: endpoint
    - key: listVectorStores
      path: list
      type: endpoint
    - key: getVectorStore
      path: retrieve
      type: endpoint
    - key: modifyVectorStore
      path: modify
      type: endpoint
    - key: deleteVectorStore
      path: delete
      type: endpoint
    - key: VectorStoreObject
      path: object
      type: object
    title: Vector Stores
  - beta: true
    description: 'Vector store files represent files inside a vector store.


      Related guide: [File Search](/docs/assistants/tools/file-search)

      '
    id: vector-stores-files
    navigationGroup: assistants
    sections:
    - key: createVectorStoreFile
      path: createFile
      type: endpoint
    - key: listVectorStoreFiles
      path: listFiles
      type: endpoint
    - key: getVectorStoreFile
      path: getFile
      type: endpoint
    - key: deleteVectorStoreFile
      path: deleteFile
      type: endpoint
    - key: VectorStoreFileObject
      path: file-object
      type: object
    title: Vector Store Files
  - beta: true
    description: 'Vector store file batches represent operations to add multiple files
      to a vector store.


      Related guide: [File Search](/docs/assistants/tools/file-search)

      '
    id: vector-stores-file-batches
    navigationGroup: assistants
    sections:
    - key: createVectorStoreFileBatch
      path: createBatch
      type: endpoint
    - key: getVectorStoreFileBatch
      path: getBatch
      type: endpoint
    - key: cancelVectorStoreFileBatch
      path: cancelBatch
      type: endpoint
    - key: listFilesInVectorStoreBatch
      path: listBatchFiles
      type: endpoint
    - key: VectorStoreFileBatchObject
      path: batch-object
      type: object
    title: Vector Store File Batches
  - beta: true
    description: 'Stream the result of executing a Run or resuming a Run after submitting
      tool outputs.


      You can stream events from the [Create Thread and Run](/docs/api-reference/runs/createThreadAndRun),

      [Create Run](/docs/api-reference/runs/createRun), and [Submit Tool Outputs](/docs/api-reference/runs/submitToolOutputs)

      endpoints by passing `"stream": true`. The response will be a [Server-Sent events](https://html.spec.whatwg.org/multipage/server-sent-events.html#server-sent-events)
      stream.


      Our Node and Python SDKs provide helpful utilities to make streaming easy. Reference
      the

      [Assistants API quickstart](/docs/assistants/overview) to learn more.

      '
    id: assistants-streaming
    navigationGroup: assistants
    sections:
    - key: MessageDeltaObject
      path: message-delta-object
      type: object
    - key: RunStepDeltaObject
      path: run-step-delta-object
      type: object
    - key: AssistantStreamEvent
      path: events
      type: object
    title: Streaming
  - description: 'Given a prompt, the model will return one or more predicted completions
      along with the probabilities of alternative tokens at each position. Most developer
      should use our [Chat Completions API](/docs/guides/text-generation/text-generation-models)
      to leverage our best and newest models.

      '
    id: completions
    legacy: true
    navigationGroup: legacy
    sections:
    - key: createCompletion
      path: create
      type: endpoint
    - key: CreateCompletionResponse
      path: object
      type: object
    title: Completions
  navigationGroups:
  - id: endpoints
    title: Endpoints
  - id: assistants
    title: Assistants
  - id: legacy
    title: Legacy
